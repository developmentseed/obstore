{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"obstore","text":"<p>Simple, fast integration with object storage services like Amazon S3, Google Cloud Storage, Azure Blob Storage, and S3-compliant APIs like Cloudflare R2.</p> <ul> <li>Sync and async API with full type hinting.</li> <li>Streaming downloads with configurable chunking.</li> <li>Streaming uploads from async or sync iterators.</li> <li>Streaming list, with no need to paginate.</li> <li>Automatically uses multipart uploads for large file objects.</li> <li>Support for conditional put (\"put if not exists\"), as well as custom tags and attributes.</li> <li>Optionally return list results as Arrow, which is faster than materializing Python <code>dict</code>s.</li> <li>File-like object API and fsspec integration.</li> <li>Easy to install with no required Python dependencies.</li> <li>The underlying Rust library is production quality and used in large scale production systems, such as the Rust package registry crates.io.</li> <li>Zero-copy data exchange between Rust and Python via the buffer protocol.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>To install obstore using pip:</p> <pre><code>pip install obstore\n</code></pre> <p>Obstore is on conda-forge and can be installed using conda, mamba, or pixi. To install obstore using conda:</p> <pre><code>conda install -c conda-forge obstore\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>Full documentation is available on the website.</p> <p>Head to Getting Started to dig in.</p>"},{"location":"CHANGELOG/","title":"Changelog","text":""},{"location":"CHANGELOG/#030-2025-01-16","title":"[0.3.0] - 2025-01-16","text":""},{"location":"CHANGELOG/#new-features","title":"New Features","text":"<ul> <li>Streaming uploads. <code>obstore.put</code> now supports iterable input, and <code>obstore.put_async</code> now supports async iterable input. This means you can pass the output of <code>obstore.get_async</code> directly into <code>obstore.put_async</code>. by @kylebarron in developmentseed/obstore!54</li> <li>Allow passing config options directly as keyword arguments. Previously, you had to pass all options as a <code>dict</code> into the <code>config</code> parameter. Now you can pass the elements directly to the store constructor. by @kylebarron in developmentseed/obstore!144</li> <li>Readable file-like objects. Open a readable file-like object with <code>obstore.open</code> and <code>obstore.open_async</code>. by @kylebarron in developmentseed/obstore!33</li> <li>Fsspec integration by @martindurant in developmentseed/obstore!63</li> <li>Prefix store by @kylebarron in developmentseed/obstore!117</li> <li>Python 3.13 wheels by @kylebarron in developmentseed/obstore!95</li> <li>Support python timedelta objects as duration config values by @kylebarron in developmentseed/obstore!146</li> <li>Add class constructors for store builders. Each store now has an <code>__init__</code> method, for easier construction. by @kylebarron in developmentseed/obstore!141</li> </ul>"},{"location":"CHANGELOG/#breaking-changes","title":"Breaking changes","text":"<ul> <li> <p><code>get_range</code>, <code>get_range_async</code>, <code>get_ranges</code>, and <code>get_ranges_async</code> now use start/end instead of offset/length. This is for consistency with the <code>range</code> option of <code>obstore.get</code>. by @kylebarron in developmentseed/obstore!71</p> </li> <li> <p>Return <code>Bytes</code> from <code>GetResult.bytes()</code> by @kylebarron in developmentseed/obstore!134</p> </li> </ul>"},{"location":"CHANGELOG/#bug-fixes","title":"Bug fixes","text":"<ul> <li>boto3 region name can be None by @kylebarron in developmentseed/obstore!59</li> <li>add missing py.typed file by @gruebel in developmentseed/obstore!115</li> </ul>"},{"location":"CHANGELOG/#documentation","title":"Documentation","text":"<ul> <li>FastAPI/Starlette example by @kylebarron in developmentseed/obstore!145</li> <li>Add conda installation doc to README by @kylebarron in developmentseed/obstore!78</li> <li>Document suggested lifecycle rules for aborted multipart uploads by @kylebarron in developmentseed/obstore!139</li> <li>Add type hint and documentation for requester pays by @kylebarron in developmentseed/obstore!131</li> <li>Add note that S3Store can be constructed without boto3 by @kylebarron in developmentseed/obstore!108</li> <li>HTTP Store usage example by @kylebarron in developmentseed/obstore!142</li> </ul>"},{"location":"CHANGELOG/#whats-changed","title":"What's Changed","text":"<ul> <li>Improved docs for from_url by @kylebarron in developmentseed/obstore!138</li> <li>Implement read_all for async iterable by @kylebarron in developmentseed/obstore!140</li> </ul>"},{"location":"CHANGELOG/#new-contributors","title":"New Contributors","text":"<ul> <li>@willemarcel made their first contribution in developmentseed/obstore!64</li> <li>@martindurant made their first contribution in developmentseed/obstore!63</li> <li>@norlandrhagen made their first contribution in developmentseed/obstore!107</li> <li>@gruebel made their first contribution in developmentseed/obstore!115</li> </ul> <p>Full Changelog: github.com/developmentseed/obstore/compare/py-v0.2.0...py-v0.3.0</p>"},{"location":"CHANGELOG/#020-2024-10-25","title":"[0.2.0] - 2024-10-25","text":""},{"location":"CHANGELOG/#whats-changed_1","title":"What's Changed","text":"<ul> <li>Streaming list results. <code>list</code> now returns an async or sync generator. by @kylebarron in developmentseed/obstore!35</li> <li>Optionally return list result as arrow. The <code>return_arrow</code> keyword argument returns chunks from <code>list</code> as Arrow RecordBatches, which is faster than materializing Python dicts/lists. by @kylebarron in developmentseed/obstore!38</li> <li>Return buffer protocol object from <code>get_range</code> and <code>get_ranges</code>. Enables zero-copy data exchange from Rust into Python. by @kylebarron in developmentseed/obstore!39</li> <li>Add put options. Enables custom tags and attributes, as well as \"put if not exists\". by @kylebarron in developmentseed/obstore!50</li> <li>Rename to obstore by @kylebarron in developmentseed/obstore!45</li> <li>Add custom exceptions. by @kylebarron in developmentseed/obstore!48</li> </ul> <p>Full Changelog: github.com/developmentseed/obstore/compare/py-v0.1.0...py-v0.2.0</p>"},{"location":"CHANGELOG/#010-2024-10-21","title":"[0.1.0] - 2024-10-21","text":"<ul> <li>Initial release.</li> </ul>"},{"location":"cookbook/","title":"Cookbook","text":""},{"location":"cookbook/#list-objects","title":"List objects","text":"<p>Use the <code>obstore.list</code> method.</p> <pre><code>import obstore as obs\n\nstore = ... # store of your choice\n\n# Recursively list all files below the 'data' path.\n# 1. On AWS S3 this would be the 'data/' prefix\n# 2. On a local filesystem, this would be the 'data' directory\nprefix = \"data\"\n\n# Get a stream of metadata objects:\nlist_stream = obs.list(store, prefix)\n\n# Print info\nfor batch in list_stream:\n    for meta in batch:\n        print(f\"Name: {meta.path}, size: {meta.size}\")\n</code></pre>"},{"location":"cookbook/#list-objects-as-arrow","title":"List objects as Arrow","text":"<p>The default <code>list</code> behavior creates many small Python <code>dict</code>s. When listing a large bucket, generating these Python objects can add up to a lot of overhead.</p> <p>Instead, you may consider passing <code>return_arrow=True</code> to <code>obstore.list</code> to return each chunk of list results as an Arrow <code>RecordBatch</code>. This can be much faster than materializing Python objects for each row because Arrow can be shared zero-copy between Rust and Python.</p> <p>This Arrow integration requires the <code>arro3-core</code> dependency, a lightweight Arrow implementation. You can pass the emitted <code>RecordBatch</code> to <code>pyarrow</code> (zero-copy) by passing it to <code>pyarrow.record_batch</code> or to <code>polars</code> (also zero-copy) by passing it to <code>polars.DataFrame</code>.</p> <pre><code>import obstore as obs\n\nstore = ... # store of your choice\n\n# Get a stream of Arrow RecordBatches of metadata\nlist_stream = obs.list(store, prefix=\"data\", return_arrow=True)\nfor record_batch in list_stream:\n    print(record_batch.num_rows)\n</code></pre> <p>Here's a working example with the <code>sentinel-cogs</code> bucket in AWS Open Data:</p> <pre><code>import obstore as obs\nimport pandas as pd\nimport pyarrow as pa\nfrom obstore.store import S3Store\n\nstore = S3Store(\"sentinel-cogs\", region=\"us-west-2\", skip_signature=True)\nstream = obs.list(store, chunk_size=20, return_arrow=True)\n\nfor record_batch in stream:\n    # Convert to pyarrow (zero-copy), then to pandas for easy export to a\n    # Markdown table\n    df = pa.record_batch(record_batch).to_pandas()\n    print(df.iloc[:5].to_markdown(index=False))\n    break\n</code></pre> <p>The Arrow record batch looks like the following:</p> path last_modified size e_tag version sentinel-s2-l2a-cogs/1/C/CV/2018/10/S2B_1CCV_20181004_0_L2A/AOT.tif 2020-09-30 20:25:56+00:00 50510 \"2e24c2ee324ea478f2f272dbd3f5ce69\" sentinel-s2-l2a-cogs/1/C/CV/2018/10/S2B_1CCV_20181004_0_L2A/B01.tif 2020-09-30 20:22:48+00:00 1455332 \"a31b78e96748ccc2b21b827bef9850c1\" sentinel-s2-l2a-cogs/1/C/CV/2018/10/S2B_1CCV_20181004_0_L2A/B02.tif 2020-09-30 20:23:19+00:00 38149405 \"d7a92f88ad19761081323165649ce799-5\" sentinel-s2-l2a-cogs/1/C/CV/2018/10/S2B_1CCV_20181004_0_L2A/B03.tif 2020-09-30 20:23:52+00:00 38123224 \"4b938b6969f1c16e5dd685e6599f115f-5\" sentinel-s2-l2a-cogs/1/C/CV/2018/10/S2B_1CCV_20181004_0_L2A/B04.tif 2020-09-30 20:24:21+00:00 39033591 \"4781b581cd32b2169d0b3d22bf40a8ef-5\""},{"location":"cookbook/#fetch-objects","title":"Fetch objects","text":"<p>Use the <code>obstore.get</code> function to fetch data bytes from remote storage or files in the local filesystem.</p> <pre><code>import obstore as obs\n\nstore = ... # store of your choice\n\n# Retrieve a specific file\npath = \"data/file01.parquet\"\n\n# Fetch just the file metadata\nmeta = obs.head(store, path)\nprint(meta)\n\n# Fetch the object including metadata\nresult = obs.get(store, path)\nassert result.meta == meta\n\n# Buffer the entire object in memory\nbuffer = result.bytes()\nassert len(buffer) == meta.size\n\n# Alternatively stream the bytes from object storage\nstream = obs.get(store, path).stream()\n\n# We can now iterate over the stream\ntotal_buffer_len = 0\nfor chunk in stream:\n    total_buffer_len += len(chunk)\n\nassert total_buffer_len == meta.size\n</code></pre>"},{"location":"cookbook/#download-to-disk","title":"Download to disk","text":"<p>Using the response as an iterator ensures that we don't buffer the entire file into memory.</p> <pre><code>import obstore as obs\n\nresp = obs.get(store, path)\n\nwith open(\"output/file\", \"wb\") as f:\n    for chunk in resp:\n        f.write(chunk)\n</code></pre>"},{"location":"cookbook/#put-object","title":"Put object","text":"<p>Use the <code>obstore.put</code> function to atomically write data. <code>obstore.put</code> will automatically use multipart uploads for large input data.</p> <pre><code>import obstore as obs\n\nstore = ... # store of your choice\npath = \"data/file1\"\ncontent = b\"hello\"\nobs.put(store, path, content)\n</code></pre> <p>You can also upload local files:</p> <pre><code>from pathlib import Path\nimport obstore as obs\n\nstore = ... # store of your choice\npath = \"data/file1\"\ncontent = Path(\"path/to/local/file\")\nobs.put(store, path, content)\n</code></pre> <p>Or file-like objects:</p> <pre><code>import obstore as obs\n\nstore = ... # store of your choice\npath = \"data/file1\"\nwith open(\"path/to/local/file\", \"rb\") as content:\n    obs.put(store, path, content)\n</code></pre> <p>Or iterables:</p> <pre><code>import obstore as obs\n\ndef bytes_iter():\n    for i in range(5):\n        yield b\"foo\"\n\nstore = ... # store of your choice\npath = \"data/file1\"\ncontent = bytes_iter()\nobs.put(store, path, content)\n</code></pre> <p>Or async iterables:</p> <pre><code>import obstore as obs\n\nasync def bytes_stream():\n    for i in range(5):\n        yield b\"foo\"\n\nstore = ... # store of your choice\npath = \"data/file1\"\ncontent = bytes_stream()\nobs.put(store, path, content)\n</code></pre>"},{"location":"cookbook/#copy-objects-from-one-store-to-another","title":"Copy objects from one store to another","text":"<p>Perhaps you have data in one store, say AWS S3, that you need to copy to another, say Google Cloud Storage.</p>"},{"location":"cookbook/#in-memory","title":"In memory","text":"<p>Download the file, collect its bytes in memory, then upload it. Note that this will materialize the entire file in memory.</p> <pre><code>import obstore as obs\n\nstore1 = ... # store of your choice\nstore2 = ... # store of your choice\n\npath1 = \"data/file1\"\npath2 = \"data/file2\"\n\nbuffer = obs.get(store1, path1).bytes()\nobs.put(store2, path2, buffer)\n</code></pre>"},{"location":"cookbook/#local-file","title":"Local file","text":"<p>First download the file to disk, then upload it.</p> <pre><code>from pathlib import Path\nimport obstore as obs\n\nstore1 = ... # store of your choice\nstore2 = ... # store of your choice\n\npath1 = \"data/file1\"\npath2 = \"data/file2\"\n\nresp = obs.get(store1, path1)\n\nwith open(\"temporary_file\", \"wb\") as f:\n    for chunk in resp:\n        f.write(chunk)\n\n# Upload the path\nobs.put(store2, path2, Path(\"temporary_file\"))\n</code></pre>"},{"location":"cookbook/#streaming","title":"Streaming","text":"<p>It's easy to stream a download from one store directly as the upload to another. Only the given</p> <p>Note</p> <p>Using the async API is currently required to use streaming copies.</p> <pre><code>import obstore as obs\n\nstore1 = ... # store of your choice\nstore2 = ... # store of your choice\n\npath1 = \"data/file1\"\npath2 = \"data/file2\"\n\n# This only constructs the stream, it doesn't materialize the data in memory\nresp = await obs.get_async(store1, path1)\n# A streaming upload is created to copy the file to path2\nawait obs.put_async(store2, path2, resp, chunk_size=chunk_size)\n</code></pre> <p>Or, by customizing the chunk size and the upload concurrency you can control memory overhead.</p> <pre><code>resp = await obs.get_async(store1, path1)\nchunk_size = 5 * 1024 * 1024 # 5MB\nstream = resp.stream(min_chunk_size=chunk_size)\n\n# A streaming upload is created to copy the file to path2\nawait obs.put_async(\n    store2,\n    path2,\n    stream,\n    chunk_size=chunk_size,\n    max_concurrency=12\n)\n</code></pre> <p>This will start up to 12 concurrent uploads, each with around 5MB chunks, giving a total memory usage of up to roughly 60MB for this copy.</p> <p>Note</p> <p>You may need to increase the download timeout for large source files. The timeout defaults to 30 seconds, which may not be long enough to upload the file to the destination.</p> <pre><code>You may set the [`timeout` parameter][obstore.store.ClientConfig] in the `client_options` passed when creating the store.\n</code></pre>"},{"location":"getting-started/","title":"Getting Started","text":"<p>There are two parts to <code>obstore</code>:</p> <ol> <li>Constructing a <code>Store</code>, a representation of a remote object store with configuration and credentials.</li> <li>Interacting with the <code>Store</code> to download, upload, move, and delete objects.</li> </ol>"},{"location":"getting-started/#constructing-a-store","title":"Constructing a store","text":"<p>Classes to construct a store are exported from the <code>obstore.store</code> submodule:</p> <ul> <li><code>S3Store</code>: Configure a connection to Amazon S3.</li> <li><code>GCSStore</code>: Configure a connection to Google Cloud Storage.</li> <li><code>AzureStore</code>: Configure a connection to Microsoft Azure Blob Storage.</li> <li><code>HTTPStore</code>: Configure a connection to a generic HTTP server</li> <li><code>LocalStore</code>: Local filesystem storage providing the same object store interface.</li> <li><code>MemoryStore</code>: A fully in-memory implementation of ObjectStore.</li> </ul> <p>Additionally, some middlewares exist:</p> <ul> <li><code>PrefixStore</code>: Store wrapper that applies a constant prefix to all paths handled by the store.</li> </ul> <p>Each store concept has a variety of constructors, and a host of configuration options.</p> <p>Example:</p> <p>For example, creating an anonymous <code>S3Store</code> (without any credentials, for use with fully public buckets):</p> <pre><code>from obstore.store import S3Store\n\nstore = S3Store(\"bucket-name\", region=\"us-east-1\", skip_signature=True)\n</code></pre>"},{"location":"getting-started/#configuration","title":"Configuration","text":"<p>Each store class above has its own store-specific configuration. Elements of the store configuration can be passed as keyword arguments or as a dictionary through the <code>config</code> named parameter.</p> <ul> <li><code>S3Config</code>: Configuration parameters for Amazon S3.</li> <li><code>GCSConfig</code>: Configuration parameters for Google Cloud Storage.</li> <li><code>AzureConfig</code>: Configuration parameters for Microsoft Azure Blob Storage.</li> </ul> <p>Additionally, each store accepts parameters for the underlying HTTP client (<code>ClientConfig</code>) and parameters for retrying requests that error (<code>RetryConfig</code>).</p>"},{"location":"getting-started/#interacting-with-a-store","title":"Interacting with a store","text":"<p>All operations for interacting with a store are exported as top-level functions (not methods on the <code>store</code> object):</p> <ul> <li><code>copy</code>: Copy an object from one path to another in the same object store.</li> <li><code>delete</code>: Delete the object at the specified location.</li> <li><code>get</code>: Return the bytes that are stored at the specified location.</li> <li><code>head</code>: Return the metadata for the specified location</li> <li><code>list</code>: List all the objects with the given prefix.</li> <li><code>put</code>: Save the provided buffer to the specified location.</li> <li><code>rename</code>: Move an object from one path to another in the same object store.</li> </ul> <p>There are a few additional APIs useful for specific use cases:</p> <ul> <li><code>get_range</code>: Get a specific byte range from a file.</li> <li><code>get_ranges</code>: Get multiple byte ranges from a single file.</li> <li><code>list_with_delimiter</code>: List objects within a specific directory.</li> <li><code>sign</code>: Create a signed URL.</li> </ul> <p>File-like object support is also provided:</p> <ul> <li><code>open</code>: Open a remote object as a Python file-like object.</li> <li><code>AsyncFsspecStore</code> adapter for use with <code>fsspec</code>.</li> </ul> <p>All operations have a comparable async method with the same name plus an <code>_async</code> suffix.</p>"},{"location":"getting-started/#example","title":"Example","text":"<pre><code>import obstore as obs\n\nstore = obs.store.MemoryStore()\n\nobs.put(store, \"file.txt\", b\"hello world!\")\nresponse = obs.get(store, \"file.txt\")\nresponse.meta\n# {'path': 'file.txt',\n#  'last_modified': datetime.datetime(2024, 10, 21, 16, 19, 45, 102620, tzinfo=datetime.timezone.utc),\n#  'size': 12,\n#  'e_tag': '0',\n#  'version': None}\nassert response.bytes() == b\"hello world!\"\n\nbyte_range = obs.get_range(store, \"file.txt\", offset=0, length=5)\nassert byte_range == b\"hello\"\n\nobs.copy(store, \"file.txt\", \"other.txt\")\nassert obs.get(store, \"other.txt\").bytes() == b\"hello world!\"\n</code></pre> <p>All of these methods also have <code>async</code> counterparts, suffixed with <code>_async</code>.</p> <pre><code>import obstore as obs\n\nstore = obs.store.MemoryStore()\n\nawait obs.put_async(store, \"file.txt\", b\"hello world!\")\nresponse = await obs.get_async(store, \"file.txt\")\nresponse.meta\n# {'path': 'file.txt',\n#  'last_modified': datetime.datetime(2024, 10, 21, 16, 20, 36, 477418, tzinfo=datetime.timezone.utc),\n#  'size': 12,\n#  'e_tag': '0',\n#  'version': None}\nassert await response.bytes_async() == b\"hello world!\"\n\nbyte_range = await obs.get_range_async(store, \"file.txt\", offset=0, length=5)\nassert byte_range == b\"hello\"\n\nawait obs.copy_async(store, \"file.txt\", \"other.txt\")\nresp = await obs.get_async(store, \"other.txt\")\nassert await resp.bytes_async() == b\"hello world!\"\n</code></pre>"},{"location":"api/attributes/","title":"Attributes","text":""},{"location":"api/attributes/#obstore.Attribute","title":"obstore.Attribute  <code>module-attribute</code>","text":"<pre><code>Attribute = (\n    Literal[\n        \"Content-Disposition\",\n        \"Content-Encoding\",\n        \"Content-Language\",\n        \"Content-Type\",\n        \"Cache-Control\",\n    ]\n    | str\n)\n</code></pre> <p>Additional object attribute types.</p> <ul> <li> <p><code>\"Content-Disposition\"</code>: Specifies how the object should be handled by a browser.</p> <p>See Content-Disposition.</p> </li> <li> <p><code>\"Content-Encoding\"</code>: Specifies the encodings applied to the object.</p> <p>See Content-Encoding.</p> </li> <li> <p><code>\"Content-Language\"</code>: Specifies the language of the object.</p> <p>See Content-Language.</p> </li> <li> <p><code>\"Content-Type\"</code>: Specifies the MIME type of the object.</p> <p>This takes precedence over any client configuration.</p> <p>See Content-Type.</p> </li> <li> <p><code>\"Cache-Control\"</code>: Overrides cache control policy of the object.</p> <p>See Cache-Control.</p> </li> </ul> <p>Any other string key specifies a user-defined metadata field for the object.</p>"},{"location":"api/attributes/#obstore.Attributes","title":"obstore.Attributes  <code>module-attribute</code>","text":"<pre><code>Attributes = Dict[Attribute, str]\n</code></pre> <p>Additional attributes of an object</p> <p>Attributes can be specified in <code>put</code>/<code>put_async</code> and retrieved from <code>get</code>/<code>get_async</code>.</p> <p>Unlike ObjectMeta, Attributes are not returned by listing APIs</p>"},{"location":"api/copy/","title":"Copy","text":""},{"location":"api/copy/#obstore.copy","title":"obstore.copy","text":"<pre><code>copy(\n    store: ObjectStore, from_: str, to: str, *, overwrite: bool = True\n) -&gt; None\n</code></pre> <p>Copy an object from one path to another in the same object store.</p> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>ObjectStore</code>)           \u2013            <p>The ObjectStore instance to use.</p> </li> <li> <code>from_</code>               (<code>str</code>)           \u2013            <p>Source path</p> </li> <li> <code>to</code>               (<code>str</code>)           \u2013            <p>Destination path</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>overwrite</code>               (<code>bool</code>)           \u2013            <p>If <code>True</code>, if there exists an object at the destination, it will     be overwritten.</p> <p>If <code>False</code>: will copy only if destination is empty. Performs an atomic operation if the underlying object storage supports it. If atomic operations are not supported by the underlying object storage (like S3) it will return an error.</p> <p>Will return an error if the destination already has an object.</p> </li> </ul>"},{"location":"api/copy/#obstore.copy_async","title":"obstore.copy_async  <code>async</code>","text":"<pre><code>copy_async(\n    store: ObjectStore, from_: str, to: str, *, overwrite: bool = True\n) -&gt; None\n</code></pre> <p>Call <code>copy</code> asynchronously.</p> <p>Refer to the documentation for copy.</p>"},{"location":"api/delete/","title":"Delete","text":""},{"location":"api/delete/#obstore.delete","title":"obstore.delete","text":"<pre><code>delete(store: ObjectStore, paths: str | Sequence[str]) -&gt; None\n</code></pre> <p>Delete the object at the specified location(s).</p> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>ObjectStore</code>)           \u2013            <p>The ObjectStore instance to use.</p> </li> <li> <code>paths</code>               (<code>str | Sequence[str]</code>)           \u2013            <p>The path or paths within the store to delete.</p> <p>When supported by the underlying store, this method will use bulk operations that delete more than one object per a request.</p> <p>If the object did not exist, the result may be an error or a success, depending on the behavior of the underlying store. For example, local filesystems, GCP, and Azure return an error, while S3 and in-memory will return Ok.</p> </li> </ul>"},{"location":"api/delete/#obstore.delete_async","title":"obstore.delete_async  <code>async</code>","text":"<pre><code>delete_async(store: ObjectStore, paths: str | Sequence[str]) -&gt; None\n</code></pre> <p>Call <code>delete</code> asynchronously.</p> <p>Refer to the documentation for delete.</p>"},{"location":"api/exceptions/","title":"Exceptions","text":""},{"location":"api/exceptions/#obstore.exceptions","title":"obstore.exceptions","text":""},{"location":"api/exceptions/#obstore.exceptions.AlreadyExistsError","title":"AlreadyExistsError","text":"<p>               Bases: <code>ObstoreError</code></p> <p>Error when the object already exists.</p>"},{"location":"api/exceptions/#obstore.exceptions.GenericError","title":"GenericError","text":"<p>               Bases: <code>ObstoreError</code></p> <p>A fallback error type when no variant matches.</p>"},{"location":"api/exceptions/#obstore.exceptions.InvalidPathError","title":"InvalidPathError","text":"<p>               Bases: <code>ObstoreError</code></p> <p>Error for invalid path.</p>"},{"location":"api/exceptions/#obstore.exceptions.JoinError","title":"JoinError","text":"<p>               Bases: <code>ObstoreError</code></p> <p>Error when <code>tokio::spawn</code> failed.</p>"},{"location":"api/exceptions/#obstore.exceptions.NotFoundError","title":"NotFoundError","text":"<p>               Bases: <code>ObstoreError</code></p> <p>Error when the object is not found at given location.</p>"},{"location":"api/exceptions/#obstore.exceptions.NotModifiedError","title":"NotModifiedError","text":"<p>               Bases: <code>ObstoreError</code></p> <p>Error when the object at the location isn't modified.</p>"},{"location":"api/exceptions/#obstore.exceptions.NotSupportedError","title":"NotSupportedError","text":"<p>               Bases: <code>ObstoreError</code></p> <p>Error when the attempted operation is not supported.</p>"},{"location":"api/exceptions/#obstore.exceptions.ObstoreError","title":"ObstoreError","text":"<p>               Bases: <code>Exception</code></p> <p>The base exception class</p>"},{"location":"api/exceptions/#obstore.exceptions.PermissionDeniedError","title":"PermissionDeniedError","text":"<p>               Bases: <code>ObstoreError</code></p> <p>Error when the used credentials don't have enough permission to perform the requested operation</p>"},{"location":"api/exceptions/#obstore.exceptions.PreconditionError","title":"PreconditionError","text":"<p>               Bases: <code>ObstoreError</code></p> <p>Error when the required conditions failed for the operation.</p>"},{"location":"api/exceptions/#obstore.exceptions.UnauthenticatedError","title":"UnauthenticatedError","text":"<p>               Bases: <code>ObstoreError</code></p> <p>Error when the used credentials lack valid authentication.</p>"},{"location":"api/exceptions/#obstore.exceptions.UnknownConfigurationKeyError","title":"UnknownConfigurationKeyError","text":"<p>               Bases: <code>ObstoreError</code></p> <p>Error when a configuration key is invalid for the store used.</p>"},{"location":"api/file/","title":"File-like Object","text":"<p>Native support for reading from object stores as a file-like object.</p> <p>Use <code>obstore.open</code> or <code>obstore.open_async</code> to open files. Writing files in this way is not yet supported.</p>"},{"location":"api/file/#obstore.open","title":"obstore.open","text":"<pre><code>open(store: ObjectStore, path: str) -&gt; ReadableFile\n</code></pre> <p>Open a file object from the specified location.</p> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>ObjectStore</code>)           \u2013            <p>The ObjectStore instance to use.</p> </li> <li> <code>path</code>               (<code>str</code>)           \u2013            <p>The path within ObjectStore to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ReadableFile</code>           \u2013            <p>ReadableFile</p> </li> </ul>"},{"location":"api/file/#obstore.open_async","title":"obstore.open_async  <code>async</code>","text":"<pre><code>open_async(store: ObjectStore, path: str) -&gt; AsyncReadableFile\n</code></pre> <p>Call <code>open</code> asynchronously, returning a file object with asynchronous operations.</p> <p>Refer to the documentation for open.</p>"},{"location":"api/file/#obstore.ReadableFile","title":"obstore.ReadableFile","text":"<p>A readable file object with synchronous operations.</p> <p>This implements a similar interface as a generic readable Python binary file-like object.</p>"},{"location":"api/file/#obstore.ReadableFile.close","title":"close","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the current file.</p> <p>This is currently a no-op.</p>"},{"location":"api/file/#obstore.ReadableFile.read","title":"read","text":"<pre><code>read(size: int | None = None) -&gt; Bytes\n</code></pre> <p>Read up to <code>size</code> bytes from the object and return them. As a convenience, if size is unspecified or <code>None</code>, all bytes until EOF are returned.</p>"},{"location":"api/file/#obstore.ReadableFile.readall","title":"readall","text":"<pre><code>readall() -&gt; Bytes\n</code></pre> <p>Read and return all the bytes from the stream until EOF, using multiple calls to the stream if necessary.</p>"},{"location":"api/file/#obstore.ReadableFile.readline","title":"readline","text":"<pre><code>readline() -&gt; Bytes\n</code></pre> <p>Read a single line of the file, up until the next newline character.</p>"},{"location":"api/file/#obstore.ReadableFile.readlines","title":"readlines","text":"<pre><code>readlines(hint: int = -1) -&gt; List[Bytes]\n</code></pre> <p>Read all remaining lines into a list of buffers</p>"},{"location":"api/file/#obstore.ReadableFile.seek","title":"seek","text":"<pre><code>seek(offset: int, whence: int = SEEK_SET) -&gt; int\n</code></pre> <p>Change the stream position to the given byte offset, interpreted relative to the position indicated by whence, and return the new absolute position. Values for whence are:</p> <ul> <li><code>os.SEEK_SET</code> or 0: start of the stream (the default); <code>offset</code> should be zero or positive</li> <li><code>os.SEEK_CUR</code> or 1: current stream position; <code>offset</code> may be negative</li> <li><code>os.SEEK_END</code> or 2: end of the stream; <code>offset</code> is usually negative</li> </ul>"},{"location":"api/file/#obstore.ReadableFile.seekable","title":"seekable","text":"<pre><code>seekable() -&gt; bool\n</code></pre> <p>Return True if the stream supports random access.</p>"},{"location":"api/file/#obstore.ReadableFile.tell","title":"tell","text":"<pre><code>tell() -&gt; int\n</code></pre> <p>Return the current stream position.</p>"},{"location":"api/file/#obstore.AsyncReadableFile","title":"obstore.AsyncReadableFile","text":"<p>A readable file object with asynchronous operations.</p>"},{"location":"api/file/#obstore.AsyncReadableFile.close","title":"close","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the current file.</p> <p>This is currently a no-op.</p>"},{"location":"api/file/#obstore.AsyncReadableFile.read","title":"read  <code>async</code>","text":"<pre><code>read(size: int | None = None) -&gt; Bytes\n</code></pre> <p>Read up to <code>size</code> bytes from the object and return them. As a convenience, if size is unspecified or <code>None</code>, all bytes until EOF are returned.</p>"},{"location":"api/file/#obstore.AsyncReadableFile.readall","title":"readall  <code>async</code>","text":"<pre><code>readall() -&gt; Bytes\n</code></pre> <p>Read and return all the bytes from the stream until EOF, using multiple calls to the stream if necessary.</p>"},{"location":"api/file/#obstore.AsyncReadableFile.readline","title":"readline  <code>async</code>","text":"<pre><code>readline() -&gt; Bytes\n</code></pre> <p>Read a single line of the file, up until the next newline character.</p>"},{"location":"api/file/#obstore.AsyncReadableFile.readlines","title":"readlines  <code>async</code>","text":"<pre><code>readlines(hint: int = -1) -&gt; List[Bytes]\n</code></pre> <p>Read all remaining lines into a list of buffers</p>"},{"location":"api/file/#obstore.AsyncReadableFile.seek","title":"seek  <code>async</code>","text":"<pre><code>seek(offset: int, whence: int = SEEK_SET) -&gt; int\n</code></pre> <p>Change the stream position to the given byte offset, interpreted relative to the position indicated by whence, and return the new absolute position. Values for whence are:</p> <ul> <li><code>os.SEEK_SET</code> or 0: start of the stream (the default); <code>offset</code> should be zero or positive</li> <li><code>os.SEEK_CUR</code> or 1: current stream position; <code>offset</code> may be negative</li> <li><code>os.SEEK_END</code> or 2: end of the stream; <code>offset</code> is usually negative</li> </ul>"},{"location":"api/file/#obstore.AsyncReadableFile.seekable","title":"seekable","text":"<pre><code>seekable() -&gt; bool\n</code></pre> <p>Return True if the stream supports random access.</p>"},{"location":"api/file/#obstore.AsyncReadableFile.tell","title":"tell  <code>async</code>","text":"<pre><code>tell() -&gt; int\n</code></pre> <p>Return the current stream position.</p>"},{"location":"api/fsspec/","title":"obstore.fsspec","text":""},{"location":"api/fsspec/#obstore.fsspec","title":"obstore.fsspec","text":"<p>fsspec integration.</p> <p>The underlying <code>object_store</code> Rust crate cautions against relying too strongly on stateful filesystem representations of object stores:</p> <p>The ObjectStore interface is designed to mirror the APIs of object stores and not filesystems, and thus has stateless APIs instead of cursor based interfaces such as Read or Seek available in filesystems.</p> <p>This design provides the following advantages:</p> <ul> <li>All operations are atomic, and readers cannot observe partial and/or failed writes</li> <li>Methods map directly to object store APIs, providing both efficiency and predictability</li> <li>Abstracts away filesystem and operating system specific quirks, ensuring portability</li> <li>Allows for functionality not native to filesystems, such as operation preconditions and atomic multipart uploads</li> </ul> <p>Where possible, implementations should use the underlying <code>obstore</code> APIs directly. Only where this is not possible should users fall back to this fsspec integration.</p>"},{"location":"api/fsspec/#obstore.fsspec.AsyncFsspecStore","title":"AsyncFsspecStore","text":"<p>               Bases: <code>AsyncFileSystem</code></p> <p>An fsspec implementation based on a obstore Store.</p> <p>You should be able to pass an instance of this class into any API that expects an fsspec-style object.</p>"},{"location":"api/fsspec/#obstore.fsspec.AsyncFsspecStore.__init__","title":"__init__","text":"<pre><code>__init__(\n    store: ObjectStore,\n    *args,\n    asynchronous: bool = False,\n    loop=None,\n    batch_size: int | None = None,\n)\n</code></pre> <p>Construct a new AsyncFsspecStore</p> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>ObjectStore</code>)           \u2013            <p>a configured instance of one of the store classes in <code>obstore.store</code>.</p> </li> <li> <code>asynchronous</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Set to <code>True</code> if this instance is meant to be be called using the fsspec async API. This should only be set to true when running within a coroutine.</p> </li> <li> <code>loop</code>           \u2013            <p>since both fsspec/python and tokio/rust may be using loops, this should be kept <code>None</code> for now, and will not be used.</p> </li> <li> <code>batch_size</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>some operations on many files will batch their requests; if you are seeing timeouts, you may want to set this number smaller than the defaults, which are determined in <code>fsspec.asyn._get_batch_size</code>.</p> </li> </ul> <p>Example:</p> <pre><code>from obstore.fsspec import AsyncFsspecStore\nfrom obstore.store import HTTPStore\n\nstore = HTTPStore.from_url(\"https://example.com\")\nfsspec_store = AsyncFsspecStore(store)\nresp = fsspec_store.cat(\"/\")\nassert resp.startswith(b\"&lt;!doctype html&gt;\")\n</code></pre>"},{"location":"api/fsspec/#obstore.fsspec.BufferedFileSimple","title":"BufferedFileSimple","text":"<p>               Bases: <code>AbstractBufferedFile</code></p>"},{"location":"api/fsspec/#obstore.fsspec.BufferedFileSimple.read","title":"read","text":"<pre><code>read(length: int = -1)\n</code></pre> <p>Return bytes from the remote file</p> if positive, returns up to this many bytes; if negative, return all <p>remaining byets.</p>"},{"location":"api/get/","title":"Get","text":""},{"location":"api/get/#obstore.get","title":"obstore.get","text":"<pre><code>get(\n    store: ObjectStore, path: str, *, options: GetOptions | None = None\n) -&gt; GetResult\n</code></pre> <p>Return the bytes that are stored at the specified location.</p> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>ObjectStore</code>)           \u2013            <p>The ObjectStore instance to use.</p> </li> <li> <code>path</code>               (<code>str</code>)           \u2013            <p>The path within ObjectStore to retrieve.</p> </li> <li> <code>options</code>               (<code>GetOptions | None</code>, default:                   <code>None</code> )           \u2013            <p>options for accessing the file. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>GetResult</code>           \u2013            <p>GetResult</p> </li> </ul>"},{"location":"api/get/#obstore.get_async","title":"obstore.get_async  <code>async</code>","text":"<pre><code>get_async(\n    store: ObjectStore, path: str, *, options: GetOptions | None = None\n) -&gt; GetResult\n</code></pre> <p>Call <code>get</code> asynchronously.</p> <p>Refer to the documentation for get.</p>"},{"location":"api/get/#obstore.get_range","title":"obstore.get_range","text":"<pre><code>get_range(store: ObjectStore, path: str, start: int, end: int) -&gt; Bytes\n</code></pre> <p>Return the bytes that are stored at the specified location in the given byte range.</p> <p>If the given range is zero-length or starts after the end of the object, an error will be returned. Additionally, if the range ends after the end of the object, the entire remainder of the object will be returned. Otherwise, the exact requested range will be returned.</p> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>ObjectStore</code>)           \u2013            <p>The ObjectStore instance to use.</p> </li> <li> <code>path</code>               (<code>str</code>)           \u2013            <p>The path within ObjectStore to retrieve.</p> </li> <li> <code>start</code>               (<code>int</code>)           \u2013            <p>The start of the byte range.</p> </li> <li> <code>end</code>               (<code>int</code>)           \u2013            <p>The end of the byte range (exclusive).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Bytes</code>           \u2013            <p>A <code>Bytes</code> object implementing the Python buffer protocol, allowing zero-copy access to the underlying memory provided by Rust.</p> </li> </ul>"},{"location":"api/get/#obstore.get_range_async","title":"obstore.get_range_async  <code>async</code>","text":"<pre><code>get_range_async(store: ObjectStore, path: str, start: int, end: int) -&gt; Bytes\n</code></pre> <p>Call <code>get_range</code> asynchronously.</p> <p>Refer to the documentation for get_range.</p>"},{"location":"api/get/#obstore.get_ranges","title":"obstore.get_ranges","text":"<pre><code>get_ranges(\n    store: ObjectStore, path: str, starts: Sequence[int], ends: Sequence[int]\n) -&gt; List[Bytes]\n</code></pre> <p>Return the bytes that are stored at the specified location in the given byte ranges</p> <p>To improve performance this will:</p> <ul> <li>Combine ranges less than 10MB apart into a single call to <code>fetch</code></li> <li>Make multiple <code>fetch</code> requests in parallel (up to maximum of 10)</li> </ul> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>ObjectStore</code>)           \u2013            <p>The ObjectStore instance to use.</p> </li> <li> <code>path</code>               (<code>str</code>)           \u2013            <p>The path within ObjectStore to retrieve.</p> </li> <li> <code>starts</code>               (<code>Sequence[int]</code>)           \u2013            <p>A sequence of <code>int</code> where each offset starts.</p> </li> <li> <code>ends</code>               (<code>Sequence[int]</code>)           \u2013            <p>A sequence of <code>int</code> where each offset ends (exclusive).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>List[Bytes]</code>           \u2013            <p>A sequence of <code>Bytes</code>, one for each range. This <code>Bytes</code> object implements the Python buffer protocol, allowing zero-copy access to the underlying memory provided by Rust.</p> </li> </ul>"},{"location":"api/get/#obstore.get_ranges_async","title":"obstore.get_ranges_async  <code>async</code>","text":"<pre><code>get_ranges_async(\n    store: ObjectStore, path: str, starts: Sequence[int], ends: Sequence[int]\n) -&gt; List[Bytes]\n</code></pre> <p>Call <code>get_ranges</code> asynchronously.</p> <p>Refer to the documentation for get_ranges.</p>"},{"location":"api/get/#obstore.GetOptions","title":"obstore.GetOptions","text":"<p>               Bases: <code>TypedDict</code></p> <p>Options for a get request.</p> <p>All options are optional.</p>"},{"location":"api/get/#obstore.GetOptions.head","title":"head  <code>instance-attribute</code>","text":"<pre><code>head: bool\n</code></pre> <p>Request transfer of no content</p> <p>datatracker.ietf.org/doc/html/rfc9110#name-head</p>"},{"location":"api/get/#obstore.GetOptions.if_match","title":"if_match  <code>instance-attribute</code>","text":"<pre><code>if_match: str | None\n</code></pre> <p>Request will succeed if the <code>ObjectMeta::e_tag</code> matches otherwise returning <code>PreconditionError</code>.</p> <p>See datatracker.ietf.org/doc/html/rfc9110#name-if-match</p> <p>Examples:</p> <pre><code>If-Match: \"xyzzy\"\nIf-Match: \"xyzzy\", \"r2d2xxxx\", \"c3piozzzz\"\nIf-Match: *\n</code></pre>"},{"location":"api/get/#obstore.GetOptions.if_modified_since","title":"if_modified_since  <code>instance-attribute</code>","text":"<pre><code>if_modified_since: datetime | None\n</code></pre> <p>Request will succeed if the object has not been modified since otherwise returning <code>PreconditionError</code>.</p> <p>Some stores, such as S3, will only return <code>NotModified</code> for exact timestamp matches, instead of for any timestamp greater than or equal.</p> <p>datatracker.ietf.org/doc/html/rfc9110#section-13.1.4</p>"},{"location":"api/get/#obstore.GetOptions.if_none_match","title":"if_none_match  <code>instance-attribute</code>","text":"<pre><code>if_none_match: str | None\n</code></pre> <p>Request will succeed if the <code>ObjectMeta::e_tag</code> does not match otherwise returning <code>NotModifiedError</code>.</p> <p>See datatracker.ietf.org/doc/html/rfc9110#section-13.1.2</p> <p>Examples:</p> <pre><code>If-None-Match: \"xyzzy\"\nIf-None-Match: \"xyzzy\", \"r2d2xxxx\", \"c3piozzzz\"\nIf-None-Match: *\n</code></pre>"},{"location":"api/get/#obstore.GetOptions.if_unmodified_since","title":"if_unmodified_since  <code>instance-attribute</code>","text":"<pre><code>if_unmodified_since: datetime | None\n</code></pre> <p>Request will succeed if the object has been modified since</p> <p>datatracker.ietf.org/doc/html/rfc9110#section-13.1.3</p>"},{"location":"api/get/#obstore.GetOptions.range","title":"range  <code>instance-attribute</code>","text":"<pre><code>range: Tuple[int, int] | List[int] | OffsetRange | SuffixRange\n</code></pre> <p>Request transfer of only the specified range of bytes otherwise returning <code>NotModifiedError</code>.</p> <p>The semantics of this tuple are:</p> <ul> <li> <p><code>(int, int)</code>: Request a specific range of bytes <code>(start, end)</code>.</p> <p>If the given range is zero-length or starts after the end of the object, an error will be returned. Additionally, if the range ends after the end of the object, the entire remainder of the object will be returned. Otherwise, the exact requested range will be returned.</p> <p>The <code>end</code> offset is exclusive.</p> </li> <li> <p><code>{\"offset\": int}</code>: Request all bytes starting from a given byte offset.</p> <p>This is equivalent to <code>bytes={int}-</code> as an HTTP header.</p> </li> <li> <p><code>{\"suffix\": int}</code>: Request the last <code>int</code> bytes. Note that here, <code>int</code> is the     size of the request, not the byte offset. This is equivalent to <code>bytes=-{int}</code>     as an HTTP header.</p> </li> </ul> <p>datatracker.ietf.org/doc/html/rfc9110#name-range</p>"},{"location":"api/get/#obstore.GetOptions.version","title":"version  <code>instance-attribute</code>","text":"<pre><code>version: str | None\n</code></pre> <p>Request a particular object version</p>"},{"location":"api/get/#obstore.GetResult","title":"obstore.GetResult","text":"<p>Result for a get request.</p> <p>You can materialize the entire buffer by using either <code>bytes</code> or <code>bytes_async</code>, or you can stream the result using <code>stream</code>. <code>__iter__</code> and <code>__aiter__</code> are implemented as aliases to <code>stream</code>, so you can alternatively call <code>iter()</code> or <code>aiter()</code> on <code>GetResult</code> to start an iterator.</p> <p>Using as an async iterator: <pre><code>resp = await obs.get_async(store, path)\n# 5MB chunk size in stream\nstream = resp.stream(min_chunk_size=5 * 1024 * 1024)\nasync for buf in stream:\n    print(len(buf))\n</code></pre></p> <p>Using as a sync iterator: <pre><code>resp = obs.get(store, path)\n# 20MB chunk size in stream\nstream = resp.stream(min_chunk_size=20 * 1024 * 1024)\nfor buf in stream:\n    print(len(buf))\n</code></pre></p> <p>Note that after calling <code>bytes</code>, <code>bytes_async</code>, or <code>stream</code>, you will no longer be able to call other methods on this object, such as the <code>meta</code> attribute.</p>"},{"location":"api/get/#obstore.GetResult.attributes","title":"attributes  <code>property</code>","text":"<pre><code>attributes: Attributes\n</code></pre> <p>Additional object attributes.</p> <p>This must be accessed before calling <code>stream</code>, <code>bytes</code>, or <code>bytes_async</code>.</p>"},{"location":"api/get/#obstore.GetResult.meta","title":"meta  <code>property</code>","text":"<pre><code>meta: ObjectMeta\n</code></pre> <p>The ObjectMeta for this object.</p> <p>This must be accessed before calling <code>stream</code>, <code>bytes</code>, or <code>bytes_async</code>.</p>"},{"location":"api/get/#obstore.GetResult.range","title":"range  <code>property</code>","text":"<pre><code>range: Tuple[int, int]\n</code></pre> <p>The range of bytes returned by this request.</p> <p>Note that this is <code>(start, stop)</code> not <code>(start, length)</code>.</p> <p>This must be accessed before calling <code>stream</code>, <code>bytes</code>, or <code>bytes_async</code>.</p>"},{"location":"api/get/#obstore.GetResult.__aiter__","title":"__aiter__","text":"<pre><code>__aiter__() -&gt; BytesStream\n</code></pre> <p>Return a chunked stream over the result's bytes with the default (10MB) chunk size.</p>"},{"location":"api/get/#obstore.GetResult.__iter__","title":"__iter__","text":"<pre><code>__iter__() -&gt; BytesStream\n</code></pre> <p>Return a chunked stream over the result's bytes with the default (10MB) chunk size.</p>"},{"location":"api/get/#obstore.GetResult.bytes","title":"bytes","text":"<pre><code>bytes() -&gt; Bytes\n</code></pre> <p>Collects the data into a <code>Bytes</code> object, which implements the Python buffer protocol. You can copy the buffer to Python memory by passing to <code>bytes</code>.</p>"},{"location":"api/get/#obstore.GetResult.bytes_async","title":"bytes_async  <code>async</code>","text":"<pre><code>bytes_async() -&gt; Bytes\n</code></pre> <p>Collects the data into a <code>Bytes</code> object, which implements the Python buffer protocol. You can copy the buffer to Python memory by passing to <code>bytes</code>.</p>"},{"location":"api/get/#obstore.GetResult.stream","title":"stream","text":"<pre><code>stream(min_chunk_size: int = 10 * 1024 * 1024) -&gt; BytesStream\n</code></pre> <p>Return a chunked stream over the result's bytes.</p> <p>Parameters:</p> <ul> <li> <code>min_chunk_size</code>               (<code>int</code>, default:                   <code>10 * 1024 * 1024</code> )           \u2013            <p>The minimum size in bytes for each chunk in the returned <code>BytesStream</code>. All chunks except for the last chunk will be at least this size. Defaults to 10*1024*1024 (10MB).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>BytesStream</code>           \u2013            <p>A chunked stream</p> </li> </ul>"},{"location":"api/get/#obstore.BytesStream","title":"obstore.BytesStream","text":"<p>An async stream of bytes.</p> <p>Request timeouts</p> <p>The underlying stream needs to stay alive until the last chunk is polled. If the file is large, it may exceed the default timeout of 30 seconds. In this case, you may see an error like:</p> <pre><code>GenericError: Generic {\n    store: \"HTTP\",\n    source: reqwest::Error {\n        kind: Decode,\n        source: reqwest::Error {\n            kind: Body,\n            source: TimedOut,\n        },\n    },\n}\n</code></pre> <p>To fix this, set the <code>timeout</code> parameter in the <code>client_options</code> passed when creating the store.</p>"},{"location":"api/get/#obstore.BytesStream.__aiter__","title":"__aiter__","text":"<pre><code>__aiter__() -&gt; BytesStream\n</code></pre> <p>Return <code>Self</code> as an async iterator.</p>"},{"location":"api/get/#obstore.BytesStream.__anext__","title":"__anext__  <code>async</code>","text":"<pre><code>__anext__() -&gt; bytes\n</code></pre> <p>Return the next chunk of bytes in the stream.</p>"},{"location":"api/get/#obstore.BytesStream.__iter__","title":"__iter__","text":"<pre><code>__iter__() -&gt; BytesStream\n</code></pre> <p>Return <code>Self</code> as an async iterator.</p>"},{"location":"api/get/#obstore.BytesStream.__next__","title":"__next__","text":"<pre><code>__next__() -&gt; bytes\n</code></pre> <p>Return the next chunk of bytes in the stream.</p>"},{"location":"api/get/#obstore.Bytes","title":"obstore.Bytes","text":"<p>               Bases: <code>Buffer</code></p> <p>A buffer implementing the Python buffer protocol, allowing zero-copy access to underlying Rust memory.</p> <p>You can pass this to <code>memoryview</code> for a zero-copy view into the underlying data or to <code>bytes</code> to copy the underlying data into a Python <code>bytes</code>.</p> <p>Many methods from the Python <code>bytes</code> class are implemented on this,</p>"},{"location":"api/get/#obstore.Bytes.isalnum","title":"isalnum","text":"<pre><code>isalnum() -&gt; bool\n</code></pre> <p>Return <code>True</code> if all bytes in the sequence are alphabetical ASCII characters or ASCII decimal digits and the sequence is not empty, <code>False</code> otherwise.</p> <p>Alphabetic ASCII characters are those byte values in the sequence <code>b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'</code>. ASCII decimal digits are those byte values in the sequence <code>b'0123456789'</code>.</p>"},{"location":"api/get/#obstore.Bytes.isalpha","title":"isalpha","text":"<pre><code>isalpha() -&gt; bool\n</code></pre> <p>Return <code>True</code> if all bytes in the sequence are alphabetic ASCII characters and the sequence is not empty, <code>False</code> otherwise.</p> <p>Alphabetic ASCII characters are those byte values in the sequence <code>b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'</code>.</p>"},{"location":"api/get/#obstore.Bytes.isascii","title":"isascii","text":"<pre><code>isascii() -&gt; bool\n</code></pre> <p>Return <code>True</code> if the sequence is empty or all bytes in the sequence are ASCII, <code>False</code> otherwise.</p> <p>ASCII bytes are in the range <code>0-0x7F</code>.</p>"},{"location":"api/get/#obstore.Bytes.isdigit","title":"isdigit","text":"<pre><code>isdigit() -&gt; bool\n</code></pre> <p>Return <code>True</code> if all bytes in the sequence are ASCII decimal digits and the sequence is not empty, <code>False</code> otherwise.</p> <p>ASCII decimal digits are those byte values in the sequence <code>b'0123456789'</code>.</p>"},{"location":"api/get/#obstore.Bytes.islower","title":"islower","text":"<pre><code>islower() -&gt; bool\n</code></pre> <p>Return <code>True</code> if there is at least one lowercase ASCII character in the sequence and no uppercase ASCII characters, <code>False</code> otherwise.</p>"},{"location":"api/get/#obstore.Bytes.isspace","title":"isspace","text":"<pre><code>isspace() -&gt; bool\n</code></pre> <pre><code> Return `True` if all bytes in the sequence are ASCII whitespace and the sequence\n is not empty, `False` otherwise.\n\n ASCII whitespace characters are those byte values\n in the sequence `b'\n</code></pre> <p>'` (space, tab, newline, carriage return,      vertical tab, form feed).</p>"},{"location":"api/get/#obstore.Bytes.isupper","title":"isupper","text":"<pre><code>isupper() -&gt; bool\n</code></pre> <p>Return <code>True</code> if there is at least one uppercase alphabetic ASCII character in the sequence and no lowercase ASCII characters, <code>False</code> otherwise.</p>"},{"location":"api/get/#obstore.Bytes.lower","title":"lower","text":"<pre><code>lower() -&gt; Bytes\n</code></pre> <p>Return a copy of the sequence with all the uppercase ASCII characters converted to their corresponding lowercase counterpart.</p>"},{"location":"api/get/#obstore.Bytes.removeprefix","title":"removeprefix","text":"<pre><code>removeprefix(prefix: Buffer) -&gt; Bytes\n</code></pre> <p>If the binary data starts with the prefix string, return <code>bytes[len(prefix):]</code>. Otherwise, return the original binary data.</p>"},{"location":"api/get/#obstore.Bytes.removesuffix","title":"removesuffix","text":"<pre><code>removesuffix(suffix: Buffer) -&gt; Bytes\n</code></pre> <p>If the binary data ends with the suffix string and that suffix is not empty, return <code>bytes[:-len(suffix)]</code>. Otherwise, return the original binary data.</p>"},{"location":"api/get/#obstore.Bytes.to_bytes","title":"to_bytes","text":"<pre><code>to_bytes() -&gt; bytes\n</code></pre> <p>Copy this buffer's contents into a Python <code>bytes</code> object.</p>"},{"location":"api/get/#obstore.Bytes.upper","title":"upper","text":"<pre><code>upper() -&gt; Bytes\n</code></pre> <p>Return a copy of the sequence with all the lowercase ASCII characters converted to their corresponding uppercase counterpart.</p>"},{"location":"api/get/#obstore.OffsetRange","title":"obstore.OffsetRange","text":"<p>               Bases: <code>TypedDict</code></p> <p>Request all bytes starting from a given byte offset</p>"},{"location":"api/get/#obstore.OffsetRange.offset","title":"offset  <code>instance-attribute</code>","text":"<pre><code>offset: int\n</code></pre> <p>The byte offset for the offset range request.</p>"},{"location":"api/get/#obstore.SuffixRange","title":"obstore.SuffixRange","text":"<p>               Bases: <code>TypedDict</code></p> <p>Request up to the last <code>n</code> bytes</p>"},{"location":"api/get/#obstore.SuffixRange.suffix","title":"suffix  <code>instance-attribute</code>","text":"<pre><code>suffix: int\n</code></pre> <p>The number of bytes from the suffix to request.</p>"},{"location":"api/head/","title":"Head","text":""},{"location":"api/head/#obstore.head","title":"obstore.head","text":"<pre><code>head(store: ObjectStore, path: str) -&gt; ObjectMeta\n</code></pre> <p>Return the metadata for the specified location</p> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>ObjectStore</code>)           \u2013            <p>The ObjectStore instance to use.</p> </li> <li> <code>path</code>               (<code>str</code>)           \u2013            <p>The path within ObjectStore to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ObjectMeta</code>           \u2013            <p>ObjectMeta</p> </li> </ul>"},{"location":"api/head/#obstore.head_async","title":"obstore.head_async  <code>async</code>","text":"<pre><code>head_async(store: ObjectStore, path: str) -&gt; ObjectMeta\n</code></pre> <p>Call <code>head</code> asynchronously.</p> <p>Refer to the documentation for head.</p>"},{"location":"api/list/","title":"List","text":""},{"location":"api/list/#obstore.list","title":"obstore.list","text":"<pre><code>list(\n    store: ObjectStore,\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[True],\n) -&gt; ListStream[RecordBatch]\n</code></pre><pre><code>list(\n    store: ObjectStore,\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[False] = False,\n) -&gt; ListStream[List[ObjectMeta]]\n</code></pre> <pre><code>list(\n    store: ObjectStore,\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: bool = False,\n) -&gt; ListStream[RecordBatch] | ListStream[List[ObjectMeta]]\n</code></pre> <p>List all the objects with the given prefix.</p> <p>Prefixes are evaluated on a path segment basis, i.e. <code>foo/bar/</code> is a prefix of <code>foo/bar/x</code> but not of <code>foo/bar_baz/x</code>. List is recursive, i.e. <code>foo/bar/more/x</code> will be included.</p> <p>Examples:</p> <p>Synchronously iterate through list results:</p> <pre><code>import obstore as obs\nfrom obstore.store import MemoryStore\n\nstore = MemoryStore()\nfor i in range(100):\n    obs.put(store, f\"file{i}.txt\", b\"foo\")\n\nstream = obs.list(store, chunk_size=10)\nfor list_result in stream:\n    print(list_result[0])\n    # {'path': 'file0.txt', 'last_modified': datetime.datetime(2024, 10, 23, 19, 19, 28, 781723, tzinfo=datetime.timezone.utc), 'size': 3, 'e_tag': '0', 'version': None}\n    break\n</code></pre> <p>Asynchronously iterate through list results. Just change <code>for</code> to <code>async for</code>:</p> <pre><code>stream = obs.list(store, chunk_size=10)\nasync for list_result in stream:\n    print(list_result[2])\n    # {'path': 'file10.txt', 'last_modified': datetime.datetime(2024, 10, 23, 19, 21, 46, 224725, tzinfo=datetime.timezone.utc), 'size': 3, 'e_tag': '10', 'version': None}\n    break\n</code></pre> <p>Return large list results as Arrow. This is most useful with large list operations. In this case you may want to increase the <code>chunk_size</code> parameter.</p> <pre><code>stream = obs.list(store, chunk_size=1000, return_arrow=True)\n# Stream is now an iterable/async iterable of `RecordBatch`es\nfor batch in stream:\n    print(batch.num_rows) # 100\n\n    # If desired, convert to a pyarrow RecordBatch (zero-copy) with\n    # `pyarrow.record_batch(batch)`\n    break\n</code></pre> <p>Collect all list results into a single Arrow <code>RecordBatch</code>.</p> <pre><code>stream = obs.list(store, return_arrow=True)\nbatch = stream.collect()\n</code></pre> <p>Note</p> <p>The order of returned <code>ObjectMeta</code> is not guaranteed</p> <p>Note</p> <p>There is no async version of this method, because <code>list</code> is not async under the hood, rather it only instantiates a stream, which can be polled in synchronous or asynchronous fashion. See <code>ListStream</code>.</p> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>ObjectStore</code>)           \u2013            <p>The ObjectStore instance to use.</p> </li> <li> <code>prefix</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>The prefix within ObjectStore to use for listing. Defaults to None.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>offset</code>               (<code>str | None</code>)           \u2013            <p>If provided, list all the objects with the given prefix and a location greater than <code>offset</code>. Defaults to <code>None</code>.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The number of items to collect per chunk in the returned (async) iterator. All chunks except for the last one will have this many items. This is ignored in the <code>collect</code> and <code>collect_async</code> methods of <code>ListStream</code>.</p> </li> <li> <code>return_arrow</code>               (<code>bool</code>)           \u2013            <p>If <code>True</code>, return each batch of list items as an Arrow <code>RecordBatch</code>, not as a list of Python <code>dict</code>s. Arrow removes serialization overhead between Rust and Python and so this can be significantly faster for large list operations. Defaults to <code>False</code>.</p> <p>If this is <code>True</code>, the <code>arro3-core</code> Python package must be installed.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ListStream[RecordBatch] | ListStream[List[ObjectMeta]]</code>           \u2013            <p>A ListStream, which you can iterate through to access list results.</p> </li> </ul>"},{"location":"api/list/#obstore.list_with_delimiter","title":"obstore.list_with_delimiter","text":"<pre><code>list_with_delimiter(\n    store: ObjectStore, prefix: str | None = None\n) -&gt; ListResult\n</code></pre> <p>List objects with the given prefix and an implementation specific delimiter. Returns common prefixes (directories) in addition to object metadata.</p> <p>Prefixes are evaluated on a path segment basis, i.e. <code>foo/bar/</code> is a prefix of <code>foo/bar/x</code> but not of <code>foo/bar_baz/x</code>. List is not recursive, i.e. <code>foo/bar/more/x</code> will not be included.</p> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>ObjectStore</code>)           \u2013            <p>The ObjectStore instance to use.</p> </li> <li> <code>prefix</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>The prefix within ObjectStore to use for listing. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ListResult</code>           \u2013            <p>ListResult</p> </li> </ul>"},{"location":"api/list/#obstore.list_with_delimiter_async","title":"obstore.list_with_delimiter_async  <code>async</code>","text":"<pre><code>list_with_delimiter_async(\n    store: ObjectStore, prefix: str | None = None\n) -&gt; ListResult\n</code></pre> <p>Call <code>list_with_delimiter</code> asynchronously.</p> <p>Refer to the documentation for list_with_delimiter.</p>"},{"location":"api/list/#obstore.ObjectMeta","title":"obstore.ObjectMeta","text":"<p>               Bases: <code>TypedDict</code></p> <p>The metadata that describes an object.</p>"},{"location":"api/list/#obstore.ObjectMeta.e_tag","title":"e_tag  <code>instance-attribute</code>","text":"<pre><code>e_tag: str | None\n</code></pre> <p>The unique identifier for the object</p> <p>datatracker.ietf.org/doc/html/rfc9110#name-etag</p>"},{"location":"api/list/#obstore.ObjectMeta.last_modified","title":"last_modified  <code>instance-attribute</code>","text":"<pre><code>last_modified: datetime\n</code></pre> <p>The last modified time</p>"},{"location":"api/list/#obstore.ObjectMeta.path","title":"path  <code>instance-attribute</code>","text":"<pre><code>path: str\n</code></pre> <p>The full path to the object</p>"},{"location":"api/list/#obstore.ObjectMeta.size","title":"size  <code>instance-attribute</code>","text":"<pre><code>size: int\n</code></pre> <p>The size in bytes of the object</p>"},{"location":"api/list/#obstore.ObjectMeta.version","title":"version  <code>instance-attribute</code>","text":"<pre><code>version: str | None\n</code></pre> <p>A version indicator for this object</p>"},{"location":"api/list/#obstore.ListResult","title":"obstore.ListResult","text":"<p>               Bases: <code>TypedDict</code></p> <p>Result of a list call that includes objects, prefixes (directories) and a token for the next set of results. Individual result sets may be limited to 1,000 objects based on the underlying object storage's limitations.</p>"},{"location":"api/list/#obstore.ListResult.common_prefixes","title":"common_prefixes  <code>instance-attribute</code>","text":"<pre><code>common_prefixes: List[str]\n</code></pre> <p>Prefixes that are common (like directories)</p>"},{"location":"api/list/#obstore.ListResult.objects","title":"objects  <code>instance-attribute</code>","text":"<pre><code>objects: List[ObjectMeta]\n</code></pre> <p>Object metadata for the listing</p>"},{"location":"api/list/#obstore.ListStream","title":"obstore.ListStream","text":"<p>               Bases: <code>Generic[ChunkType]</code></p> <p>A stream of ObjectMeta that can be polled in a sync or async fashion.</p>"},{"location":"api/list/#obstore.ListStream.__aiter__","title":"__aiter__","text":"<pre><code>__aiter__() -&gt; Self\n</code></pre> <p>Return <code>Self</code> as an async iterator.</p>"},{"location":"api/list/#obstore.ListStream.__anext__","title":"__anext__  <code>async</code>","text":"<pre><code>__anext__() -&gt; ChunkType\n</code></pre> <p>Return the next chunk of ObjectMeta in the stream.</p>"},{"location":"api/list/#obstore.ListStream.__iter__","title":"__iter__","text":"<pre><code>__iter__() -&gt; Self\n</code></pre> <p>Return <code>Self</code> as an async iterator.</p>"},{"location":"api/list/#obstore.ListStream.__next__","title":"__next__","text":"<pre><code>__next__() -&gt; ChunkType\n</code></pre> <p>Return the next chunk of ObjectMeta in the stream.</p>"},{"location":"api/list/#obstore.ListStream.collect","title":"collect","text":"<pre><code>collect() -&gt; ChunkType\n</code></pre> <p>Collect all remaining ObjectMeta objects in the stream.</p> <p>This ignores the <code>chunk_size</code> parameter from the <code>list</code> call and collects all remaining data into a single chunk.</p>"},{"location":"api/list/#obstore.ListStream.collect_async","title":"collect_async  <code>async</code>","text":"<pre><code>collect_async() -&gt; ChunkType\n</code></pre> <p>Collect all remaining ObjectMeta objects in the stream.</p> <p>This ignores the <code>chunk_size</code> parameter from the <code>list</code> call and collects all remaining data into a single chunk.</p>"},{"location":"api/put/","title":"Put","text":""},{"location":"api/put/#obstore.put","title":"obstore.put","text":"<pre><code>put(\n    store: ObjectStore,\n    path: str,\n    file: IO[bytes]\n    | Path\n    | bytes\n    | Buffer\n    | Iterator[Buffer]\n    | Iterable[Buffer],\n    *,\n    attributes: Attributes | None = None,\n    tags: Dict[str, str] | None = None,\n    mode: PutMode | None = None,\n    use_multipart: bool | None = None,\n    chunk_size: int = 5 * 1024 * 1024,\n    max_concurrency: int = 12,\n) -&gt; PutResult\n</code></pre> <p>Save the provided bytes to the specified location</p> <p>The operation is guaranteed to be atomic, it will either successfully write the entirety of <code>file</code> to <code>location</code>, or fail. No clients should be able to observe a partially written object.</p> <p>Aborted multipart uploads</p> <p>This function will automatically use multipart uploads under the hood for large file objects (whenever the length of the file is greater than <code>chunk_size</code>) or for iterable or async iterable input.</p> <p>Multipart uploads have a variety of advantages, including performance and reliability.</p> <p>However, aborted or incomplete multipart uploads can leave partial content in a hidden state in your bucket, silently adding to your storage costs. It's recommended to configure lifecycle rules to automatically delete aborted multipart uploads. See here for the AWS S3 documentation, for example.</p> <p>You can turn off multipart uploads by passing <code>use_multipart=False</code>.</p> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>ObjectStore</code>)           \u2013            <p>The ObjectStore instance to use.</p> </li> <li> <code>path</code>               (<code>str</code>)           \u2013            <p>The path within ObjectStore for where to save the file.</p> </li> <li> <code>file</code>               (<code>IO[bytes] | Path | bytes | Buffer | Iterator[Buffer] | Iterable[Buffer]</code>)           \u2013            <p>The object to upload. Supports various input:</p> <ul> <li>A file-like object opened in binary read mode</li> <li>A <code>Path</code> to a local file</li> <li>A <code>bytes</code> object.</li> <li>Any object implementing the Python buffer   protocol (includes <code>bytes</code>   but also <code>memoryview</code>, numpy arrays, and more).</li> <li>An iterator or iterable of objects implementing the Python buffer   protocol.</li> </ul> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>mode</code>               (<code>PutMode | None</code>)           \u2013            <p>Configure the <code>PutMode</code> for this operation. Refer to the <code>PutMode</code> docstring for more information.</p> <p>If this provided and is not <code>\"overwrite\"</code>, a non-multipart upload will be performed. Defaults to <code>\"overwrite\"</code>.</p> </li> <li> <code>attributes</code>               (<code>Attributes | None</code>)           \u2013            <p>Provide a set of <code>Attributes</code>. Defaults to <code>None</code>.</p> </li> <li> <code>tags</code>               (<code>Dict[str, str] | None</code>)           \u2013            <p>Provide tags for this object. Defaults to <code>None</code>.</p> </li> <li> <code>use_multipart</code>               (<code>bool | None</code>)           \u2013            <p>Whether to use a multipart upload under the hood. Defaults using a multipart upload if the length of the file is greater than <code>chunk_size</code>. When <code>use_multipart</code> is <code>False</code>, the entire input will be materialized in memory as part of the upload.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The size of chunks to use within each part of the multipart upload. Defaults to 5 MB.</p> </li> <li> <code>max_concurrency</code>               (<code>int</code>)           \u2013            <p>The maximum number of chunks to upload concurrently. Defaults to 12.</p> </li> </ul>"},{"location":"api/put/#obstore.put_async","title":"obstore.put_async  <code>async</code>","text":"<pre><code>put_async(\n    store: ObjectStore,\n    path: str,\n    file: IO[bytes]\n    | Path\n    | bytes\n    | Buffer\n    | AsyncIterator[Buffer]\n    | AsyncIterable[Buffer]\n    | Iterator[Buffer]\n    | Iterable[Buffer],\n    *,\n    attributes: Attributes | None = None,\n    tags: Dict[str, str] | None = None,\n    mode: PutMode | None = None,\n    use_multipart: bool | None = None,\n    chunk_size: int = 5 * 1024 * 1024,\n    max_concurrency: int = 12,\n) -&gt; PutResult\n</code></pre> <p>Call <code>put</code> asynchronously.</p> <p>Refer to the documentation for <code>put</code>. In addition to what the synchronous <code>put</code> allows for the <code>file</code> parameter, this also supports an async iterator or iterable of objects implementing the Python buffer protocol.</p> <p>This means, for example, you can pass the result of <code>get_async</code> directly to <code>put_async</code>, and the request will be streamed through Python during the put operation:</p> <pre><code>import obstore as obs\n\n# This only constructs the stream, it doesn't materialize the data in memory\nresp = await obs.get_async(store1, path1)\n# A streaming upload is created to copy the file to path2\nawait obs.put_async(store2, path2)\n</code></pre>"},{"location":"api/put/#obstore.PutResult","title":"obstore.PutResult","text":"<p>               Bases: <code>TypedDict</code></p> <p>Result for a put request.</p>"},{"location":"api/put/#obstore.PutResult.e_tag","title":"e_tag  <code>instance-attribute</code>","text":"<pre><code>e_tag: str | None\n</code></pre> <p>The unique identifier for the newly created object</p> <p>datatracker.ietf.org/doc/html/rfc9110#name-etag</p>"},{"location":"api/put/#obstore.PutResult.version","title":"version  <code>instance-attribute</code>","text":"<pre><code>version: str | None\n</code></pre> <p>A version indicator for the newly created object.</p>"},{"location":"api/put/#obstore.UpdateVersion","title":"obstore.UpdateVersion","text":"<p>               Bases: <code>TypedDict</code></p> <p>Uniquely identifies a version of an object to update</p> <p>Stores will use differing combinations of <code>e_tag</code> and <code>version</code> to provide conditional updates, and it is therefore recommended applications preserve both</p>"},{"location":"api/put/#obstore.UpdateVersion.e_tag","title":"e_tag  <code>instance-attribute</code>","text":"<pre><code>e_tag: str | None\n</code></pre> <p>The unique identifier for the newly created object.</p> <p>datatracker.ietf.org/doc/html/rfc9110#name-etag</p>"},{"location":"api/put/#obstore.UpdateVersion.version","title":"version  <code>instance-attribute</code>","text":"<pre><code>version: str | None\n</code></pre> <p>A version indicator for the newly created object.</p>"},{"location":"api/put/#obstore.PutMode","title":"obstore.PutMode  <code>module-attribute</code>","text":"<pre><code>PutMode = Literal['create', 'overwrite'] | UpdateVersion\n</code></pre> <p>Configure preconditions for the put operation</p> <p>There are three modes:</p> <ul> <li>Overwrite: Perform an atomic write operation, overwriting any object present at the provided path.</li> <li>Create: Perform an atomic write operation, returning <code>AlreadyExistsError</code> if an object already exists at the provided path.</li> <li>Update: Perform an atomic write operation if the current version of the object matches the provided <code>UpdateVersion</code>, returning <code>PreconditionError</code> otherwise.</li> </ul> <p>If a string is provided, it must be one of:</p> <ul> <li><code>\"overwrite\"</code></li> <li><code>\"create\"</code></li> </ul> <p>If a <code>dict</code> is provided, it must meet the criteria of <code>UpdateVersion</code>.</p>"},{"location":"api/rename/","title":"Rename","text":""},{"location":"api/rename/#obstore.rename","title":"obstore.rename","text":"<pre><code>rename(\n    store: ObjectStore, from_: str, to: str, *, overwrite: bool = True\n) -&gt; None\n</code></pre> <p>Move an object from one path to another in the same object store.</p> <p>By default, this is implemented as a copy and then delete source. It may not check when deleting source that it was the same object that was originally copied.</p> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>ObjectStore</code>)           \u2013            <p>The ObjectStore instance to use.</p> </li> <li> <code>from_</code>               (<code>str</code>)           \u2013            <p>Source path</p> </li> <li> <code>to</code>               (<code>str</code>)           \u2013            <p>Destination path</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>overwrite</code>               (<code>bool</code>)           \u2013            <p>If <code>True</code>, if there exists an object at the destination, it will be overwritten. If <code>False</code>, will return an error if the destination already has an object.</p> </li> </ul>"},{"location":"api/rename/#obstore.rename_async","title":"obstore.rename_async  <code>async</code>","text":"<pre><code>rename_async(\n    store: ObjectStore, from_: str, to: str, *, overwrite: bool = True\n) -&gt; None\n</code></pre> <p>Call <code>rename</code> asynchronously.</p> <p>Refer to the documentation for rename.</p>"},{"location":"api/sign/","title":"Sign","text":""},{"location":"api/sign/#obstore.sign","title":"obstore.sign","text":"<pre><code>sign(\n    store: SignCapableStore,\n    method: HTTP_METHOD,\n    paths: str,\n    expires_in: timedelta,\n) -&gt; str\n</code></pre><pre><code>sign(\n    store: SignCapableStore,\n    method: HTTP_METHOD,\n    paths: Sequence[str],\n    expires_in: timedelta,\n) -&gt; List[str]\n</code></pre> <pre><code>sign(\n    store: SignCapableStore,\n    method: HTTP_METHOD,\n    paths: str | Sequence[str],\n    expires_in: timedelta,\n) -&gt; str | List[str]\n</code></pre> <p>Create a signed URL.</p> <p>Given the intended <code>method</code> and <code>paths</code> to use and the desired length of time for which the URL should be valid, return a signed URL created with the object store implementation's credentials such that the URL can be handed to something that doesn't have access to the object store's credentials, to allow limited access to the object store.</p> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>SignCapableStore</code>)           \u2013            <p>The ObjectStore instance to use.</p> </li> <li> <code>method</code>               (<code>HTTP_METHOD</code>)           \u2013            <p>The HTTP method to use.</p> </li> <li> <code>paths</code>               (<code>str | Sequence[str]</code>)           \u2013            <p>The path(s) within ObjectStore to retrieve. If</p> </li> <li> <code>expires_in</code>               (<code>timedelta</code>)           \u2013            <p>How long the signed URL(s) should be valid.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str | List[str]</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/sign/#obstore.sign_async","title":"obstore.sign_async  <code>async</code>","text":"<pre><code>sign_async(\n    store: SignCapableStore,\n    method: HTTP_METHOD,\n    paths: str,\n    expires_in: timedelta,\n) -&gt; str\n</code></pre><pre><code>sign_async(\n    store: SignCapableStore,\n    method: HTTP_METHOD,\n    paths: Sequence[str],\n    expires_in: timedelta,\n) -&gt; List[str]\n</code></pre> <pre><code>sign_async(\n    store: SignCapableStore,\n    method: HTTP_METHOD,\n    paths: str | Sequence[str],\n    expires_in: timedelta,\n) -&gt; str | List[str]\n</code></pre> <p>Call <code>sign</code> asynchronously.</p> <p>Refer to the documentation for sign.</p>"},{"location":"api/sign/#obstore.SignCapableStore","title":"obstore.SignCapableStore  <code>module-attribute</code>","text":"<pre><code>SignCapableStore = AzureStore | GCSStore | S3Store\n</code></pre> <p>ObjectStore instances that are capable of signing.</p>"},{"location":"api/sign/#obstore.HTTP_METHOD","title":"obstore.HTTP_METHOD  <code>module-attribute</code>","text":"<pre><code>HTTP_METHOD = Literal[\n    \"GET\",\n    \"PUT\",\n    \"POST\",\n    \"HEAD\",\n    \"PATCH\",\n    \"TRACE\",\n    \"DELETE\",\n    \"OPTIONS\",\n    \"CONNECT\",\n]\n</code></pre> <p>Allowed HTTP Methods for signing.</p>"},{"location":"api/store/","title":"ObjectStore","text":""},{"location":"api/store/#obstore.store.ObjectStore","title":"obstore.store.ObjectStore  <code>module-attribute</code>","text":"<pre><code>ObjectStore = (\n    AzureStore\n    | GCSStore\n    | HTTPStore\n    | S3Store\n    | LocalStore\n    | MemoryStore\n    | PrefixStore\n)\n</code></pre> <p>All supported ObjectStore implementations.</p>"},{"location":"api/store/aws/","title":"AWS S3","text":""},{"location":"api/store/aws/#obstore.store.S3Store","title":"obstore.store.S3Store","text":"<p>Configure a connection to Amazon S3 using the specified credentials in the specified Amazon region and bucket.</p> <p>Examples:</p> <p>Using requester-pays buckets:</p> <p>Pass <code>request_payer=True</code> as a keyword argument. Or, if you're using <code>S3Store.from_env</code>, have <code>AWS_REQUESTER_PAYS=True</code> set in the environment.</p> <p>Anonymous requests:</p> <p>Pass <code>skip_signature=True</code> as a keyword argument. Or, if you're using <code>S3Store.from_env</code>, have <code>AWS_SKIP_SIGNATURE=True</code> set in the environment.</p>"},{"location":"api/store/aws/#obstore.store.S3Store.__init__","title":"__init__","text":"<pre><code>__init__(\n    bucket: str,\n    *,\n    config: S3Config | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    **kwargs: Unpack[S3Config],\n) -&gt; None\n</code></pre> <p>Create a new S3Store</p> <p>Parameters:</p> <ul> <li> <code>bucket</code>               (<code>str</code>)           \u2013            <p>The AWS bucket to use.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>config</code>               (<code>S3Config | None</code>)           \u2013            <p>AWS Configuration. Values in this config will override values inferred from the environment. Defaults to None.</p> </li> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>S3Store</p> </li> </ul>"},{"location":"api/store/aws/#obstore.store.S3Store.from_env","title":"from_env  <code>classmethod</code>","text":"<pre><code>from_env(\n    bucket: str | None = None,\n    *,\n    config: S3Config | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    **kwargs: Unpack[S3Config],\n) -&gt; S3Store\n</code></pre> <p>Construct a new S3Store with regular AWS environment variables</p> <p>All environment variables starting with <code>AWS_</code> will be evaluated. Names must match items from <code>S3ConfigKey</code>. Only upper-case environment variables are accepted.</p> <p>Some examples of variables extracted from environment:</p> <ul> <li><code>AWS_ACCESS_KEY_ID</code> -&gt; access_key_id</li> <li><code>AWS_SECRET_ACCESS_KEY</code> -&gt; secret_access_key</li> <li><code>AWS_DEFAULT_REGION</code> -&gt; region</li> <li><code>AWS_ENDPOINT</code> -&gt; endpoint</li> <li><code>AWS_SESSION_TOKEN</code> -&gt; token</li> <li><code>AWS_CONTAINER_CREDENTIALS_RELATIVE_URI</code> -&gt; docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html</li> <li><code>AWS_REQUEST_PAYER</code> -&gt; set to \"true\" to permit requester-pays connections.</li> </ul> <p>Parameters:</p> <ul> <li> <code>bucket</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>The AWS bucket to use.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>config</code>               (<code>S3Config | None</code>)           \u2013            <p>AWS Configuration. Values in this config will override values inferred from the environment. Defaults to None.</p> </li> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>S3Store</code>           \u2013            <p>S3Store</p> </li> </ul>"},{"location":"api/store/aws/#obstore.store.S3Store.from_session","title":"from_session  <code>classmethod</code>","text":"<pre><code>from_session(\n    session: Session | Session,\n    bucket: str,\n    *,\n    config: S3Config | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    **kwargs: Unpack[S3Config],\n) -&gt; S3Store\n</code></pre> <p>Construct a new S3Store with credentials inferred from a boto3 Session</p> <p>This can be useful to read S3 credentials from disk-based credentials sources.</p> <p>Note</p> <p>This is a convenience function for users who are already using <code>boto3</code> or <code>botocore</code>. If you're not already using <code>boto3</code> or <code>botocore</code>, use other constructors, which do not need <code>boto3</code> or <code>botocore</code> to be installed.</p> <p>Examples:</p> <pre><code>import boto3\n\nsession = boto3.Session()\nstore = S3Store.from_session(session, \"bucket-name\", region=\"us-east-1\")\n</code></pre> <p>Parameters:</p> <ul> <li> <code>session</code>               (<code>Session | Session</code>)           \u2013            <p>The boto3.Session or botocore.session.Session to infer credentials from.</p> </li> <li> <code>bucket</code>               (<code>str</code>)           \u2013            <p>The AWS bucket to use.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>config</code>               (<code>S3Config | None</code>)           \u2013            <p>AWS Configuration. Values in this config will override values inferred from the session. Defaults to None.</p> </li> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>S3Store</code>           \u2013            <p>S3Store</p> </li> </ul>"},{"location":"api/store/aws/#obstore.store.S3Store.from_url","title":"from_url  <code>classmethod</code>","text":"<pre><code>from_url(\n    url: str,\n    *,\n    config: S3Config | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    **kwargs: Unpack[S3Config],\n) -&gt; S3Store\n</code></pre> <p>Parse available connection info from a well-known storage URL.</p> <p>The supported url schemes are:</p> <ul> <li><code>s3://&lt;bucket&gt;/&lt;path&gt;</code></li> <li><code>s3a://&lt;bucket&gt;/&lt;path&gt;</code></li> <li><code>https://s3.&lt;region&gt;.amazonaws.com/&lt;bucket&gt;</code></li> <li><code>https://&lt;bucket&gt;.s3.&lt;region&gt;.amazonaws.com</code></li> <li><code>https://ACCOUNT_ID.r2.cloudflarestorage.com/bucket</code></li> </ul> <p>Note</p> <p>Note that <code>from_url</code> will not use any additional parts of the path as a bucket prefix. It will only extract the bucket, region, and endpoint. If you wish to use a path prefix, consider wrapping this with <code>PrefixStore</code>.</p> <p>Parameters:</p> <ul> <li> <code>url</code>               (<code>str</code>)           \u2013            <p>well-known storage URL.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>config</code>               (<code>S3Config | None</code>)           \u2013            <p>AWS Configuration. Values in this config will override values inferred from the url. Defaults to None.</p> </li> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>S3Store</code>           \u2013            <p>S3Store</p> </li> </ul>"},{"location":"api/store/aws/#obstore.store.S3Config","title":"obstore.store.S3Config","text":"<p>               Bases: <code>TypedDict</code></p> <p>Configuration parameters for S3Store.</p> <p>There are duplicates of many parameters, and parameters can be either upper or lower case. Not all parameters are required.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.ACCESS_KEY_ID","title":"ACCESS_KEY_ID  <code>instance-attribute</code>","text":"<pre><code>ACCESS_KEY_ID: str\n</code></pre> <p>AWS Access Key</p>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_ACCESS_KEY_ID","title":"AWS_ACCESS_KEY_ID  <code>instance-attribute</code>","text":"<pre><code>AWS_ACCESS_KEY_ID: str\n</code></pre> <p>AWS Access Key</p>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_BUCKET","title":"AWS_BUCKET  <code>instance-attribute</code>","text":"<pre><code>AWS_BUCKET: str\n</code></pre> <p>Bucket name</p>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_BUCKET_NAME","title":"AWS_BUCKET_NAME  <code>instance-attribute</code>","text":"<pre><code>AWS_BUCKET_NAME: str\n</code></pre> <p>Bucket name</p>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_CHECKSUM_ALGORITHM","title":"AWS_CHECKSUM_ALGORITHM  <code>instance-attribute</code>","text":"<pre><code>AWS_CHECKSUM_ALGORITHM: str\n</code></pre> <p>Sets the checksum algorithm which has to be used for object integrity check during upload.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_CONDITIONAL_PUT","title":"AWS_CONDITIONAL_PUT  <code>instance-attribute</code>","text":"<pre><code>AWS_CONDITIONAL_PUT: str\n</code></pre> <p>Configure how to provide conditional put support</p> <p>Supported values:</p> <ul> <li> <p><code>\"etag\"</code>: Supported for S3-compatible stores that support conditional     put using the standard HTTP precondition headers <code>If-Match</code> and     <code>If-None-Match</code>.</p> </li> <li> <p><code>\"dynamo:&lt;TABLE_NAME&gt;\"</code> or <code>\"dynamo:&lt;TABLE_NAME&gt;:&lt;TIMEOUT_MILLIS&gt;\"</code>: The name of a DynamoDB table to use for coordination.</p> <p>This will use the same region, credentials and endpoint as configured for S3.</p> </li> </ul>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_CONTAINER_CREDENTIALS_RELATIVE_URI","title":"AWS_CONTAINER_CREDENTIALS_RELATIVE_URI  <code>instance-attribute</code>","text":"<pre><code>AWS_CONTAINER_CREDENTIALS_RELATIVE_URI: str\n</code></pre> <p>Set the container credentials relative URI</p> <p>docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html</p>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_COPY_IF_NOT_EXISTS","title":"AWS_COPY_IF_NOT_EXISTS  <code>instance-attribute</code>","text":"<pre><code>AWS_COPY_IF_NOT_EXISTS: str\n</code></pre> <p>Configure how to provide \"copy if not exists\".</p> <p>Supported values:</p> <ul> <li> <p><code>\"multipart\"</code>:</p> <p>Native Amazon S3 supports copy if not exists through a multipart upload where the upload copies an existing object and is completed only if the new object does not already exist.</p> <p>Warning</p> <p>When using this mode, <code>copy_if_not_exists</code> does not copy tags or attributes from the source object.</p> <p>Warning</p> <p>When using this mode, <code>copy_if_not_exists</code> makes only a best effort attempt to clean up the multipart upload if the copy operation fails. Consider using a lifecycle rule to automatically clean up abandoned multipart uploads.</p> </li> <li> <p><code>\"header:&lt;HEADER_NAME&gt;:&lt;HEADER_VALUE&gt;\"</code>:</p> <p>Some S3-compatible stores, such as Cloudflare R2, support copy if not exists semantics through custom headers.</p> <p>If set, <code>copy_if_not_exists</code> will perform a normal copy operation with the provided header pair, and expect the store to fail with <code>412 Precondition Failed</code> if the destination file already exists.</p> <p>For example <code>header: cf-copy-destination-if-none-match: *</code>, would set the header <code>cf-copy-destination-if-none-match</code> to <code>*</code>.</p> </li> <li> <p><code>\"header-with-status:&lt;HEADER_NAME&gt;:&lt;HEADER_VALUE&gt;:&lt;STATUS&gt;\"</code>:</p> <p>The same as the header variant above but allows custom status code checking, for object stores that return values other than 412.</p> </li> <li> <p><code>\"dynamo:&lt;TABLE_NAME&gt;\"</code> or <code>\"dynamo:&lt;TABLE_NAME&gt;:&lt;TIMEOUT_MILLIS&gt;\"</code>:</p> <p>The name of a DynamoDB table to use for coordination.</p> <p>The default timeout is used if not specified. This will use the same region, credentials and endpoint as configured for S3.</p> </li> </ul>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_DEFAULT_REGION","title":"AWS_DEFAULT_REGION  <code>instance-attribute</code>","text":"<pre><code>AWS_DEFAULT_REGION: str\n</code></pre> <p>Default region</p>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_DISABLE_TAGGING","title":"AWS_DISABLE_TAGGING  <code>instance-attribute</code>","text":"<pre><code>AWS_DISABLE_TAGGING: bool\n</code></pre> <p>Disable tagging objects. This can be desirable if not supported by the backing store.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_ENDPOINT","title":"AWS_ENDPOINT  <code>instance-attribute</code>","text":"<pre><code>AWS_ENDPOINT: str\n</code></pre> <p>Sets custom endpoint for communicating with AWS S3.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_ENDPOINT_URL","title":"AWS_ENDPOINT_URL  <code>instance-attribute</code>","text":"<pre><code>AWS_ENDPOINT_URL: str\n</code></pre> <p>Sets custom endpoint for communicating with AWS S3.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_IMDSV1_FALLBACK","title":"AWS_IMDSV1_FALLBACK  <code>instance-attribute</code>","text":"<pre><code>AWS_IMDSV1_FALLBACK: str\n</code></pre> <p>Fall back to ImdsV1</p>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_METADATA_ENDPOINT","title":"AWS_METADATA_ENDPOINT  <code>instance-attribute</code>","text":"<pre><code>AWS_METADATA_ENDPOINT: str\n</code></pre> <p>Set the instance metadata endpoint</p>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_REGION","title":"AWS_REGION  <code>instance-attribute</code>","text":"<pre><code>AWS_REGION: str\n</code></pre> <p>Region</p>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_REQUEST_PAYER","title":"AWS_REQUEST_PAYER  <code>instance-attribute</code>","text":"<pre><code>AWS_REQUEST_PAYER: bool\n</code></pre> <p>If <code>True</code>, enable operations on requester-pays buckets.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_S3_EXPRESS","title":"AWS_S3_EXPRESS  <code>instance-attribute</code>","text":"<pre><code>AWS_S3_EXPRESS: str\n</code></pre> <p>Enable Support for S3 Express One Zone</p>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_SECRET_ACCESS_KEY","title":"AWS_SECRET_ACCESS_KEY  <code>instance-attribute</code>","text":"<pre><code>AWS_SECRET_ACCESS_KEY: str\n</code></pre> <p>Secret Access Key</p>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_SERVER_SIDE_ENCRYPTION","title":"AWS_SERVER_SIDE_ENCRYPTION  <code>instance-attribute</code>","text":"<pre><code>AWS_SERVER_SIDE_ENCRYPTION: str\n</code></pre> <p>Type of encryption to use.</p> <p>If set, must be one of:</p> <ul> <li><code>\"AES256\"</code> (SSE-S3)</li> <li><code>\"aws:kms\"</code> (SSE-KMS)</li> <li><code>\"aws:kms:dsse\"</code> (DSSE-KMS)</li> <li><code>\"sse-c\"</code></li> </ul>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_SESSION_TOKEN","title":"AWS_SESSION_TOKEN  <code>instance-attribute</code>","text":"<pre><code>AWS_SESSION_TOKEN: str\n</code></pre> <p>Token to use for requests (passed to underlying provider)</p>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_SKIP_SIGNATURE","title":"AWS_SKIP_SIGNATURE  <code>instance-attribute</code>","text":"<pre><code>AWS_SKIP_SIGNATURE: bool\n</code></pre> <p>If <code>True</code>, S3Store will not fetch credentials and will not sign requests.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_SSE_BUCKET_KEY_ENABLED","title":"AWS_SSE_BUCKET_KEY_ENABLED  <code>instance-attribute</code>","text":"<pre><code>AWS_SSE_BUCKET_KEY_ENABLED: bool\n</code></pre> <p>If set to <code>True</code>, will use the bucket's default KMS key for server-side encryption. If set to <code>False</code>, will disable the use of the bucket's default KMS key for server-side encryption.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_SSE_CUSTOMER_KEY_BASE64","title":"AWS_SSE_CUSTOMER_KEY_BASE64  <code>instance-attribute</code>","text":"<pre><code>AWS_SSE_CUSTOMER_KEY_BASE64: str\n</code></pre> <p>The base64 encoded, 256-bit customer encryption key to use for server-side encryption. If set, the server side encryption config value must be <code>\"sse-c\"</code>.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_SSE_KMS_KEY_ID","title":"AWS_SSE_KMS_KEY_ID  <code>instance-attribute</code>","text":"<pre><code>AWS_SSE_KMS_KEY_ID: str\n</code></pre> <p>The KMS key ID to use for server-side encryption.</p> <p>If set, the server side encrypting config value must be <code>\"aws:kms\"</code> or <code>\"aws:kms:dsse\"</code>.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_TOKEN","title":"AWS_TOKEN  <code>instance-attribute</code>","text":"<pre><code>AWS_TOKEN: str\n</code></pre> <p>Token to use for requests (passed to underlying provider)</p>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_UNSIGNED_PAYLOAD","title":"AWS_UNSIGNED_PAYLOAD  <code>instance-attribute</code>","text":"<pre><code>AWS_UNSIGNED_PAYLOAD: bool\n</code></pre> <p>Avoid computing payload checksum when calculating signature.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.AWS_VIRTUAL_HOSTED_STYLE_REQUEST","title":"AWS_VIRTUAL_HOSTED_STYLE_REQUEST  <code>instance-attribute</code>","text":"<pre><code>AWS_VIRTUAL_HOSTED_STYLE_REQUEST: bool\n</code></pre> <p>If virtual hosted style request has to be used.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.BUCKET","title":"BUCKET  <code>instance-attribute</code>","text":"<pre><code>BUCKET: str\n</code></pre> <p>Bucket name</p>"},{"location":"api/store/aws/#obstore.store.S3Config.BUCKET_NAME","title":"BUCKET_NAME  <code>instance-attribute</code>","text":"<pre><code>BUCKET_NAME: str\n</code></pre> <p>Bucket name</p>"},{"location":"api/store/aws/#obstore.store.S3Config.CHECKSUM_ALGORITHM","title":"CHECKSUM_ALGORITHM  <code>instance-attribute</code>","text":"<pre><code>CHECKSUM_ALGORITHM: str\n</code></pre> <p>Sets the checksum algorithm which has to be used for object integrity check during upload.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.CONDITIONAL_PUT","title":"CONDITIONAL_PUT  <code>instance-attribute</code>","text":"<pre><code>CONDITIONAL_PUT: str\n</code></pre> <p>Configure how to provide conditional put support</p> <p>Supported values:</p> <ul> <li> <p><code>\"etag\"</code>: Supported for S3-compatible stores that support conditional     put using the standard HTTP precondition headers <code>If-Match</code> and     <code>If-None-Match</code>.</p> </li> <li> <p><code>\"dynamo:&lt;TABLE_NAME&gt;\"</code> or <code>\"dynamo:&lt;TABLE_NAME&gt;:&lt;TIMEOUT_MILLIS&gt;\"</code>: The name of a DynamoDB table to use for coordination.</p> <p>This will use the same region, credentials and endpoint as configured for S3.</p> </li> </ul>"},{"location":"api/store/aws/#obstore.store.S3Config.COPY_IF_NOT_EXISTS","title":"COPY_IF_NOT_EXISTS  <code>instance-attribute</code>","text":"<pre><code>COPY_IF_NOT_EXISTS: str\n</code></pre> <p>Configure how to provide \"copy if not exists\".</p> <p>Supported values:</p> <ul> <li> <p><code>\"multipart\"</code>:</p> <p>Native Amazon S3 supports copy if not exists through a multipart upload where the upload copies an existing object and is completed only if the new object does not already exist.</p> <p>Warning</p> <p>When using this mode, <code>copy_if_not_exists</code> does not copy tags or attributes from the source object.</p> <p>Warning</p> <p>When using this mode, <code>copy_if_not_exists</code> makes only a best effort attempt to clean up the multipart upload if the copy operation fails. Consider using a lifecycle rule to automatically clean up abandoned multipart uploads.</p> </li> <li> <p><code>\"header:&lt;HEADER_NAME&gt;:&lt;HEADER_VALUE&gt;\"</code>:</p> <p>Some S3-compatible stores, such as Cloudflare R2, support copy if not exists semantics through custom headers.</p> <p>If set, <code>copy_if_not_exists</code> will perform a normal copy operation with the provided header pair, and expect the store to fail with <code>412 Precondition Failed</code> if the destination file already exists.</p> <p>For example <code>header: cf-copy-destination-if-none-match: *</code>, would set the header <code>cf-copy-destination-if-none-match</code> to <code>*</code>.</p> </li> <li> <p><code>\"header-with-status:&lt;HEADER_NAME&gt;:&lt;HEADER_VALUE&gt;:&lt;STATUS&gt;\"</code>:</p> <p>The same as the header variant above but allows custom status code checking, for object stores that return values other than 412.</p> </li> <li> <p><code>\"dynamo:&lt;TABLE_NAME&gt;\"</code> or <code>\"dynamo:&lt;TABLE_NAME&gt;:&lt;TIMEOUT_MILLIS&gt;\"</code>:</p> <p>The name of a DynamoDB table to use for coordination.</p> <p>The default timeout is used if not specified. This will use the same region, credentials and endpoint as configured for S3.</p> </li> </ul>"},{"location":"api/store/aws/#obstore.store.S3Config.DEFAULT_REGION","title":"DEFAULT_REGION  <code>instance-attribute</code>","text":"<pre><code>DEFAULT_REGION: str\n</code></pre> <p>Default region</p>"},{"location":"api/store/aws/#obstore.store.S3Config.DISABLE_TAGGING","title":"DISABLE_TAGGING  <code>instance-attribute</code>","text":"<pre><code>DISABLE_TAGGING: bool\n</code></pre> <p>Disable tagging objects. This can be desirable if not supported by the backing store.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.ENDPOINT","title":"ENDPOINT  <code>instance-attribute</code>","text":"<pre><code>ENDPOINT: str\n</code></pre> <p>Sets custom endpoint for communicating with AWS S3.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.ENDPOINT_URL","title":"ENDPOINT_URL  <code>instance-attribute</code>","text":"<pre><code>ENDPOINT_URL: str\n</code></pre> <p>Sets custom endpoint for communicating with AWS S3.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.IMDSV1_FALLBACK","title":"IMDSV1_FALLBACK  <code>instance-attribute</code>","text":"<pre><code>IMDSV1_FALLBACK: str\n</code></pre> <p>Fall back to ImdsV1</p>"},{"location":"api/store/aws/#obstore.store.S3Config.METADATA_ENDPOINT","title":"METADATA_ENDPOINT  <code>instance-attribute</code>","text":"<pre><code>METADATA_ENDPOINT: str\n</code></pre> <p>Set the instance metadata endpoint</p>"},{"location":"api/store/aws/#obstore.store.S3Config.REGION","title":"REGION  <code>instance-attribute</code>","text":"<pre><code>REGION: str\n</code></pre> <p>Region</p>"},{"location":"api/store/aws/#obstore.store.S3Config.REQUEST_PAYER","title":"REQUEST_PAYER  <code>instance-attribute</code>","text":"<pre><code>REQUEST_PAYER: bool\n</code></pre> <p>If <code>True</code>, enable operations on requester-pays buckets.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.S3_EXPRESS","title":"S3_EXPRESS  <code>instance-attribute</code>","text":"<pre><code>S3_EXPRESS: str\n</code></pre> <p>Enable Support for S3 Express One Zone</p>"},{"location":"api/store/aws/#obstore.store.S3Config.SECRET_ACCESS_KEY","title":"SECRET_ACCESS_KEY  <code>instance-attribute</code>","text":"<pre><code>SECRET_ACCESS_KEY: str\n</code></pre> <p>Secret Access Key</p>"},{"location":"api/store/aws/#obstore.store.S3Config.SESSION_TOKEN","title":"SESSION_TOKEN  <code>instance-attribute</code>","text":"<pre><code>SESSION_TOKEN: str\n</code></pre> <p>Token to use for requests (passed to underlying provider)</p>"},{"location":"api/store/aws/#obstore.store.S3Config.SKIP_SIGNATURE","title":"SKIP_SIGNATURE  <code>instance-attribute</code>","text":"<pre><code>SKIP_SIGNATURE: bool\n</code></pre> <p>If <code>True</code>, S3Store will not fetch credentials and will not sign requests.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.TOKEN","title":"TOKEN  <code>instance-attribute</code>","text":"<pre><code>TOKEN: str\n</code></pre> <p>Token to use for requests (passed to underlying provider)</p>"},{"location":"api/store/aws/#obstore.store.S3Config.UNSIGNED_PAYLOAD","title":"UNSIGNED_PAYLOAD  <code>instance-attribute</code>","text":"<pre><code>UNSIGNED_PAYLOAD: bool\n</code></pre> <p>Avoid computing payload checksum when calculating signature.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.VIRTUAL_HOSTED_STYLE_REQUEST","title":"VIRTUAL_HOSTED_STYLE_REQUEST  <code>instance-attribute</code>","text":"<pre><code>VIRTUAL_HOSTED_STYLE_REQUEST: bool\n</code></pre> <p>If virtual hosted style request has to be used.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.access_key_id","title":"access_key_id  <code>instance-attribute</code>","text":"<pre><code>access_key_id: str\n</code></pre> <p>AWS Access Key</p>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_access_key_id","title":"aws_access_key_id  <code>instance-attribute</code>","text":"<pre><code>aws_access_key_id: str\n</code></pre> <p>AWS Access Key</p>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_bucket","title":"aws_bucket  <code>instance-attribute</code>","text":"<pre><code>aws_bucket: str\n</code></pre> <p>Bucket name</p>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_bucket_name","title":"aws_bucket_name  <code>instance-attribute</code>","text":"<pre><code>aws_bucket_name: str\n</code></pre> <p>Bucket name</p>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_checksum_algorithm","title":"aws_checksum_algorithm  <code>instance-attribute</code>","text":"<pre><code>aws_checksum_algorithm: str\n</code></pre> <p>Sets the checksum algorithm which has to be used for object integrity check during upload.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_conditional_put","title":"aws_conditional_put  <code>instance-attribute</code>","text":"<pre><code>aws_conditional_put: str\n</code></pre> <p>Configure how to provide conditional put support</p> <p>Supported values:</p> <ul> <li> <p><code>\"etag\"</code>: Supported for S3-compatible stores that support conditional     put using the standard HTTP precondition headers <code>If-Match</code> and     <code>If-None-Match</code>.</p> </li> <li> <p><code>\"dynamo:&lt;TABLE_NAME&gt;\"</code> or <code>\"dynamo:&lt;TABLE_NAME&gt;:&lt;TIMEOUT_MILLIS&gt;\"</code>: The name of a DynamoDB table to use for coordination.</p> <p>This will use the same region, credentials and endpoint as configured for S3.</p> </li> </ul>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_container_credentials_relative_uri","title":"aws_container_credentials_relative_uri  <code>instance-attribute</code>","text":"<pre><code>aws_container_credentials_relative_uri: str\n</code></pre> <p>Set the container credentials relative URI</p> <p>docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html</p>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_copy_if_not_exists","title":"aws_copy_if_not_exists  <code>instance-attribute</code>","text":"<pre><code>aws_copy_if_not_exists: str\n</code></pre> <p>Configure how to provide \"copy if not exists\".</p> <p>Supported values:</p> <ul> <li> <p><code>\"multipart\"</code>:</p> <p>Native Amazon S3 supports copy if not exists through a multipart upload where the upload copies an existing object and is completed only if the new object does not already exist.</p> <p>Warning</p> <p>When using this mode, <code>copy_if_not_exists</code> does not copy tags or attributes from the source object.</p> <p>Warning</p> <p>When using this mode, <code>copy_if_not_exists</code> makes only a best effort attempt to clean up the multipart upload if the copy operation fails. Consider using a lifecycle rule to automatically clean up abandoned multipart uploads.</p> </li> <li> <p><code>\"header:&lt;HEADER_NAME&gt;:&lt;HEADER_VALUE&gt;\"</code>:</p> <p>Some S3-compatible stores, such as Cloudflare R2, support copy if not exists semantics through custom headers.</p> <p>If set, <code>copy_if_not_exists</code> will perform a normal copy operation with the provided header pair, and expect the store to fail with <code>412 Precondition Failed</code> if the destination file already exists.</p> <p>For example <code>header: cf-copy-destination-if-none-match: *</code>, would set the header <code>cf-copy-destination-if-none-match</code> to <code>*</code>.</p> </li> <li> <p><code>\"header-with-status:&lt;HEADER_NAME&gt;:&lt;HEADER_VALUE&gt;:&lt;STATUS&gt;\"</code>:</p> <p>The same as the header variant above but allows custom status code checking, for object stores that return values other than 412.</p> </li> <li> <p><code>\"dynamo:&lt;TABLE_NAME&gt;\"</code> or <code>\"dynamo:&lt;TABLE_NAME&gt;:&lt;TIMEOUT_MILLIS&gt;\"</code>:</p> <p>The name of a DynamoDB table to use for coordination.</p> <p>The default timeout is used if not specified. This will use the same region, credentials and endpoint as configured for S3.</p> </li> </ul>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_default_region","title":"aws_default_region  <code>instance-attribute</code>","text":"<pre><code>aws_default_region: str\n</code></pre> <p>Default region</p>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_disable_tagging","title":"aws_disable_tagging  <code>instance-attribute</code>","text":"<pre><code>aws_disable_tagging: bool\n</code></pre> <p>Disable tagging objects. This can be desirable if not supported by the backing store.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_endpoint","title":"aws_endpoint  <code>instance-attribute</code>","text":"<pre><code>aws_endpoint: str\n</code></pre> <p>Sets custom endpoint for communicating with AWS S3.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_endpoint_url","title":"aws_endpoint_url  <code>instance-attribute</code>","text":"<pre><code>aws_endpoint_url: str\n</code></pre> <p>Sets custom endpoint for communicating with AWS S3.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_imdsv1_fallback","title":"aws_imdsv1_fallback  <code>instance-attribute</code>","text":"<pre><code>aws_imdsv1_fallback: str\n</code></pre> <p>Fall back to ImdsV1</p>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_metadata_endpoint","title":"aws_metadata_endpoint  <code>instance-attribute</code>","text":"<pre><code>aws_metadata_endpoint: str\n</code></pre> <p>Set the instance metadata endpoint</p>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_region","title":"aws_region  <code>instance-attribute</code>","text":"<pre><code>aws_region: str\n</code></pre> <p>Region</p>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_request_payer","title":"aws_request_payer  <code>instance-attribute</code>","text":"<pre><code>aws_request_payer: bool\n</code></pre> <p>If <code>True</code>, enable operations on requester-pays buckets.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_s3_express","title":"aws_s3_express  <code>instance-attribute</code>","text":"<pre><code>aws_s3_express: bool\n</code></pre> <p>Enable Support for S3 Express One Zone</p>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_secret_access_key","title":"aws_secret_access_key  <code>instance-attribute</code>","text":"<pre><code>aws_secret_access_key: str\n</code></pre> <p>Secret Access Key</p>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_server_side_encryption","title":"aws_server_side_encryption  <code>instance-attribute</code>","text":"<pre><code>aws_server_side_encryption: str\n</code></pre> <p>Type of encryption to use.</p> <p>If set, must be one of:</p> <ul> <li><code>\"AES256\"</code> (SSE-S3)</li> <li><code>\"aws:kms\"</code> (SSE-KMS)</li> <li><code>\"aws:kms:dsse\"</code> (DSSE-KMS)</li> <li><code>\"sse-c\"</code></li> </ul>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_session_token","title":"aws_session_token  <code>instance-attribute</code>","text":"<pre><code>aws_session_token: str\n</code></pre> <p>Token to use for requests (passed to underlying provider)</p>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_skip_signature","title":"aws_skip_signature  <code>instance-attribute</code>","text":"<pre><code>aws_skip_signature: bool\n</code></pre> <p>If <code>True</code>, S3Store will not fetch credentials and will not sign requests.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_sse_bucket_key_enabled","title":"aws_sse_bucket_key_enabled  <code>instance-attribute</code>","text":"<pre><code>aws_sse_bucket_key_enabled: bool\n</code></pre> <p>If set to <code>True</code>, will use the bucket's default KMS key for server-side encryption. If set to <code>False</code>, will disable the use of the bucket's default KMS key for server-side encryption.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_sse_customer_key_base64","title":"aws_sse_customer_key_base64  <code>instance-attribute</code>","text":"<pre><code>aws_sse_customer_key_base64: str\n</code></pre> <p>The base64 encoded, 256-bit customer encryption key to use for server-side encryption. If set, the server side encryption config value must be <code>\"sse-c\"</code>.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_sse_kms_key_id","title":"aws_sse_kms_key_id  <code>instance-attribute</code>","text":"<pre><code>aws_sse_kms_key_id: str\n</code></pre> <p>The KMS key ID to use for server-side encryption.</p> <p>If set, the server side encryption config value must be <code>\"aws:kms\"</code> or <code>\"aws:kms:dsse\"</code>.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_token","title":"aws_token  <code>instance-attribute</code>","text":"<pre><code>aws_token: str\n</code></pre> <p>Token to use for requests (passed to underlying provider)</p>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_unsigned_payload","title":"aws_unsigned_payload  <code>instance-attribute</code>","text":"<pre><code>aws_unsigned_payload: bool\n</code></pre> <p>Avoid computing payload checksum when calculating signature.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.aws_virtual_hosted_style_request","title":"aws_virtual_hosted_style_request  <code>instance-attribute</code>","text":"<pre><code>aws_virtual_hosted_style_request: bool\n</code></pre> <p>If virtual hosted style request has to be used.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.bucket_name","title":"bucket_name  <code>instance-attribute</code>","text":"<pre><code>bucket_name: str\n</code></pre> <p>Bucket name</p>"},{"location":"api/store/aws/#obstore.store.S3Config.checksum_algorithm","title":"checksum_algorithm  <code>instance-attribute</code>","text":"<pre><code>checksum_algorithm: str\n</code></pre> <p>Sets the checksum algorithm which has to be used for object integrity check during upload.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.conditional_put","title":"conditional_put  <code>instance-attribute</code>","text":"<pre><code>conditional_put: str\n</code></pre> <p>Configure how to provide conditional put support</p> <p>Supported values:</p> <ul> <li> <p><code>\"etag\"</code>: Supported for S3-compatible stores that support conditional     put using the standard HTTP precondition headers <code>If-Match</code> and     <code>If-None-Match</code>.</p> </li> <li> <p><code>\"dynamo:&lt;TABLE_NAME&gt;\"</code> or <code>\"dynamo:&lt;TABLE_NAME&gt;:&lt;TIMEOUT_MILLIS&gt;\"</code>: The name of a DynamoDB table to use for coordination.</p> <p>This will use the same region, credentials and endpoint as configured for S3.</p> </li> </ul>"},{"location":"api/store/aws/#obstore.store.S3Config.copy_if_not_exists","title":"copy_if_not_exists  <code>instance-attribute</code>","text":"<pre><code>copy_if_not_exists: str\n</code></pre> <p>Configure how to provide \"copy if not exists\".</p> <p>Supported values:</p> <ul> <li> <p><code>\"multipart\"</code>:</p> <p>Native Amazon S3 supports copy if not exists through a multipart upload where the upload copies an existing object and is completed only if the new object does not already exist.</p> <p>Warning</p> <p>When using this mode, <code>copy_if_not_exists</code> does not copy tags or attributes from the source object.</p> <p>Warning</p> <p>When using this mode, <code>copy_if_not_exists</code> makes only a best effort attempt to clean up the multipart upload if the copy operation fails. Consider using a lifecycle rule to automatically clean up abandoned multipart uploads.</p> </li> <li> <p><code>\"header:&lt;HEADER_NAME&gt;:&lt;HEADER_VALUE&gt;\"</code>:</p> <p>Some S3-compatible stores, such as Cloudflare R2, support copy if not exists semantics through custom headers.</p> <p>If set, <code>copy_if_not_exists</code> will perform a normal copy operation with the provided header pair, and expect the store to fail with <code>412 Precondition Failed</code> if the destination file already exists.</p> <p>For example <code>header: cf-copy-destination-if-none-match: *</code>, would set the header <code>cf-copy-destination-if-none-match</code> to <code>*</code>.</p> </li> <li> <p><code>\"header-with-status:&lt;HEADER_NAME&gt;:&lt;HEADER_VALUE&gt;:&lt;STATUS&gt;\"</code>:</p> <p>The same as the header variant above but allows custom status code checking, for object stores that return values other than 412.</p> </li> <li> <p><code>\"dynamo:&lt;TABLE_NAME&gt;\"</code> or <code>\"dynamo:&lt;TABLE_NAME&gt;:&lt;TIMEOUT_MILLIS&gt;\"</code>:</p> <p>The name of a DynamoDB table to use for coordination.</p> <p>The default timeout is used if not specified. This will use the same region, credentials and endpoint as configured for S3.</p> </li> </ul>"},{"location":"api/store/aws/#obstore.store.S3Config.default_region","title":"default_region  <code>instance-attribute</code>","text":"<pre><code>default_region: str\n</code></pre> <p>Default region</p>"},{"location":"api/store/aws/#obstore.store.S3Config.disable_tagging","title":"disable_tagging  <code>instance-attribute</code>","text":"<pre><code>disable_tagging: bool\n</code></pre> <p>Disable tagging objects. This can be desirable if not supported by the backing store.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.endpoint","title":"endpoint  <code>instance-attribute</code>","text":"<pre><code>endpoint: str\n</code></pre> <p>Sets custom endpoint for communicating with AWS S3.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.endpoint_url","title":"endpoint_url  <code>instance-attribute</code>","text":"<pre><code>endpoint_url: str\n</code></pre> <p>Sets custom endpoint for communicating with AWS S3.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.imdsv1_fallback","title":"imdsv1_fallback  <code>instance-attribute</code>","text":"<pre><code>imdsv1_fallback: str\n</code></pre> <p>Fall back to ImdsV1</p>"},{"location":"api/store/aws/#obstore.store.S3Config.metadata_endpoint","title":"metadata_endpoint  <code>instance-attribute</code>","text":"<pre><code>metadata_endpoint: str\n</code></pre> <p>Set the instance metadata endpoint</p>"},{"location":"api/store/aws/#obstore.store.S3Config.region","title":"region  <code>instance-attribute</code>","text":"<pre><code>region: str\n</code></pre> <p>Region</p>"},{"location":"api/store/aws/#obstore.store.S3Config.request_payer","title":"request_payer  <code>instance-attribute</code>","text":"<pre><code>request_payer: bool\n</code></pre> <p>If <code>True</code>, enable operations on requester-pays buckets.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.s3_express","title":"s3_express  <code>instance-attribute</code>","text":"<pre><code>s3_express: bool\n</code></pre> <p>Enable Support for S3 Express One Zone</p>"},{"location":"api/store/aws/#obstore.store.S3Config.secret_access_key","title":"secret_access_key  <code>instance-attribute</code>","text":"<pre><code>secret_access_key: str\n</code></pre> <p>Secret Access Key</p>"},{"location":"api/store/aws/#obstore.store.S3Config.session_token","title":"session_token  <code>instance-attribute</code>","text":"<pre><code>session_token: str\n</code></pre> <p>Token to use for requests (passed to underlying provider)</p>"},{"location":"api/store/aws/#obstore.store.S3Config.skip_signature","title":"skip_signature  <code>instance-attribute</code>","text":"<pre><code>skip_signature: bool\n</code></pre> <p>If <code>True</code>, S3Store will not fetch credentials and will not sign requests.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.token","title":"token  <code>instance-attribute</code>","text":"<pre><code>token: str\n</code></pre> <p>Token to use for requests (passed to underlying provider)</p>"},{"location":"api/store/aws/#obstore.store.S3Config.unsigned_payload","title":"unsigned_payload  <code>instance-attribute</code>","text":"<pre><code>unsigned_payload: bool\n</code></pre> <p>Avoid computing payload checksum when calculating signature.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.virtual_hosted_style_request","title":"virtual_hosted_style_request  <code>instance-attribute</code>","text":"<pre><code>virtual_hosted_style_request: bool\n</code></pre> <p>If virtual hosted style request has to be used.</p>"},{"location":"api/store/azure/","title":"Microsoft Azure","text":""},{"location":"api/store/azure/#obstore.store.AzureStore","title":"obstore.store.AzureStore","text":"<p>Configure a connection to Microsoft Azure Blob Storage container using the specified credentials.</p>"},{"location":"api/store/azure/#obstore.store.AzureStore.__init__","title":"__init__","text":"<pre><code>__init__(\n    container: str,\n    *,\n    config: AzureConfig | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    **kwargs: Unpack[AzureConfig],\n) -&gt; None\n</code></pre> <p>Construct a new AzureStore.</p> <p>Parameters:</p> <ul> <li> <code>container</code>               (<code>str</code>)           \u2013            <p>description</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>config</code>               (<code>AzureConfig | None</code>)           \u2013            <p>Azure Configuration. Values in this config will override values inferred from the url. Defaults to None.</p> </li> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>AzureStore</p> </li> </ul>"},{"location":"api/store/azure/#obstore.store.AzureStore.from_env","title":"from_env  <code>classmethod</code>","text":"<pre><code>from_env(\n    container: str,\n    *,\n    config: AzureConfig | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    **kwargs: Unpack[AzureConfig],\n) -&gt; AzureStore\n</code></pre> <p>Construct a new AzureStore with values pre-populated from environment variables.</p> <p>Variables extracted from environment:</p> <ul> <li><code>AZURE_STORAGE_ACCOUNT_NAME</code>: storage account name</li> <li><code>AZURE_STORAGE_ACCOUNT_KEY</code>: storage account master key</li> <li><code>AZURE_STORAGE_ACCESS_KEY</code>: alias for <code>AZURE_STORAGE_ACCOUNT_KEY</code></li> <li><code>AZURE_STORAGE_CLIENT_ID</code> -&gt; client id for service principal authorization</li> <li><code>AZURE_STORAGE_CLIENT_SECRET</code> -&gt; client secret for service principal authorization</li> <li><code>AZURE_STORAGE_TENANT_ID</code> -&gt; tenant id used in oauth flows</li> </ul> <p>Parameters:</p> <ul> <li> <code>container</code>               (<code>str</code>)           \u2013            <p>description</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>config</code>               (<code>AzureConfig | None</code>)           \u2013            <p>Azure Configuration. Values in this config will override values inferred from the url. Defaults to None.</p> </li> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>AzureStore</code>           \u2013            <p>AzureStore</p> </li> </ul>"},{"location":"api/store/azure/#obstore.store.AzureStore.from_url","title":"from_url  <code>classmethod</code>","text":"<pre><code>from_url(\n    url: str,\n    *,\n    config: AzureConfig | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    **kwargs: Unpack[AzureConfig],\n) -&gt; AzureStore\n</code></pre> <p>Construct a new AzureStore with values populated from a well-known storage URL.</p> <p>The supported url schemes are:</p> <ul> <li><code>abfs[s]://&lt;container&gt;/&lt;path&gt;</code> (according to fsspec)</li> <li><code>abfs[s]://&lt;file_system&gt;@&lt;account_name&gt;.dfs.core.windows.net/&lt;path&gt;</code></li> <li><code>abfs[s]://&lt;file_system&gt;@&lt;account_name&gt;.dfs.fabric.microsoft.com/&lt;path&gt;</code></li> <li><code>az://&lt;container&gt;/&lt;path&gt;</code> (according to fsspec)</li> <li><code>adl://&lt;container&gt;/&lt;path&gt;</code> (according to fsspec)</li> <li><code>azure://&lt;container&gt;/&lt;path&gt;</code> (custom)</li> <li><code>https://&lt;account&gt;.dfs.core.windows.net</code></li> <li><code>https://&lt;account&gt;.blob.core.windows.net</code></li> <li><code>https://&lt;account&gt;.blob.core.windows.net/&lt;container&gt;</code></li> <li><code>https://&lt;account&gt;.dfs.fabric.microsoft.com</code></li> <li><code>https://&lt;account&gt;.dfs.fabric.microsoft.com/&lt;container&gt;</code></li> <li><code>https://&lt;account&gt;.blob.fabric.microsoft.com</code></li> <li><code>https://&lt;account&gt;.blob.fabric.microsoft.com/&lt;container&gt;</code></li> </ul> <p>Note</p> <p>Note that <code>from_url</code> will not use any additional parts of the path as a bucket prefix. It will only extract the container name, account name, and whether it's a fabric endpoint. If you wish to use a path prefix, consider wrapping this with <code>PrefixStore</code>.</p> <p>Parameters:</p> <ul> <li> <code>url</code>               (<code>str</code>)           \u2013            <p>well-known storage URL.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>config</code>               (<code>AzureConfig | None</code>)           \u2013            <p>Azure Configuration. Values in this config will override values inferred from the url. Defaults to None.</p> </li> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>AzureStore</code>           \u2013            <p>AzureStore</p> </li> </ul>"},{"location":"api/store/azure/#obstore.store.AzureConfig","title":"obstore.store.AzureConfig","text":"<p>               Bases: <code>TypedDict</code></p> <p>Configuration parameters for AzureStore.</p> <p>There are duplicates of many parameters, and parameters can be either upper or lower case. Not all parameters are required.</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.ACCESS_KEY","title":"ACCESS_KEY  <code>instance-attribute</code>","text":"<pre><code>ACCESS_KEY: str\n</code></pre> <p>Master key for accessing storage account</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.ACCOUNT_KEY","title":"ACCOUNT_KEY  <code>instance-attribute</code>","text":"<pre><code>ACCOUNT_KEY: str\n</code></pre> <p>Master key for accessing storage account</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.ACCOUNT_NAME","title":"ACCOUNT_NAME  <code>instance-attribute</code>","text":"<pre><code>ACCOUNT_NAME: str\n</code></pre> <p>The name of the azure storage account</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AUTHORITY_ID","title":"AUTHORITY_ID  <code>instance-attribute</code>","text":"<pre><code>AUTHORITY_ID: str\n</code></pre> <p>Tenant id used in oauth flows</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_AUTHORITY_ID","title":"AZURE_AUTHORITY_ID  <code>instance-attribute</code>","text":"<pre><code>AZURE_AUTHORITY_ID: str\n</code></pre> <p>Tenant id used in oauth flows</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_CLIENT_ID","title":"AZURE_CLIENT_ID  <code>instance-attribute</code>","text":"<pre><code>AZURE_CLIENT_ID: str\n</code></pre> <p>Service principal client id for authorizing requests</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_CLIENT_SECRET","title":"AZURE_CLIENT_SECRET  <code>instance-attribute</code>","text":"<pre><code>AZURE_CLIENT_SECRET: str\n</code></pre> <p>Service principal client secret for authorizing requests</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_CONTAINER_NAME","title":"AZURE_CONTAINER_NAME  <code>instance-attribute</code>","text":"<pre><code>AZURE_CONTAINER_NAME: str\n</code></pre> <p>Container name</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_DISABLE_TAGGING","title":"AZURE_DISABLE_TAGGING  <code>instance-attribute</code>","text":"<pre><code>AZURE_DISABLE_TAGGING: bool\n</code></pre> <p>Disables tagging objects</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_ENDPOINT","title":"AZURE_ENDPOINT  <code>instance-attribute</code>","text":"<pre><code>AZURE_ENDPOINT: str\n</code></pre> <p>Override the endpoint used to communicate with blob storage</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_FEDERATED_TOKEN_FILE","title":"AZURE_FEDERATED_TOKEN_FILE  <code>instance-attribute</code>","text":"<pre><code>AZURE_FEDERATED_TOKEN_FILE: str\n</code></pre> <p>File containing token for Azure AD workload identity federation</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_IDENTITY_ENDPOINT","title":"AZURE_IDENTITY_ENDPOINT  <code>instance-attribute</code>","text":"<pre><code>AZURE_IDENTITY_ENDPOINT: str\n</code></pre> <p>Endpoint to request a imds managed identity token</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_MSI_ENDPOINT","title":"AZURE_MSI_ENDPOINT  <code>instance-attribute</code>","text":"<pre><code>AZURE_MSI_ENDPOINT: str\n</code></pre> <p>Endpoint to request a imds managed identity token</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_MSI_RESOURCE_ID","title":"AZURE_MSI_RESOURCE_ID  <code>instance-attribute</code>","text":"<pre><code>AZURE_MSI_RESOURCE_ID: str\n</code></pre> <p>Msi resource id for use with managed identity authentication</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_OBJECT_ID","title":"AZURE_OBJECT_ID  <code>instance-attribute</code>","text":"<pre><code>AZURE_OBJECT_ID: str\n</code></pre> <p>Object id for use with managed identity authentication</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_SKIP_SIGNATURE","title":"AZURE_SKIP_SIGNATURE  <code>instance-attribute</code>","text":"<pre><code>AZURE_SKIP_SIGNATURE: bool\n</code></pre> <p>Skip signing requests</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_STORAGE_ACCESS_KEY","title":"AZURE_STORAGE_ACCESS_KEY  <code>instance-attribute</code>","text":"<pre><code>AZURE_STORAGE_ACCESS_KEY: str\n</code></pre> <p>Master key for accessing storage account</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_STORAGE_ACCOUNT_KEY","title":"AZURE_STORAGE_ACCOUNT_KEY  <code>instance-attribute</code>","text":"<pre><code>AZURE_STORAGE_ACCOUNT_KEY: str\n</code></pre> <p>Master key for accessing storage account</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_STORAGE_ACCOUNT_NAME","title":"AZURE_STORAGE_ACCOUNT_NAME  <code>instance-attribute</code>","text":"<pre><code>AZURE_STORAGE_ACCOUNT_NAME: str\n</code></pre> <p>The name of the azure storage account</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_STORAGE_AUTHORITY_ID","title":"AZURE_STORAGE_AUTHORITY_ID  <code>instance-attribute</code>","text":"<pre><code>AZURE_STORAGE_AUTHORITY_ID: str\n</code></pre> <p>Tenant id used in oauth flows</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_STORAGE_CLIENT_ID","title":"AZURE_STORAGE_CLIENT_ID  <code>instance-attribute</code>","text":"<pre><code>AZURE_STORAGE_CLIENT_ID: str\n</code></pre> <p>Service principal client id for authorizing requests</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_STORAGE_CLIENT_SECRET","title":"AZURE_STORAGE_CLIENT_SECRET  <code>instance-attribute</code>","text":"<pre><code>AZURE_STORAGE_CLIENT_SECRET: str\n</code></pre> <p>Service principal client secret for authorizing requests</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_STORAGE_ENDPOINT","title":"AZURE_STORAGE_ENDPOINT  <code>instance-attribute</code>","text":"<pre><code>AZURE_STORAGE_ENDPOINT: str\n</code></pre> <p>Override the endpoint used to communicate with blob storage</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_STORAGE_MASTER_KEY","title":"AZURE_STORAGE_MASTER_KEY  <code>instance-attribute</code>","text":"<pre><code>AZURE_STORAGE_MASTER_KEY: str\n</code></pre> <p>Master key for accessing storage account</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_STORAGE_SAS_KEY","title":"AZURE_STORAGE_SAS_KEY  <code>instance-attribute</code>","text":"<pre><code>AZURE_STORAGE_SAS_KEY: str\n</code></pre> <p>Shared access signature.</p> <p>The signature is expected to be percent-encoded, <code>much</code>like they are provided in the azure storage explorer or azure portal.</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_STORAGE_SAS_TOKEN","title":"AZURE_STORAGE_SAS_TOKEN  <code>instance-attribute</code>","text":"<pre><code>AZURE_STORAGE_SAS_TOKEN: str\n</code></pre> <p>Shared access signature.</p> <p>The signature is expected to be percent-encoded, <code>much</code>like they are provided in the azure storage explorer or azure portal.</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_STORAGE_TENANT_ID","title":"AZURE_STORAGE_TENANT_ID  <code>instance-attribute</code>","text":"<pre><code>AZURE_STORAGE_TENANT_ID: str\n</code></pre> <p>Tenant id used in oauth flows</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_STORAGE_TOKEN","title":"AZURE_STORAGE_TOKEN  <code>instance-attribute</code>","text":"<pre><code>AZURE_STORAGE_TOKEN: str\n</code></pre> <p>Bearer token</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_STORAGE_USE_EMULATOR","title":"AZURE_STORAGE_USE_EMULATOR  <code>instance-attribute</code>","text":"<pre><code>AZURE_STORAGE_USE_EMULATOR: bool\n</code></pre> <p>Use object store with azurite storage emulator</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_TENANT_ID","title":"AZURE_TENANT_ID  <code>instance-attribute</code>","text":"<pre><code>AZURE_TENANT_ID: str\n</code></pre> <p>Tenant id used in oauth flows</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_USE_AZURE_CLI","title":"AZURE_USE_AZURE_CLI  <code>instance-attribute</code>","text":"<pre><code>AZURE_USE_AZURE_CLI: bool\n</code></pre> <p>Use azure cli for acquiring access token</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.AZURE_USE_FABRIC_ENDPOINT","title":"AZURE_USE_FABRIC_ENDPOINT  <code>instance-attribute</code>","text":"<pre><code>AZURE_USE_FABRIC_ENDPOINT: bool\n</code></pre> <p>Use object store with url scheme account.dfs.fabric.microsoft.com</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.BEARER_TOKEN","title":"BEARER_TOKEN  <code>instance-attribute</code>","text":"<pre><code>BEARER_TOKEN: str\n</code></pre> <p>Bearer token</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.CLIENT_ID","title":"CLIENT_ID  <code>instance-attribute</code>","text":"<pre><code>CLIENT_ID: str\n</code></pre> <p>Service principal client id for authorizing requests</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.CLIENT_SECRET","title":"CLIENT_SECRET  <code>instance-attribute</code>","text":"<pre><code>CLIENT_SECRET: str\n</code></pre> <p>Service principal client secret for authorizing requests</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.CONTAINER_NAME","title":"CONTAINER_NAME  <code>instance-attribute</code>","text":"<pre><code>CONTAINER_NAME: str\n</code></pre> <p>Container name</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.DISABLE_TAGGING","title":"DISABLE_TAGGING  <code>instance-attribute</code>","text":"<pre><code>DISABLE_TAGGING: bool\n</code></pre> <p>Disables tagging objects</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.ENDPOINT","title":"ENDPOINT  <code>instance-attribute</code>","text":"<pre><code>ENDPOINT: str\n</code></pre> <p>Override the endpoint used to communicate with blob storage</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.FEDERATED_TOKEN_FILE","title":"FEDERATED_TOKEN_FILE  <code>instance-attribute</code>","text":"<pre><code>FEDERATED_TOKEN_FILE: str\n</code></pre> <p>File containing token for Azure AD workload identity federation</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.IDENTITY_ENDPOINT","title":"IDENTITY_ENDPOINT  <code>instance-attribute</code>","text":"<pre><code>IDENTITY_ENDPOINT: str\n</code></pre> <p>Endpoint to request a imds managed identity token</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.MASTER_KEY","title":"MASTER_KEY  <code>instance-attribute</code>","text":"<pre><code>MASTER_KEY: str\n</code></pre> <p>Master key for accessing storage account</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.MSI_ENDPOINT","title":"MSI_ENDPOINT  <code>instance-attribute</code>","text":"<pre><code>MSI_ENDPOINT: str\n</code></pre> <p>Endpoint to request a imds managed identity token</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.MSI_RESOURCE_ID","title":"MSI_RESOURCE_ID  <code>instance-attribute</code>","text":"<pre><code>MSI_RESOURCE_ID: str\n</code></pre> <p>Msi resource id for use with managed identity authentication</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.OBJECT_ID","title":"OBJECT_ID  <code>instance-attribute</code>","text":"<pre><code>OBJECT_ID: str\n</code></pre> <p>Object id for use with managed identity authentication</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.SAS_KEY","title":"SAS_KEY  <code>instance-attribute</code>","text":"<pre><code>SAS_KEY: str\n</code></pre> <p>Shared access signature.</p> <p>The signature is expected to be percent-encoded, <code>much</code>like they are provided in the azure storage explorer or azure portal.</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.SAS_TOKEN","title":"SAS_TOKEN  <code>instance-attribute</code>","text":"<pre><code>SAS_TOKEN: str\n</code></pre> <p>Shared access signature.</p> <p>The signature is expected to be percent-encoded, <code>much</code>like they are provided in the azure storage explorer or azure portal.</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.SKIP_SIGNATURE","title":"SKIP_SIGNATURE  <code>instance-attribute</code>","text":"<pre><code>SKIP_SIGNATURE: bool\n</code></pre> <p>Skip signing requests</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.TENANT_ID","title":"TENANT_ID  <code>instance-attribute</code>","text":"<pre><code>TENANT_ID: str\n</code></pre> <p>Tenant id used in oauth flows</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.TOKEN","title":"TOKEN  <code>instance-attribute</code>","text":"<pre><code>TOKEN: str\n</code></pre> <p>Bearer token</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.USE_AZURE_CLI","title":"USE_AZURE_CLI  <code>instance-attribute</code>","text":"<pre><code>USE_AZURE_CLI: bool\n</code></pre> <p>Use azure cli for acquiring access token</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.USE_EMULATOR","title":"USE_EMULATOR  <code>instance-attribute</code>","text":"<pre><code>USE_EMULATOR: bool\n</code></pre> <p>Use object store with azurite storage emulator</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.USE_FABRIC_ENDPOINT","title":"USE_FABRIC_ENDPOINT  <code>instance-attribute</code>","text":"<pre><code>USE_FABRIC_ENDPOINT: bool\n</code></pre> <p>Use object store with url scheme account.dfs.fabric.microsoft.com</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.access_key","title":"access_key  <code>instance-attribute</code>","text":"<pre><code>access_key: str\n</code></pre> <p>Master key for accessing storage account</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.account_key","title":"account_key  <code>instance-attribute</code>","text":"<pre><code>account_key: str\n</code></pre> <p>Master key for accessing storage account</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.account_name","title":"account_name  <code>instance-attribute</code>","text":"<pre><code>account_name: str\n</code></pre> <p>The name of the azure storage account</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.authority_id","title":"authority_id  <code>instance-attribute</code>","text":"<pre><code>authority_id: str\n</code></pre> <p>Tenant id used in oauth flows</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_authority_id","title":"azure_authority_id  <code>instance-attribute</code>","text":"<pre><code>azure_authority_id: str\n</code></pre> <p>Tenant id used in oauth flows</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_client_id","title":"azure_client_id  <code>instance-attribute</code>","text":"<pre><code>azure_client_id: str\n</code></pre> <p>Service principal client id for authorizing requests</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_client_secret","title":"azure_client_secret  <code>instance-attribute</code>","text":"<pre><code>azure_client_secret: str\n</code></pre> <p>Service principal client secret for authorizing requests</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_container_name","title":"azure_container_name  <code>instance-attribute</code>","text":"<pre><code>azure_container_name: str\n</code></pre> <p>Container name</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_disable_tagging","title":"azure_disable_tagging  <code>instance-attribute</code>","text":"<pre><code>azure_disable_tagging: bool\n</code></pre> <p>Disables tagging objects</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_endpoint","title":"azure_endpoint  <code>instance-attribute</code>","text":"<pre><code>azure_endpoint: str\n</code></pre> <p>Override the endpoint used to communicate with blob storage</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_federated_token_file","title":"azure_federated_token_file  <code>instance-attribute</code>","text":"<pre><code>azure_federated_token_file: str\n</code></pre> <p>File containing token for Azure AD workload identity federation</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_identity_endpoint","title":"azure_identity_endpoint  <code>instance-attribute</code>","text":"<pre><code>azure_identity_endpoint: str\n</code></pre> <p>Endpoint to request a imds managed identity token</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_msi_endpoint","title":"azure_msi_endpoint  <code>instance-attribute</code>","text":"<pre><code>azure_msi_endpoint: str\n</code></pre> <p>Endpoint to request a imds managed identity token</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_msi_resource_id","title":"azure_msi_resource_id  <code>instance-attribute</code>","text":"<pre><code>azure_msi_resource_id: str\n</code></pre> <p>Msi resource id for use with managed identity authentication</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_object_id","title":"azure_object_id  <code>instance-attribute</code>","text":"<pre><code>azure_object_id: str\n</code></pre> <p>Object id for use with managed identity authentication</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_skip_signature","title":"azure_skip_signature  <code>instance-attribute</code>","text":"<pre><code>azure_skip_signature: bool\n</code></pre> <p>Skip signing requests</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_storage_access_key","title":"azure_storage_access_key  <code>instance-attribute</code>","text":"<pre><code>azure_storage_access_key: str\n</code></pre> <p>Master key for accessing storage account</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_storage_account_key","title":"azure_storage_account_key  <code>instance-attribute</code>","text":"<pre><code>azure_storage_account_key: str\n</code></pre> <p>Master key for accessing storage account</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_storage_account_name","title":"azure_storage_account_name  <code>instance-attribute</code>","text":"<pre><code>azure_storage_account_name: str\n</code></pre> <p>The name of the azure storage account</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_storage_authority_id","title":"azure_storage_authority_id  <code>instance-attribute</code>","text":"<pre><code>azure_storage_authority_id: str\n</code></pre> <p>Tenant id used in oauth flows</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_storage_client_id","title":"azure_storage_client_id  <code>instance-attribute</code>","text":"<pre><code>azure_storage_client_id: str\n</code></pre> <p>Service principal client id for authorizing requests</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_storage_client_secret","title":"azure_storage_client_secret  <code>instance-attribute</code>","text":"<pre><code>azure_storage_client_secret: str\n</code></pre> <p>Service principal client secret for authorizing requests</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_storage_endpoint","title":"azure_storage_endpoint  <code>instance-attribute</code>","text":"<pre><code>azure_storage_endpoint: str\n</code></pre> <p>Override the endpoint used to communicate with blob storage</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_storage_master_key","title":"azure_storage_master_key  <code>instance-attribute</code>","text":"<pre><code>azure_storage_master_key: str\n</code></pre> <p>Master key for accessing storage account</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_storage_sas_key","title":"azure_storage_sas_key  <code>instance-attribute</code>","text":"<pre><code>azure_storage_sas_key: str\n</code></pre> <p>Shared access signature.</p> <p>The signature is expected to be percent-encoded, <code>much</code>like they are provided in the azure storage explorer or azure portal.</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_storage_sas_token","title":"azure_storage_sas_token  <code>instance-attribute</code>","text":"<pre><code>azure_storage_sas_token: str\n</code></pre> <p>Shared access signature.</p> <p>The signature is expected to be percent-encoded, <code>much</code>like they are provided in the azure storage explorer or azure portal.</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_storage_tenant_id","title":"azure_storage_tenant_id  <code>instance-attribute</code>","text":"<pre><code>azure_storage_tenant_id: str\n</code></pre> <p>Tenant id used in oauth flows</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_storage_token","title":"azure_storage_token  <code>instance-attribute</code>","text":"<pre><code>azure_storage_token: str\n</code></pre> <p>Bearer token</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_storage_use_emulator","title":"azure_storage_use_emulator  <code>instance-attribute</code>","text":"<pre><code>azure_storage_use_emulator: bool\n</code></pre> <p>Use object store with azurite storage emulator</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_tenant_id","title":"azure_tenant_id  <code>instance-attribute</code>","text":"<pre><code>azure_tenant_id: str\n</code></pre> <p>Tenant id used in oauth flows</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_use_azure_cli","title":"azure_use_azure_cli  <code>instance-attribute</code>","text":"<pre><code>azure_use_azure_cli: bool\n</code></pre> <p>Use azure cli for acquiring access token</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.azure_use_fabric_endpoint","title":"azure_use_fabric_endpoint  <code>instance-attribute</code>","text":"<pre><code>azure_use_fabric_endpoint: bool\n</code></pre> <p>Use object store with url scheme account.dfs.fabric.microsoft.com</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.bearer_token","title":"bearer_token  <code>instance-attribute</code>","text":"<pre><code>bearer_token: str\n</code></pre> <p>Bearer token</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.client_id","title":"client_id  <code>instance-attribute</code>","text":"<pre><code>client_id: str\n</code></pre> <p>Service principal client id for authorizing requests</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.client_secret","title":"client_secret  <code>instance-attribute</code>","text":"<pre><code>client_secret: str\n</code></pre> <p>Service principal client secret for authorizing requests</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.container_name","title":"container_name  <code>instance-attribute</code>","text":"<pre><code>container_name: str\n</code></pre> <p>Container name</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.disable_tagging","title":"disable_tagging  <code>instance-attribute</code>","text":"<pre><code>disable_tagging: bool\n</code></pre> <p>Disables tagging objects</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.endpoint","title":"endpoint  <code>instance-attribute</code>","text":"<pre><code>endpoint: str\n</code></pre> <p>Override the endpoint used to communicate with blob storage</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.federated_token_file","title":"federated_token_file  <code>instance-attribute</code>","text":"<pre><code>federated_token_file: str\n</code></pre> <p>File containing token for Azure AD workload identity federation</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.identity_endpoint","title":"identity_endpoint  <code>instance-attribute</code>","text":"<pre><code>identity_endpoint: str\n</code></pre> <p>Endpoint to request a imds managed identity token</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.master_key","title":"master_key  <code>instance-attribute</code>","text":"<pre><code>master_key: str\n</code></pre> <p>Master key for accessing storage account</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.msi_endpoint","title":"msi_endpoint  <code>instance-attribute</code>","text":"<pre><code>msi_endpoint: str\n</code></pre> <p>Endpoint to request a imds managed identity token</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.msi_resource_id","title":"msi_resource_id  <code>instance-attribute</code>","text":"<pre><code>msi_resource_id: str\n</code></pre> <p>Msi resource id for use with managed identity authentication</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.object_id","title":"object_id  <code>instance-attribute</code>","text":"<pre><code>object_id: str\n</code></pre> <p>Object id for use with managed identity authentication</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.sas_key","title":"sas_key  <code>instance-attribute</code>","text":"<pre><code>sas_key: str\n</code></pre> <p>Shared access signature.</p> <p>The signature is expected to be percent-encoded, <code>much</code>like they are provided in the azure storage explorer or azure portal.</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.sas_token","title":"sas_token  <code>instance-attribute</code>","text":"<pre><code>sas_token: str\n</code></pre> <p>Shared access signature.</p> <p>The signature is expected to be percent-encoded, <code>much</code>like they are provided in the azure storage explorer or azure portal.</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.skip_signature","title":"skip_signature  <code>instance-attribute</code>","text":"<pre><code>skip_signature: bool\n</code></pre> <p>Skip signing requests</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.tenant_id","title":"tenant_id  <code>instance-attribute</code>","text":"<pre><code>tenant_id: str\n</code></pre> <p>Tenant id used in oauth flows</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.token","title":"token  <code>instance-attribute</code>","text":"<pre><code>token: str\n</code></pre> <p>Bearer token</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.use_azure_cli","title":"use_azure_cli  <code>instance-attribute</code>","text":"<pre><code>use_azure_cli: bool\n</code></pre> <p>Use azure cli for acquiring access token</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.use_emulator","title":"use_emulator  <code>instance-attribute</code>","text":"<pre><code>use_emulator: bool\n</code></pre> <p>Use object store with azurite storage emulator</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.use_fabric_endpoint","title":"use_fabric_endpoint  <code>instance-attribute</code>","text":"<pre><code>use_fabric_endpoint: bool\n</code></pre> <p>Use object store with url scheme account.dfs.fabric.microsoft.com</p>"},{"location":"api/store/config/","title":"Configuration","text":""},{"location":"api/store/config/#obstore.store.ClientConfig","title":"obstore.store.ClientConfig","text":"<p>               Bases: <code>TypedDict</code></p> <p>HTTP client configuration</p> <p>For timeout values (<code>connect_timeout</code>, <code>http2_keep_alive_timeout</code>, <code>pool_idle_timeout</code>, and <code>timeout</code>), values can either be Python <code>timedelta</code> objects, or they can be \"human-readable duration strings\".</p> <p>The human-readable duration string is a concatenation of time spans. Where each time span is an integer number and a suffix. Supported suffixes:</p> <ul> <li><code>nsec</code>, <code>ns</code> -- nanoseconds</li> <li><code>usec</code>, <code>us</code> -- microseconds</li> <li><code>msec</code>, <code>ms</code> -- milliseconds</li> <li><code>seconds</code>, <code>second</code>, <code>sec</code>, <code>s</code></li> <li><code>minutes</code>, <code>minute</code>, <code>min</code>, <code>m</code></li> <li><code>hours</code>, <code>hour</code>, <code>hr</code>, <code>h</code></li> <li><code>days</code>, <code>day</code>, <code>d</code></li> <li><code>weeks</code>, <code>week</code>, <code>w</code></li> <li><code>months</code>, <code>month</code>, <code>M</code> -- defined as 30.44 days</li> <li><code>years</code>, <code>year</code>, <code>y</code> -- defined as 365.25 days</li> </ul> <p>For example:</p> <ul> <li><code>\"2h 37min\"</code></li> <li><code>\"32ms\"</code></li> </ul>"},{"location":"api/store/config/#obstore.store.ClientConfig.allow_http","title":"allow_http  <code>instance-attribute</code>","text":"<pre><code>allow_http: bool\n</code></pre> <p>Allow non-TLS, i.e. non-HTTPS connections.</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.allow_invalid_certificates","title":"allow_invalid_certificates  <code>instance-attribute</code>","text":"<pre><code>allow_invalid_certificates: bool\n</code></pre> <p>Skip certificate validation on https connections.</p> <p>Warning</p> <p>You should think very carefully before using this method. If invalid certificates are trusted, any certificate for any site will be trusted for use. This includes expired certificates. This introduces significant vulnerabilities, and should only be used as a last resort or for testing</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.connect_timeout","title":"connect_timeout  <code>instance-attribute</code>","text":"<pre><code>connect_timeout: str | timedelta\n</code></pre> <p>Timeout for only the connect phase of a Client</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.default_content_type","title":"default_content_type  <code>instance-attribute</code>","text":"<pre><code>default_content_type: str\n</code></pre> <p>default <code>CONTENT_TYPE</code> for uploads</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.http1_only","title":"http1_only  <code>instance-attribute</code>","text":"<pre><code>http1_only: bool\n</code></pre> <p>Only use http1 connections.</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.http2_keep_alive_interval","title":"http2_keep_alive_interval  <code>instance-attribute</code>","text":"<pre><code>http2_keep_alive_interval: str\n</code></pre> <p>Interval for HTTP2 Ping frames should be sent to keep a connection alive.</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.http2_keep_alive_timeout","title":"http2_keep_alive_timeout  <code>instance-attribute</code>","text":"<pre><code>http2_keep_alive_timeout: str | timedelta\n</code></pre> <p>Timeout for receiving an acknowledgement of the keep-alive ping.</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.http2_keep_alive_while_idle","title":"http2_keep_alive_while_idle  <code>instance-attribute</code>","text":"<pre><code>http2_keep_alive_while_idle: str\n</code></pre> <p>Enable HTTP2 keep alive pings for idle connections</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.http2_only","title":"http2_only  <code>instance-attribute</code>","text":"<pre><code>http2_only: bool\n</code></pre> <p>Only use http2 connections</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.pool_idle_timeout","title":"pool_idle_timeout  <code>instance-attribute</code>","text":"<pre><code>pool_idle_timeout: str | timedelta\n</code></pre> <p>The pool max idle timeout.</p> <p>This is the length of time an idle connection will be kept alive.</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.pool_max_idle_per_host","title":"pool_max_idle_per_host  <code>instance-attribute</code>","text":"<pre><code>pool_max_idle_per_host: str\n</code></pre> <p>Maximum number of idle connections per host.</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.proxy_url","title":"proxy_url  <code>instance-attribute</code>","text":"<pre><code>proxy_url: str\n</code></pre> <p>HTTP proxy to use for requests.</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.timeout","title":"timeout  <code>instance-attribute</code>","text":"<pre><code>timeout: str | timedelta\n</code></pre> <p>Request timeout.</p> <p>The timeout is applied from when the request starts connecting until the response body has finished.</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.user_agent","title":"user_agent  <code>instance-attribute</code>","text":"<pre><code>user_agent: str\n</code></pre> <p>User-Agent header to be used by this client.</p>"},{"location":"api/store/config/#obstore.store.BackoffConfig","title":"obstore.store.BackoffConfig","text":"<p>               Bases: <code>TypedDict</code></p> <p>Exponential backoff with jitter</p> <p>See aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/</p>"},{"location":"api/store/config/#obstore.store.BackoffConfig.base","title":"base  <code>instance-attribute</code>","text":"<pre><code>base: int | float\n</code></pre> <p>The base of the exponential to use</p>"},{"location":"api/store/config/#obstore.store.BackoffConfig.init_backoff","title":"init_backoff  <code>instance-attribute</code>","text":"<pre><code>init_backoff: timedelta\n</code></pre> <p>The initial backoff duration</p>"},{"location":"api/store/config/#obstore.store.BackoffConfig.max_backoff","title":"max_backoff  <code>instance-attribute</code>","text":"<pre><code>max_backoff: timedelta\n</code></pre> <p>The maximum backoff duration</p>"},{"location":"api/store/config/#obstore.store.RetryConfig","title":"obstore.store.RetryConfig","text":"<p>               Bases: <code>TypedDict</code></p> <p>The configuration for how to respond to request errors</p> <p>The following categories of error will be retried:</p> <ul> <li>5xx server errors</li> <li>Connection errors</li> <li>Dropped connections</li> <li>Timeouts for safe / read-only requests</li> </ul> <p>Requests will be retried up to some limit, using exponential backoff with jitter. See <code>BackoffConfig</code> for more information</p>"},{"location":"api/store/config/#obstore.store.RetryConfig.backoff","title":"backoff  <code>instance-attribute</code>","text":"<pre><code>backoff: BackoffConfig\n</code></pre> <p>The backoff configuration</p>"},{"location":"api/store/config/#obstore.store.RetryConfig.max_retries","title":"max_retries  <code>instance-attribute</code>","text":"<pre><code>max_retries: int\n</code></pre> <p>The maximum number of times to retry a request</p> <p>Set to 0 to disable retries</p>"},{"location":"api/store/config/#obstore.store.RetryConfig.retry_timeout","title":"retry_timeout  <code>instance-attribute</code>","text":"<pre><code>retry_timeout: timedelta\n</code></pre> <p>The maximum length of time from the initial request after which no further retries will be attempted</p> <p>This not only bounds the length of time before a server error will be surfaced to the application, but also bounds the length of time a request's credentials must remain valid.</p> <p>As requests are retried without renewing credentials or regenerating request payloads, this number should be kept below 5 minutes to avoid errors due to expired credentials and/or request payloads</p>"},{"location":"api/store/gcs/","title":"Google Cloud Storage","text":""},{"location":"api/store/gcs/#obstore.store.GCSStore","title":"obstore.store.GCSStore","text":"<p>Configure a connection to Google Cloud Storage.</p> <p>If no credentials are explicitly provided, they will be sourced from the environment as documented here.</p>"},{"location":"api/store/gcs/#obstore.store.GCSStore.__init__","title":"__init__","text":"<pre><code>__init__(\n    bucket: str,\n    *,\n    config: GCSConfig | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    **kwargs: Unpack[GCSConfig],\n) -&gt; None\n</code></pre> <p>Construct a new GCSStore.</p> <p>Parameters:</p> <ul> <li> <code>bucket</code>               (<code>str</code>)           \u2013            <p>The GCS bucket to use.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>config</code>               (<code>GCSConfig | None</code>)           \u2013            <p>GCS Configuration. Values in this config will override values inferred from the environment. Defaults to None.</p> </li> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>GCSStore</p> </li> </ul>"},{"location":"api/store/gcs/#obstore.store.GCSStore.from_env","title":"from_env  <code>classmethod</code>","text":"<pre><code>from_env(\n    bucket: str,\n    *,\n    config: GCSConfig | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    **kwargs: Unpack[GCSConfig],\n) -&gt; GCSStore\n</code></pre> <p>Construct a new GCSStore with values pre-populated from environment variables.</p> <p>Variables extracted from environment:</p> <ul> <li><code>GOOGLE_SERVICE_ACCOUNT</code>: location of service account file</li> <li><code>GOOGLE_SERVICE_ACCOUNT_PATH</code>: (alias) location of service account file</li> <li><code>SERVICE_ACCOUNT</code>: (alias) location of service account file</li> <li><code>GOOGLE_SERVICE_ACCOUNT_KEY</code>: JSON serialized service account key</li> <li><code>GOOGLE_BUCKET</code>: bucket name</li> <li><code>GOOGLE_BUCKET_NAME</code>: (alias) bucket name</li> </ul> <p>Parameters:</p> <ul> <li> <code>bucket</code>               (<code>str</code>)           \u2013            <p>The GCS bucket to use.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>config</code>               (<code>GCSConfig | None</code>)           \u2013            <p>GCS Configuration. Values in this config will override values inferred from the environment. Defaults to None.</p> </li> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>GCSStore</code>           \u2013            <p>GCSStore</p> </li> </ul>"},{"location":"api/store/gcs/#obstore.store.GCSStore.from_url","title":"from_url  <code>classmethod</code>","text":"<pre><code>from_url(\n    url: str,\n    *,\n    config: GCSConfig | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    **kwargs: Unpack[GCSConfig],\n) -&gt; GCSStore\n</code></pre> <p>Construct a new GCSStore with values populated from a well-known storage URL.</p> <p>The supported url schemes are:</p> <ul> <li><code>gs://&lt;bucket&gt;/&lt;path&gt;</code></li> </ul> <p>Note</p> <p>Note that <code>from_url</code> will not use any additional parts of the path as a bucket prefix. It will only extract the bucket name. If you wish to use a path prefix, consider wrapping this with <code>PrefixStore</code>.</p> <p>Parameters:</p> <ul> <li> <code>url</code>               (<code>str</code>)           \u2013            <p>well-known storage URL.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>config</code>               (<code>GCSConfig | None</code>)           \u2013            <p>GCS Configuration. Values in this config will override values inferred from the url. Defaults to None.</p> </li> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>GCSStore</code>           \u2013            <p>GCSStore</p> </li> </ul>"},{"location":"api/store/gcs/#obstore.store.GCSConfig","title":"obstore.store.GCSConfig","text":"<p>               Bases: <code>TypedDict</code></p> <p>Configuration parameters for GCSStore.</p> <p>There are duplicates of many parameters, and parameters can be either upper or lower case. Not all parameters are required.</p>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.BUCKET","title":"BUCKET  <code>instance-attribute</code>","text":"<pre><code>BUCKET: str\n</code></pre> <p>Bucket name.</p>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.BUCKET_NAME","title":"BUCKET_NAME  <code>instance-attribute</code>","text":"<pre><code>BUCKET_NAME: str\n</code></pre> <p>Bucket name.</p>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.GOOGLE_APPLICATION_CREDENTIALS","title":"GOOGLE_APPLICATION_CREDENTIALS  <code>instance-attribute</code>","text":"<pre><code>GOOGLE_APPLICATION_CREDENTIALS: str\n</code></pre> <p>Application credentials path.</p> <p>See cloud.google.com/docs/authentication/provide-credentials-adc.</p>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.GOOGLE_BUCKET","title":"GOOGLE_BUCKET  <code>instance-attribute</code>","text":"<pre><code>GOOGLE_BUCKET: str\n</code></pre> <p>Bucket name.</p>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.GOOGLE_BUCKET_NAME","title":"GOOGLE_BUCKET_NAME  <code>instance-attribute</code>","text":"<pre><code>GOOGLE_BUCKET_NAME: str\n</code></pre> <p>Bucket name.</p>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.GOOGLE_SERVICE_ACCOUNT","title":"GOOGLE_SERVICE_ACCOUNT  <code>instance-attribute</code>","text":"<pre><code>GOOGLE_SERVICE_ACCOUNT: str\n</code></pre> <p>Path to the service account file.</p>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.GOOGLE_SERVICE_ACCOUNT_KEY","title":"GOOGLE_SERVICE_ACCOUNT_KEY  <code>instance-attribute</code>","text":"<pre><code>GOOGLE_SERVICE_ACCOUNT_KEY: str\n</code></pre> <p>The serialized service account key</p>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.GOOGLE_SERVICE_ACCOUNT_PATH","title":"GOOGLE_SERVICE_ACCOUNT_PATH  <code>instance-attribute</code>","text":"<pre><code>GOOGLE_SERVICE_ACCOUNT_PATH: str\n</code></pre> <p>Path to the service account file.</p>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.SERVICE_ACCOUNT","title":"SERVICE_ACCOUNT  <code>instance-attribute</code>","text":"<pre><code>SERVICE_ACCOUNT: str\n</code></pre> <p>Path to the service account file.</p>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.SERVICE_ACCOUNT_KEY","title":"SERVICE_ACCOUNT_KEY  <code>instance-attribute</code>","text":"<pre><code>SERVICE_ACCOUNT_KEY: str\n</code></pre> <p>The serialized service account key</p>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.SERVICE_ACCOUNT_PATH","title":"SERVICE_ACCOUNT_PATH  <code>instance-attribute</code>","text":"<pre><code>SERVICE_ACCOUNT_PATH: str\n</code></pre> <p>Path to the service account file.</p>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.bucket_name","title":"bucket_name  <code>instance-attribute</code>","text":"<pre><code>bucket_name: str\n</code></pre> <p>Bucket name.</p>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.google_application_credentials","title":"google_application_credentials  <code>instance-attribute</code>","text":"<pre><code>google_application_credentials: str\n</code></pre> <p>Application credentials path.</p> <p>See cloud.google.com/docs/authentication/provide-credentials-adc.</p>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.google_bucket","title":"google_bucket  <code>instance-attribute</code>","text":"<pre><code>google_bucket: str\n</code></pre> <p>Bucket name.</p>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.google_bucket_name","title":"google_bucket_name  <code>instance-attribute</code>","text":"<pre><code>google_bucket_name: str\n</code></pre> <p>Bucket name.</p>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.google_service_account","title":"google_service_account  <code>instance-attribute</code>","text":"<pre><code>google_service_account: str\n</code></pre> <p>Path to the service account file.</p>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.google_service_account_key","title":"google_service_account_key  <code>instance-attribute</code>","text":"<pre><code>google_service_account_key: str\n</code></pre> <p>The serialized service account key</p>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.google_service_account_path","title":"google_service_account_path  <code>instance-attribute</code>","text":"<pre><code>google_service_account_path: str\n</code></pre> <p>Path to the service account file.</p>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.service_account","title":"service_account  <code>instance-attribute</code>","text":"<pre><code>service_account: str\n</code></pre> <p>Path to the service account file.</p>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.service_account_key","title":"service_account_key  <code>instance-attribute</code>","text":"<pre><code>service_account_key: str\n</code></pre> <p>The serialized service account key</p>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.service_account_path","title":"service_account_path  <code>instance-attribute</code>","text":"<pre><code>service_account_path: str\n</code></pre> <p>Path to the service account file.</p>"},{"location":"api/store/http/","title":"HTTP","text":""},{"location":"api/store/http/#obstore.store.HTTPStore","title":"obstore.store.HTTPStore","text":"<p>Configure a connection to a generic HTTP server</p> <p>Example</p> <p>Accessing the number of stars for a repo:</p> <pre><code>import json\n\nimport obstore as obs\nfrom obstore.store import HTTPStore\n\nstore = HTTPStore.from_url(\"https://api.github.com\")\nresp = obs.get(store, \"repos/developmentseed/obstore\")\ndata = json.loads(resp.bytes())\nprint(data[\"stargazers_count\"])\n</code></pre>"},{"location":"api/store/http/#obstore.store.HTTPStore.from_url","title":"from_url  <code>classmethod</code>","text":"<pre><code>from_url(\n    url: str,\n    *,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n) -&gt; HTTPStore\n</code></pre> <p>Construct a new HTTPStore from a URL</p> <p>Note</p> <p>Note that in contrast to the other stores, <code>from_url</code> will use the full URL provided here as a prefix for further operations.</p> <p>Parameters:</p> <ul> <li> <code>url</code>               (<code>str</code>)           \u2013            <p>The base URL to use for the store.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>HTTPStore</code>           \u2013            <p>HTTPStore</p> </li> </ul>"},{"location":"api/store/local/","title":"Local","text":""},{"location":"api/store/local/#obstore.store.LocalStore","title":"obstore.store.LocalStore","text":"<p>Local filesystem storage providing an ObjectStore interface to files on local disk. Can optionally be created with a directory prefix.</p> <pre><code>from pathlib import Path\n\nstore = LocalStore()\nstore = LocalStore(prefix=\"/path/to/directory\")\nstore = LocalStore(prefix=Path(\".\"))\n</code></pre>"},{"location":"api/store/local/#obstore.store.LocalStore.from_url","title":"from_url  <code>classmethod</code>","text":"<pre><code>from_url(url: str) -&gt; LocalStore\n</code></pre> <p>Construct a new LocalStore from a <code>file://</code> URL.</p> <p>Examples:</p> <p>Construct a new store pointing to the root of your filesystem: <pre><code>url = \"file:///\"\nstore = LocalStore.from_url(url)\n</code></pre></p> <p>Construct a new store with a directory prefix: <pre><code>url = \"file:///Users/kyle/\"\nstore = LocalStore.from_url(url)\n</code></pre></p>"},{"location":"api/store/memory/","title":"Memory","text":""},{"location":"api/store/memory/#obstore.store.MemoryStore","title":"obstore.store.MemoryStore","text":"<p>A fully in-memory implementation of ObjectStore.</p> <p>Create a new in-memory store: <pre><code>store = MemoryStore()\n</code></pre></p>"},{"location":"api/store/middleware/","title":"Middleware","text":"<p>Wrappers around other <code>ObjectStore</code> instances to provide monitoring or other modifications.</p>"},{"location":"api/store/middleware/#obstore.store.PrefixStore","title":"obstore.store.PrefixStore","text":"<p>Store wrapper that applies a constant prefix to all paths handled by the store.</p> <p>Example:</p> <pre><code>import obstore as obs\nfrom obstore.store import MemoryStore, PrefixStore\n\nstore = MemoryStore()\n\ndata = b\"the quick brown fox jumps over the lazy dog\"\npath = \"a/b/c/data.txt\"\n\nobs.put(store, path, data)\n\nprefix_store = PrefixStore(store, \"a/\")\nassert obs.get(prefix_store, \"b/c/data.txt\").bytes() == data\n\n# The / after the passed-in prefix is inferred\nprefix_store2 = PrefixStore(store, \"a\")\nassert obs.get(prefix_store2, \"b/c/data.txt\").bytes() == data\n\n# The prefix is removed from list results\nassert obs.list(prefix_store).collect()[0][\"path\"] == \"b/c/data.txt\"\n\n# More deeply nested prefix\nprefix_store3 = PrefixStore(store, \"a/b/c\")\nassert obs.get(prefix_store3, \"data.txt\").bytes() == data\n</code></pre>"},{"location":"api/store/middleware/#obstore.store.PrefixStore.__init__","title":"__init__","text":"<pre><code>__init__(store: ObjectStore, prefix: str) -&gt; None\n</code></pre> <p>Create a new PrefixStore with the provided prefix.</p> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>ObjectStore</code>)           \u2013            <p>The underlying store to wrap.</p> </li> <li> <code>prefix</code>               (<code>str</code>)           \u2013            <p>If the prefix does not end with <code>/</code>, one will be added.</p> </li> </ul>"},{"location":"examples/fastapi/","title":"FastAPI","text":"<p>FastAPI is a modern, high-performance, web framework for building APIs with Python based on standard Python type hints.</p> <p>It's easy to integrate obstore with FastAPI routes, where you want to download a file from an object store and return it to the user.</p> <p>FastAPI has a <code>StreamingResponse</code>, which neatly integrates with <code>BytesStream</code> to stream the response to the user.</p> <p>Note</p> <p>This example is also available on Github if you'd like to test it out locally.</p> <p>First, import <code>fastapi</code> and <code>obstore</code> and create the FastAPI application.</p> <pre><code>from fastapi import FastAPI\nfrom fastapi.responses import StreamingResponse\n\nimport obstore as obs\nfrom obstore.store import HTTPStore, S3Store\n\napp = FastAPI()\n</code></pre> <p>Next, we can add our route. Here, we create a simple route that fetches a small Parquet file from an HTTP url and returns it to the user.</p> <p>Passing <code>resp</code> directly to <code>StreamingResponse</code> calls <code>GetResult.stream()</code> under the hood and thus uses the default chunking behavior of <code>GetResult.stream()</code>.</p> <pre><code>@app.get(\"/example.parquet\")\nasync def download_example() -&gt; StreamingResponse:\n    store = HTTPStore.from_url(\"https://raw.githubusercontent.com\")\n    path = \"opengeospatial/geoparquet/refs/heads/main/examples/example.parquet\"\n\n    # Make the request. This only begins the download; it does not wait for the\n    # download to finish.\n    resp = await obs.get_async(store, path)\n    return StreamingResponse(resp)\n</code></pre> <p>You may also want to customize the chunking behavior of the async stream. To do this, call <code>GetResult.stream()</code> before passing to <code>StreamingResponse</code>.</p> <pre><code>@app.get(\"/large.parquet\")\nasync def large_example() -&gt; StreamingResponse:\n    # Example large Parquet file hosted in AWS open data\n    store = S3Store(\"ookla-open-data\", region=\"us-west-2\", skip_signature=True)\n    path = \"parquet/performance/type=fixed/year=2024/quarter=1/2024-01-01_performance_fixed_tiles.parquet\"\n\n    # Note: for large file downloads you may need to increase the timeout in\n    # the client configuration\n    resp = await obs.get_async(store, path)\n\n    # Example: Ensure the stream returns at least 5MB of data in each chunk.\n    return StreamingResponse(resp.stream(min_chunk_size=5 * 1024 * 1024))\n</code></pre> <p>Note that here FastAPI wraps <code>starlette.responses.StreamingResponse</code>. So any web server that uses Starlette for responses can use this same code.</p>"}]}