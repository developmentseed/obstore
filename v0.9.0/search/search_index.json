{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"obstore","text":"<p>The simplest, highest-throughput <sup>1</sup> Python interface to Amazon S3, Google Cloud Storage, Azure Storage, &amp; other S3-compliant APIs, powered by Rust.</p> <ul> <li>One interface for all backends with no required Python dependencies.</li> <li>Sync and async API with full type hinting.</li> <li>Streaming downloads with configurable chunking.</li> <li>Streaming uploads from files or async or sync iterators.</li> <li>Streaming list, with no need to paginate.</li> <li>Automatic multipart uploads for large file objects.</li> <li>Automatic credential refresh before expiration.</li> <li>File-like object API and fsspec integration.</li> <li>Optionally return list results in Apache Arrow format, which is faster and more memory-efficient than materializing Python <code>dict</code>s.</li> <li>Zero-copy data exchange between Rust and Python via the buffer protocol.</li> </ul> <p>For Rust developers looking to add <code>object_store</code> support to their own Python packages, refer to <code>pyo3-object_store</code>.</p>"},{"location":"#installation","title":"Installation","text":"<p>To install obstore using pip:</p> <pre><code>pip install obstore\n</code></pre> <p>Obstore is on conda-forge and can be installed using conda, mamba, or pixi. To install obstore using conda:</p> <pre><code>conda install -c conda-forge obstore\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>Full documentation is available on the website.</p> <p>Head to Getting Started to dig in.</p> <ol> <li> <p>Benchmarking is ongoing, but preliminary results indicate roughly 9x higher throughput than fsspec and 2.8x higher throughput than aioboto3 for many concurrent, small, get requests from an async context.\u00a0\u21a9</p> </li> </ol>"},{"location":"CHANGELOG/","title":"Changelog","text":""},{"location":"CHANGELOG/#unreleased","title":"Unreleased","text":""},{"location":"CHANGELOG/#090-2026-02-22","title":"[0.9.0] - 2026-02-22","text":""},{"location":"CHANGELOG/#breaking-changes","title":"Breaking Changes","text":"<ul> <li>chore!: Deprecate support for python 3.9 by @kylebarron in developmentseed/obstore!609</li> </ul>"},{"location":"CHANGELOG/#whats-changed","title":"What's Changed","text":"<ul> <li>fix: Remove TypeVar constraints on arro3-core to fix list typing when arro3-core not installed by @kylebarron in developmentseed/obstore!578</li> <li>docs: Update cookbook.md - unmatched quotes by @mdsumner in developmentseed/obstore!587</li> <li>fix: Prevent early EOF error in reader.read by @nvictus in developmentseed/obstore!593</li> <li>feat: Allow S3 HTTP URLs without region by @kylebarron in developmentseed/obstore!590</li> <li>feat: upgrade object store 0.13.x by @alukach in developmentseed/obstore!600</li> <li>ci: Make abi3 wheels for mainline Python 3.11+ by @kylebarron in developmentseed/obstore!623</li> <li>feat: Update docs, examples, tests to use method-based API by @kylebarron in developmentseed/obstore!625</li> </ul>"},{"location":"CHANGELOG/#new-contributors","title":"New Contributors","text":"<ul> <li>@nvictus made their first contribution in developmentseed/obstore!593</li> <li>@alukach made their first contribution in developmentseed/obstore!600</li> <li>@DisturbedOcean made their first contribution in developmentseed/obstore!620</li> </ul> <p>Full Changelog: github.com/developmentseed/obstore/compare/py-v0.8.2...py-v0.9.0</p>"},{"location":"CHANGELOG/#082-2025-09-16","title":"[0.8.2] - 2025-09-16","text":""},{"location":"CHANGELOG/#whats-changed_1","title":"What's Changed","text":"<ul> <li>Added sdist and wheels for Python 3.14 (except Windows) @kylebarron in developmentseed/obstore!561 and developmentseed/obstore!563</li> <li>test: Set up minio-based testing, replace moto by @kylebarron in developmentseed/obstore!553</li> <li>chore: Bump ruff to 0.13 by @kylebarron in developmentseed/obstore!562</li> <li>docs: Use dictionary syntax for list properties by @mdsumner in developmentseed/obstore!558</li> </ul>"},{"location":"CHANGELOG/#new-contributors_1","title":"New Contributors","text":"<ul> <li>@mdsumner made their first contribution in developmentseed/obstore!558</li> </ul> <p>Full Changelog: github.com/developmentseed/obstore/compare/py-v0.8.1...py-v0.8.2</p>"},{"location":"CHANGELOG/#081-2025-08-22","title":"[0.8.1] - 2025-08-22","text":""},{"location":"CHANGELOG/#whats-changed_2","title":"What's Changed","text":"<ul> <li>fix: Fix passing down <code>application_credentials</code> to GCSStore by @kylebarron in developmentseed/obstore!541</li> <li>fix: earthdata token refresh when not redirected by @chuckwondo in developmentseed/obstore!539</li> </ul> <p>Full Changelog: github.com/developmentseed/obstore/compare/py-v0.8.0...py-v0.8.1</p>"},{"location":"CHANGELOG/#080-2025-08-07","title":"[0.8.0] - 2025-08-07","text":""},{"location":"CHANGELOG/#whats-changed_3","title":"What's Changed","text":"<ul> <li>Breaking: Don't double percent-encode paths by @kylebarron in developmentseed/obstore!524</li> <li>This changes the internals from using <code>Path</code> \"encoding\" to <code>Path</code> \"parsing\". This avoids issues where paths could be unintentionally double-encoded. But this means that the user must ensure that paths are valid.</li> <li>fix: Only SHA256 is supported for S3 checksum algorithm by @kylebarron in developmentseed/obstore!527</li> </ul>"},{"location":"CHANGELOG/#073-2025-08-01","title":"[0.7.3] - 2025-08-01","text":""},{"location":"CHANGELOG/#whats-changed_4","title":"What's Changed","text":"<ul> <li>fix: Fix conversion from python string to Rust Attribute #520</li> <li>chore: Bump arrow to 56</li> </ul>"},{"location":"CHANGELOG/#072-2025-07-31","title":"[0.7.2] - 2025-07-31","text":""},{"location":"CHANGELOG/#whats-changed_5","title":"What's Changed","text":"<ul> <li>feat(fsspec): <code>FsspecStore.modified()</code> by @keen85 in developmentseed/obstore!517</li> </ul>"},{"location":"CHANGELOG/#new-contributors_2","title":"New Contributors","text":"<ul> <li>@keen85 made their first contribution in developmentseed/obstore!517</li> </ul> <p>Full Changelog: github.com/developmentseed/obstore/compare/py-v0.7.1...py-v0.7.2</p>"},{"location":"CHANGELOG/#071-2025-07-24","title":"[0.7.1] - 2025-07-24","text":""},{"location":"CHANGELOG/#whats-changed_6","title":"What's Changed","text":"<ul> <li>chore: Bump object_store to 0.12.3 by @kylebarron in developmentseed/obstore!501. From upstream changelog:</li> <li>Retry on 429s and equivalents (apache/arrow-rs-object-store#309)</li> <li>Support <code>container@account.dfs.core.windows.net/path</code> URL style for <code>az</code> protocol (apache/arrow-rs-object-store#285)</li> </ul>"},{"location":"CHANGELOG/#documentation","title":"Documentation","text":"<ul> <li>docs: Add Cloudflare R2 example by @kylebarron in developmentseed/obstore!504</li> <li>docs: Improve documentation about URL path handling in <code>from_url</code> class methods by @kylebarron in developmentseed/obstore!512</li> <li>docs: Clarify that <code>return_arrow</code> is only a performance optimization by @kylebarron in developmentseed/obstore!513</li> </ul>"},{"location":"CHANGELOG/#other","title":"Other","text":"<ul> <li>fix: fix pyright config by @pjonsson in developmentseed/obstore!505</li> <li>ci: reinstate pyright check by @pjonsson in developmentseed/obstore!510</li> </ul>"},{"location":"CHANGELOG/#new-contributors_3","title":"New Contributors","text":"<ul> <li>@pjonsson made their first contribution in developmentseed/obstore!505</li> </ul> <p>Full Changelog: github.com/developmentseed/obstore/compare/py-v0.7.0...py-v0.7.1</p>"},{"location":"CHANGELOG/#070-2025-06-25","title":"[0.7.0] - 2025-06-25","text":""},{"location":"CHANGELOG/#new-features","title":"New Features","text":"<ul> <li>Support anonymous GCS connections by @kylebarron in developmentseed/obstore!404</li> <li>Support default headers in client options by @kylebarron in developmentseed/obstore!427</li> <li>Validate that obstore implements the obspec API by @kylebarron in developmentseed/obstore!461</li> <li>Allow passing credential providers in to fsspec wrapper by @kylebarron in developmentseed/obstore!396</li> <li>feat: Improve NASA Earthdata credential providers by @chuckwondo in developmentseed/obstore!472</li> <li>feat: Deprecate custom NotFoundError in favor of built-in FileNotFoundError by @kylebarron in developmentseed/obstore!487</li> </ul>"},{"location":"CHANGELOG/#breaking-changes_1","title":"Breaking changes","text":"<ul> <li><code>obstore.auth.AzureCredentialProvider</code> (and <code>obstore.auth.AzureAsyncCredentialProvider</code>) removed some attributes that were previously accidentally public. Also, <code>scopes</code> and <code>tenant_id</code> parameters in the <code>__init__</code> of those two classes are now keyword-only parameters. by @kylebarron in developmentseed/obstore!442</li> </ul>"},{"location":"CHANGELOG/#bug-fixes","title":"Bug fixes","text":"<ul> <li>Remove <code>@staticmethod</code> from credential provider type annotations by @kylebarron in developmentseed/obstore!446</li> <li>Enable accessing <code>meta</code>, <code>range</code>, and <code>attributes</code> after reading <code>GetResult</code> payload by @kylebarron in developmentseed/obstore!440</li> <li>Ensure we always release the GIL before calling <code>tokio::Runtime::block_on</code> by @kylebarron in developmentseed/obstore!451</li> <li>fix: AzureStore creation by HTTPS url by @kylebarron in developmentseed/obstore!481</li> </ul>"},{"location":"CHANGELOG/#documentation_1","title":"Documentation","text":"<ul> <li>docs: Add Zarr example to docs by @kylebarron in developmentseed/obstore!468</li> <li>docs: stream-zip example by @kylebarron in developmentseed/obstore!470</li> <li>fix: docs for json.loads(bytes) by @gadomski in developmentseed/obstore!432</li> </ul>"},{"location":"CHANGELOG/#other_1","title":"Other","text":"<ul> <li>Include <code>object_store</code> version and source in Python dist by @kylebarron in developmentseed/obstore!408</li> </ul>"},{"location":"CHANGELOG/#new-contributors_4","title":"New Contributors","text":"<ul> <li>@emmanuel-ferdman made their first contribution in developmentseed/obstore!410</li> <li>@gadomski made their first contribution in developmentseed/obstore!432</li> <li>@chuckwondo made their first contribution in developmentseed/obstore!454</li> </ul> <p>Full Changelog: github.com/developmentseed/obstore/compare/py-v0.6.0...py-v0.7.0</p>"},{"location":"CHANGELOG/#060-2025-03-24","title":"[0.6.0] - 2025-03-24","text":""},{"location":"CHANGELOG/#new-features_1","title":"New Features","text":"<ul> <li>Planetary computer credential provider by @kylebarron in developmentseed/obstore!379</li> </ul>"},{"location":"CHANGELOG/#breaking-changes_2","title":"Breaking changes","text":""},{"location":"CHANGELOG/#object-store-methods","title":"Object store methods","text":"<p>No breaking changes.</p>"},{"location":"CHANGELOG/#store-constructors","title":"Store constructors","text":"<ul> <li>In the <code>AzureStore</code> constructor, the <code>container</code> positional argument was renamed to <code>container_name</code> to match the <code>container_name</code> key in <code>AzureConfig</code>. by @kylebarron in developmentseed/obstore!380</li> </ul> <p>This is a breaking change if you had been calling <code>AzureStore(container=\"my container name\")</code>.</p> <p>This is not breaking if you had been using it as a positional argument <code>AzureStore(\"my container name\")</code> or if you had already been using <code>AzureStore(container_name=\"my container name\")</code>.</p> <p>The idea here is that we want one and only one argument name for each underlying config parameter. Most of these breaking changes took place in 0.5.0, but this was overlooked.</p>"},{"location":"CHANGELOG/#bug-fixes_1","title":"Bug fixes","text":"<ul> <li>Fix import errors on Python 3.9:</li> <li>Fix azure auth import on Python 3.9 by @kylebarron in developmentseed/obstore!378</li> <li>Fix <code>_buffered.pyi</code> for python 3.9 by @kylebarron in developmentseed/obstore!381</li> <li>Define <code>__all__</code> to fix type checking import paths developmentseed/obstore!389</li> </ul>"},{"location":"CHANGELOG/#documentation_2","title":"Documentation","text":"<ul> <li>Fix chunk_size typo by @kylebarron in developmentseed/obstore!377</li> <li>Docs: Make integrations dropdown by @kylebarron in developmentseed/obstore!382</li> <li>Docs: Use source order in credential provider docs by @kylebarron in developmentseed/obstore!383</li> </ul>"},{"location":"CHANGELOG/#other_2","title":"Other","text":"<ul> <li>Add typing extensions as runtime dependency by @kylebarron in developmentseed/obstore!384</li> </ul> <p>Full Changelog: github.com/developmentseed/obstore/compare/py-v0.5.1...py-v0.6.0</p>"},{"location":"CHANGELOG/#051-2025-03-17","title":"[0.5.1] - 2025-03-17","text":""},{"location":"CHANGELOG/#bug-fixes_2","title":"Bug fixes","text":"<ul> <li>Fix import errors for Python 3.9 and 3.10. Update CI. by @kylebarron in developmentseed/obstore!372</li> </ul> <p>Full Changelog: github.com/developmentseed/obstore/compare/py-v0.5.0...py-v0.5.1</p>"},{"location":"CHANGELOG/#050-2025-03-17","title":"[0.5.0] - 2025-03-17","text":""},{"location":"CHANGELOG/#new-features_2","title":"New Features","text":"<ul> <li>Class methods wrapper. Instead of calling <code>obstore.get(store)</code>, you can now call <code>store.get()</code> directly. by @kylebarron in developmentseed/obstore!331</li> <li>User-supplied credential callback by @kylebarron in developmentseed/obstore!234</li> <li>Add Azure credential providers by @daviewales in developmentseed/obstore!343</li> <li>Fsspec updates:</li> <li>[FEAT] Create obstore store in fsspec on demand by @machichima in developmentseed/obstore!198</li> <li>[FEAT] support df.to_parquet and df.read_parquet() by @machichima in developmentseed/obstore!165</li> <li>Document fsspec integration in user guide by @kylebarron in developmentseed/obstore!299</li> <li>fsspec: Allow calling <code>register</code> with no arguments by @kylebarron in developmentseed/obstore!298</li> <li>Enable pickling Bytes by @kylebarron in developmentseed/obstore!295</li> <li>Add AWS literal type hints by @kylebarron in developmentseed/obstore!301</li> <li>pyo3-bytes slicing by @jessekrubin in developmentseed/obstore!249</li> </ul>"},{"location":"CHANGELOG/#breaking-changes_3","title":"Breaking changes","text":""},{"location":"CHANGELOG/#object-store-methods_1","title":"Object store methods","text":"<p>No breaking changes.</p>"},{"location":"CHANGELOG/#store-constructors_1","title":"Store constructors","text":"<ul> <li>Removed <code>S3Store.from_session</code> and <code>S3Store._from_native</code>. Use credential providers instead.</li> <li>Reduce the config variations supported for input. I.e. we previously allowed <code>region</code>, <code>aws_region</code>, <code>REGION</code> or <code>AWS_REGION</code> as a config parameter to <code>S3Store</code>, which could make it confusing. We now only support a single config input value for each underlying concept. developmentseed/obstore!323</li> </ul>"},{"location":"CHANGELOG/#fsspec","title":"Fsspec","text":"<ul> <li>Rename <code>AsyncFsspecStore</code> to <code>FsspecStore</code> by @kylebarron in developmentseed/obstore!297</li> </ul>"},{"location":"CHANGELOG/#bug-fixes_3","title":"Bug fixes","text":"<ul> <li>Validate input for range request by @kylebarron in developmentseed/obstore!255</li> </ul>"},{"location":"CHANGELOG/#documentation_3","title":"Documentation","text":"<ul> <li>Update performance numbers by @kylebarron in developmentseed/obstore!307</li> <li>Document type-only constructs by @kylebarron in developmentseed/obstore!309, developmentseed/obstore!311</li> <li>Add import warning admonition on ObjectStore type by @kylebarron in</li> <li>Update etag conditional put docs by @kylebarron in developmentseed/obstore!310</li> </ul>"},{"location":"CHANGELOG/#new-contributors_5","title":"New Contributors","text":"<ul> <li>@weiji14 made their first contribution in developmentseed/obstore!272</li> <li>@machichima made their first contribution in developmentseed/obstore!198</li> </ul> <p>Full Changelog: github.com/developmentseed/obstore/compare/py-v0.4.0...py-v0.5.0</p>"},{"location":"CHANGELOG/#040-2025-02-10","title":"[0.4.0] - 2025-02-10","text":""},{"location":"CHANGELOG/#new-features_3","title":"New Features","text":"<ul> <li>Support for pickling &amp; always manage store prefix by @kylebarron in developmentseed/obstore!185, developmentseed/obstore!239, developmentseed/obstore!223</li> <li>Add top-level <code>obstore.store.from_url</code> function, which delegates to each store's <code>from_url</code> constructor by @kylebarron in developmentseed/obstore!179, developmentseed/obstore!201</li> <li>Add option to return Arrow from <code>list_with_delimiter</code> by @kylebarron in developmentseed/obstore!238, developmentseed/obstore!244</li> <li>(Provisional) Enhanced loading of s3 credentials using <code>aws-config</code> crate by @kylebarron in developmentseed/obstore!203</li> <li>Access config values out from stores by @kylebarron in developmentseed/obstore!210</li> <li>LocalStore updates:</li> <li>Enable automatic cleanup for local store, when deleting directories by @kylebarron in developmentseed/obstore!175</li> <li>Optionally create root dir in LocalStore by @kylebarron in developmentseed/obstore!177</li> <li> <p>File-like object updates:</p> </li> <li> <p>Add support for writable file-like objects by @kylebarron in developmentseed/obstore!167</p> </li> <li> <p>Updates to readable file API:</p> <ul> <li>Support user-specified capacity in readable file-like objects by @kylebarron in developmentseed/obstore!174</li> <li>Expose <code>ObjectMeta</code> from readable file API by @kylebarron in developmentseed/obstore!176</li> </ul> </li> <li> <p>Merge <code>config</code> and <code>kwargs</code> and validate that no configuration parameters have been passed multiple times. (developmentseed/obstore!180, developmentseed/obstore!182, developmentseed/obstore!218)</p> </li> <li>Add <code>__repr__</code> to <code>Bytes</code> class by @jessekrubin in developmentseed/obstore!173</li> </ul>"},{"location":"CHANGELOG/#breaking-changes_4","title":"Breaking changes","text":"<ul> <li><code>get_range</code>, <code>get_range_async</code>, <code>get_ranges</code>, and <code>get_ranges_async</code> now require named parameters for <code>start</code>, <code>end</code>, and <code>length</code> to make the semantics of the range request fully explicit. by @kylebarron in developmentseed/obstore!156</li> <li>Previously, individual stores did not manage a prefix path within the remote resource and <code>PrefixStore</code> was used to enable this. As of 0.4.0, <code>PrefixStore</code> was removed and all stores manage an optional mount prefix natively.</li> <li><code>obstore.open</code> has been renamed to <code>obstore.open_reader</code>.</li> <li>The <code>from_env</code> constructor has been removed from <code>S3Store</code>, <code>GCSStore</code>, and <code>AzureStore</code>. Now all constructors will read from environment variables. Use <code>__init__</code> or <code>from_url</code> instead. developmentseed/obstore!189</li> <li><code>obstore.exceptions.ObstoreError</code> renamed to <code>obstore.exceptions.BaseError</code> developmentseed/obstore!200</li> </ul>"},{"location":"CHANGELOG/#bug-fixes_4","title":"Bug fixes","text":"<ul> <li>Fix pylance finding exceptions module by @kylebarron in developmentseed/obstore!183</li> <li>Allow passing in partial retry/backoff config by @kylebarron in developmentseed/obstore!205</li> <li>Fix returning None from async functions by @kylebarron in developmentseed/obstore!245</li> <li>Fix LocalStore range request past end of file, by @kylebarron in developmentseed/obstore!230</li> </ul>"},{"location":"CHANGELOG/#documentation_4","title":"Documentation","text":"<ul> <li>Update wording for fsspec docstring by @kylebarron in developmentseed/obstore!195</li> <li>Add documentation about AWS region by @kylebarron in developmentseed/obstore!213</li> <li>Add developer documentation for functional API choice by @kylebarron in developmentseed/obstore!215</li> <li>Add <code>tqdm</code> progress bar example by @kylebarron in developmentseed/obstore!237</li> <li>Add contributor, performance, integrations docs by @kylebarron in developmentseed/obstore!227</li> <li>Add minio example by @kylebarron in developmentseed/obstore!241</li> </ul>"},{"location":"CHANGELOG/#other_3","title":"Other","text":"<ul> <li>Use manylinux 2_24 for aarch64 linux wheels by @kylebarron in developmentseed/obstore!225</li> </ul>"},{"location":"CHANGELOG/#new-contributors_6","title":"New Contributors","text":"<ul> <li>@vincentsarago made their first contribution in developmentseed/obstore!168</li> <li>@jessekrubin made their first contribution in developmentseed/obstore!173</li> </ul> <p>Full Changelog: github.com/developmentseed/obstore/compare/py-v0.3.0...py-v0.4.0</p>"},{"location":"CHANGELOG/#030-2025-01-16","title":"[0.3.0] - 2025-01-16","text":""},{"location":"CHANGELOG/#new-features_4","title":"New Features","text":"<ul> <li>Streaming uploads. <code>obstore.put</code> now supports iterable input, and <code>obstore.put_async</code> now supports async iterable input. This means you can pass the output of <code>obstore.get_async</code> directly into <code>obstore.put_async</code>. by @kylebarron in developmentseed/obstore!54</li> <li>Allow passing config options directly as keyword arguments. Previously, you had to pass all options as a <code>dict</code> into the <code>config</code> parameter. Now you can pass the elements directly to the store constructor. by @kylebarron in developmentseed/obstore!144</li> <li>Readable file-like objects. Open a readable file-like object with <code>obstore.open</code> and <code>obstore.open_async</code>. by @kylebarron in developmentseed/obstore!33</li> <li>Fsspec integration by @martindurant in developmentseed/obstore!63</li> <li>Prefix store by @kylebarron in developmentseed/obstore!117</li> <li>Python 3.13 wheels by @kylebarron in developmentseed/obstore!95</li> <li>Support python timedelta objects as duration config values by @kylebarron in developmentseed/obstore!146</li> <li>Add class constructors for store builders. Each store now has an <code>__init__</code> method, for easier construction. by @kylebarron in developmentseed/obstore!141</li> </ul>"},{"location":"CHANGELOG/#breaking-changes_5","title":"Breaking changes","text":"<ul> <li> <p><code>get_range</code>, <code>get_range_async</code>, <code>get_ranges</code>, and <code>get_ranges_async</code> now use start/end instead of offset/length. This is for consistency with the <code>range</code> option of <code>obstore.get</code>. by @kylebarron in developmentseed/obstore!71</p> </li> <li> <p>Return <code>Bytes</code> from <code>GetResult.bytes()</code> by @kylebarron in developmentseed/obstore!134</p> </li> </ul>"},{"location":"CHANGELOG/#bug-fixes_5","title":"Bug fixes","text":"<ul> <li>boto3 region name can be None by @kylebarron in developmentseed/obstore!59</li> <li>add missing py.typed file by @gruebel in developmentseed/obstore!115</li> </ul>"},{"location":"CHANGELOG/#documentation_5","title":"Documentation","text":"<ul> <li>FastAPI/Starlette example by @kylebarron in developmentseed/obstore!145</li> <li>Add conda installation doc to README by @kylebarron in developmentseed/obstore!78</li> <li>Document suggested lifecycle rules for aborted multipart uploads by @kylebarron in developmentseed/obstore!139</li> <li>Add type hint and documentation for requester pays by @kylebarron in developmentseed/obstore!131</li> <li>Add note that S3Store can be constructed without boto3 by @kylebarron in developmentseed/obstore!108</li> <li>HTTP Store usage example by @kylebarron in developmentseed/obstore!142</li> </ul>"},{"location":"CHANGELOG/#whats-changed_7","title":"What's Changed","text":"<ul> <li>Improved docs for from_url by @kylebarron in developmentseed/obstore!138</li> <li>Implement read_all for async iterable by @kylebarron in developmentseed/obstore!140</li> </ul>"},{"location":"CHANGELOG/#new-contributors_7","title":"New Contributors","text":"<ul> <li>@willemarcel made their first contribution in developmentseed/obstore!64</li> <li>@martindurant made their first contribution in developmentseed/obstore!63</li> <li>@norlandrhagen made their first contribution in developmentseed/obstore!107</li> <li>@gruebel made their first contribution in developmentseed/obstore!115</li> </ul> <p>Full Changelog: github.com/developmentseed/obstore/compare/py-v0.2.0...py-v0.3.0</p>"},{"location":"CHANGELOG/#020-2024-10-25","title":"[0.2.0] - 2024-10-25","text":""},{"location":"CHANGELOG/#whats-changed_8","title":"What's Changed","text":"<ul> <li>Streaming list results. <code>list</code> now returns an async or sync generator. by @kylebarron in developmentseed/obstore!35</li> <li>Optionally return list result as arrow. The <code>return_arrow</code> keyword argument returns chunks from <code>list</code> as Arrow RecordBatches, which is faster than materializing Python dicts/lists. by @kylebarron in developmentseed/obstore!38</li> <li>Return buffer protocol object from <code>get_range</code> and <code>get_ranges</code>. Enables zero-copy data exchange from Rust into Python. by @kylebarron in developmentseed/obstore!39</li> <li>Add put options. Enables custom tags and attributes, as well as \"put if not exists\". by @kylebarron in developmentseed/obstore!50</li> <li>Rename to obstore by @kylebarron in developmentseed/obstore!45</li> <li>Add custom exceptions. by @kylebarron in developmentseed/obstore!48</li> </ul> <p>Full Changelog: github.com/developmentseed/obstore/compare/py-v0.1.0...py-v0.2.0</p>"},{"location":"CHANGELOG/#010-2024-10-21","title":"[0.1.0] - 2024-10-21","text":"<ul> <li>Initial release.</li> </ul>"},{"location":"alternatives/","title":"Alternatives to Obstore","text":""},{"location":"alternatives/#obstore-vs-fsspec","title":"Obstore vs fsspec","text":"<p>Fsspec is a generic specification for pythonic filesystems. It includes implementations for several cloud storage providers, including s3fs for Amazon S3, gcsfs for Google Cloud Storage, and adlfs for Azure Storage.</p>"},{"location":"alternatives/#api-differences","title":"API Differences","text":"<p>Like Obstore, fsspec presents an abstraction layer that allows you to write code once to interface to multiple cloud providers. However, the abstracted API each presents is different. Obstore tries to mirror native object store APIs while fsspec tries to mirror a file-like API.</p> <p>The upstream Rust library powering obstore, <code>object_store</code>, documents why it intentionally avoids a primary file-like API:</p> <p>The <code>ObjectStore</code> interface is designed to mirror the APIs of object stores and not filesystems, and thus has stateless APIs instead of cursor based interfaces such as <code>Read</code> or <code>Seek</code> available in filesystems.</p> <p>This design provides the following advantages:</p> <ul> <li>All operations are atomic, and readers cannot observe partial and/or failed writes</li> <li>Methods map directly to object store APIs, providing both efficiency and predictability</li> <li>Abstracts away filesystem and operating system specific quirks, ensuring portability</li> <li>Allows for functionality not native to filesystems, such as operation preconditions and atomic multipart uploads</li> </ul> <p>Obstore's primary APIs, like <code>get</code>, <code>put</code>, and <code>list</code>, mirror such object store APIs. However, if you still need to use a file-like API, Obstore provides such APIs with <code>open_reader</code> and <code>open_writer</code>.</p> <p>Obstore also includes a best-effort fsspec compatibility layer, which allows you to use obstore in applications that expect an fsspec-compatible API.</p>"},{"location":"alternatives/#performance","title":"Performance","text":"<p>Beyond API design, performance can also be a consideration. Initial benchmarks show that obstore's async API can provide 9x higher throughput than fsspec's async API.</p>"},{"location":"alternatives/#obstore-vs-boto3","title":"Obstore vs boto3","text":"<p>boto3 is the official Python client for working with AWS services, including S3.</p> <p>boto3 supports all features of S3, including some features that obstore doesn't provide, like creating or deleting buckets.</p> <p>However, boto3 is synchronous and specific to AWS. To support multiple clouds you'd need to use boto3 and another library and abstract away those differences yourself. With obstore you can interface with data in multiple clouds, changing only configuration settings.</p>"},{"location":"alternatives/#obstore-vs-aioboto3","title":"Obstore vs aioboto3","text":"<p>aioboto3 is an async Python client for S3, wrapping boto3 and aiobotocore.</p> <p>aioboto3 presents largely the same API as boto3, but async. As above, this means that it may support more S3-specific features than what obstore supports.</p> <p>But it's still specific to AWS, and in early benchmarks we've measured obstore to provide significantly higher throughput than aioboto3.</p>"},{"location":"alternatives/#obstore-vs-google-cloud-storage-python-client","title":"Obstore vs Google Cloud Storage Python Client","text":"<p>The official Google Cloud Storage Python client uses requests as its HTTP client. This means that the GCS Python client supports only synchronous requests.</p> <p>It also presents a Google-specific API, so you'd need to re-implement your code if you want to use multiple cloud providers.</p>"},{"location":"authentication/","title":"Authentication","text":"<p>Authentication tends to be among the trickiest but most important elements of connecting to object storage. Obstore supports various native and custom authentication methods.</p>"},{"location":"authentication/#native-authentication","title":"Native Authentication","text":"<p>\"Native\" authentication refers to authentication methods that are natively supported by the underlying Rust <code>object_store</code> library.</p> <p>Native authentication is most efficient, as obstore never needs to call into Python to update credentials.</p>"},{"location":"authentication/#order-of-application","title":"Order of application","text":"<p>Native authentication is checked in order:</p> <ul> <li>Environment variables</li> <li>Passed in via <code>config</code>/keyword parameters.</li> </ul> <p>So any parameters passed by the <code>config</code> parameter or by keyword parameters will override any values found from environment variables.</p>"},{"location":"authentication/#native-authentication-variants","title":"Native Authentication Variants","text":"<p>Note that many authentication variants are already supported natively.</p>"},{"location":"authentication/#aws","title":"AWS","text":"<ul> <li>Basic authentication, where an access key ID, secret access key, and optionally token are passed in via environment variables or configuration parameters.</li> <li>WebIdentity. This requires the <code>AWS_WEB_IDENTITY_TOKEN_FILE</code> and <code>AWS_ROLE_ARN</code> environment variables to be set. Additionally, <code>AWS_ROLE_SESSION_NAME</code> can be set to specify a session name.</li> <li>Container credentials. Ensure you pass <code>container_credentials_relative_uri</code> to the <code>S3Store</code>.</li> <li>Instance credentials.</li> </ul> <p>(A transcription of this underlying code).</p>"},{"location":"authentication/#google-cloud-storage","title":"Google Cloud Storage","text":"<ul> <li>Service account credentials</li> <li>Application default credentials</li> <li>Instance credentials</li> </ul> <p>(A transcription of this underlying code).</p>"},{"location":"authentication/#azure","title":"Azure","text":"<ul> <li>Fabric OAuth2, using <code>fabric_token_service_url</code>, <code>fabric_workload_host</code>, <code>fabric_session_token</code>, and <code>fabric_cluster_identifier</code> passed in by the user</li> <li>Workload identity OAuth2, using a <code>client_id</code>, <code>tenant_id</code>, and <code>federated_token_file</code> passed in by the user</li> <li>OAuth2, using a <code>client_id</code>, <code>client_secret</code>, and <code>tenant_id</code> passed in by the user</li> <li>A SAS key passed in by the user.</li> <li>Azure CLI. (When constructing <code>AzureStore</code> you must set <code>use_azure_cli</code> to <code>True</code>, either by passing <code>use_azure_cli=True</code> or by setting the <code>AZURE_USE_AZURE_CLI</code> environment variable to <code>\"TRUE\"</code>).</li> <li>IMDS Managed Identity Provider.</li> </ul> <p>(A transcription of this underlying code).</p>"},{"location":"authentication/#credential-providers","title":"Credential Providers","text":"<p>Credential providers are Python callbacks that allow for full control over credential generation. Passing in a credential provider will override any native credentials.</p>"},{"location":"authentication/#official-sdk-credential-providers","title":"\"Official\" SDK credential providers","text":""},{"location":"authentication/#boto3","title":"boto3","text":"<p>You can use the <code>Boto3CredentialProvider</code> to use <code>boto3.Session</code> to handle credentials.</p> <pre><code>from boto3 import Session\nfrom obstore.auth.boto3 import Boto3CredentialProvider\nfrom obstore.store import S3Store\n\nsession = Session(...)\ncredential_provider = Boto3CredentialProvider(session)\nstore = S3Store(\"bucket_name\", credential_provider=credential_provider)\n</code></pre> <p>Refer to <code>obstore.auth.boto3</code>.</p>"},{"location":"authentication/#googleauth","title":"google.auth","text":"<p>You can use the <code>GoogleCredentialProvider</code> to use <code>google.auth</code> to handle credentials.</p> <pre><code>from obstore.auth.google import GoogleCredentialProvider\nfrom obstore.store import GCSStore\n\ncredential_provider = GoogleCredentialProvider(credentials=...)\nstore = GCSStore(\"bucket_name\", credential_provider=credential_provider)\n</code></pre> <p>Refer to <code>obstore.auth.google</code>.</p>"},{"location":"authentication/#azureidentity","title":"<code>azure.identity</code>","text":"<p>You can use the <code>AzureCredentialProvider</code> to use <code>azure.identity</code> to handle credentials.</p> <pre><code>from obstore.auth.azure import AzureCredentialProvider\nfrom obstore.store import AzureStore\n\ncredential_provider = AzureAsyncCredentialProvider(credential=...)\nstore = AzureStore(\"container\", credential_provider=credential_provider)\nprint(store.list().collect())\n</code></pre> <p>Alternatively, you can use <code>AzureAsyncCredentialProvider</code> with the async API:</p> <pre><code>import asyncio\nfrom obstore.auth.azure import AzureCredentialProvider\nfrom obstore.store import AzureStore\n\ncredential_provider = AzureAsyncCredentialProvider(credential=...)\nstore = AzureStore(\"container\", credential_provider=credential_provider)\n\nasync def fetch_blobs():\n    blobs = await store.list().collect_async()\n    print(blobs)\n\nasyncio.run(fetch_blobs())\n\nRefer to [`obstore.auth.azure`](api/auth/azure.md).\n</code></pre>"},{"location":"authentication/#other-credential-providers","title":"Other credential providers","text":"<ul> <li><code>NasaEarthdataCredentialProvider</code>: A credential provider for accessing NASA Earthdata to be used with S3Store.</li> <li><code>PlanetaryComputerCredentialProvider</code>: A credential provider for accessing Planetary Computer data resources to be used with AzureStore .</li> </ul>"},{"location":"authentication/#microsoft-planetary-computer","title":"Microsoft Planetary Computer","text":"<p>The Microsoft Planetary Computer hosts a multi-petabyte catalog of global environmental data.</p> <p>The contained data is publicly accessible, but requires the user to fetch short-lived access tokens. But accessing and refreshing these tokens every hour can be confusing and annoying.</p> <p>The <code>PlanetaryComputerCredentialProvider</code> handles all token access and refresh automatically.</p> <p>As a quick example, we'll read data from the NAIP dataset:</p> <pre><code>from obstore.store import AzureStore\nfrom obstore.auth.planetary_computer import PlanetaryComputerCredentialProvider\n\nurl = \"https://naipeuwest.blob.core.windows.net/naip/v002/mt/2023/mt_060cm_2023/\"\n\n# Construct an AzureStore with this credential provider.\n#\n# The account, container, and container prefix are passed down to AzureStore\n# automatically.\nstore = AzureStore(credential_provider=PlanetaryComputerCredentialProvider(url))\n</code></pre> <p>Then, for example, list some items in the container (the prefix <code>v002/mt/2023/mt_060cm_2023</code> was automatically set as the prefix on the <code>AzureStore</code>): <pre><code>items = next(store.list())\nprint(items[:2])\n</code></pre></p> <pre><code>[{'path': '44104/m_4410401_ne_13_060_20230811_20240103.200.jpg',\n  'last_modified': datetime.datetime(2025, 1, 13, 18, 18, 1, tzinfo=datetime.timezone.utc),\n  'size': 14459,\n  'e_tag': '0x8DD33FE9DB7A24D',\n  'version': None},\n {'path': '44104/m_4410401_ne_13_060_20230811_20240103.tif',\n  'last_modified': datetime.datetime(2025, 1, 13, 16, 39, 6, tzinfo=datetime.timezone.utc),\n  'size': 400422790,\n  'e_tag': '0x8DD33F0CC1D1752',\n  'version': None}]\n</code></pre> <p>And we can fetch an image thumbnail:</p> <pre><code>path = \"44106/m_4410602_nw_13_060_20230712_20240103.200.jpg\"\nimage_content = store.get(path).bytes()\n\n# Write out the image content to a file in the current directory\nwith open(\"thumbnail.jpg\", \"wb\") as f:\n    f.write(image_content)\n</code></pre> <p>And voil\u00e0:</p> <p></p>"},{"location":"authentication/#custom-authentication","title":"Custom Authentication","text":"<p>There's a long tail of possible authentication mechanisms. Obstore allows you to provide your own custom authentication callback.</p> <p>You can provide either a synchronous or asynchronous callback for your custom authentication function.</p> <ul> <li>A custom AWS credential provider, passed in to <code>S3Store</code> must return an <code>S3Credential</code>.</li> <li>A custom GCS credential provider, passed in to <code>GCSStore</code> must return a <code>GCSCredential</code>.</li> <li>A custom Azure credential provider, passed in to <code>AzureStore</code> must return an <code>AzureCredential</code>.</li> </ul> <p>Warning</p> <p>Asynchronous credential providers can be more performant but are only supported when using obstore's asynchronous APIs. (In particular, there must be an event loop running.)</p>"},{"location":"authentication/#basic-example","title":"Basic Example","text":"<p>The simplest custom credential provider can be just a synchronous or asynchronous function callback:</p> <pre><code>from datetime import datetime, timedelta, UTC\n\ndef get_credentials() -&gt; S3Credential:\n    return {\n        \"access_key_id\": \"...\",\n        \"secret_access_key\": \"...\",\n        # Not always required\n        \"token\": \"...\",\n        \"expires_at\": datetime.now(UTC) + timedelta(minutes=30),\n    }\n</code></pre> <p>Then just pass that function into <code>credential_provider</code>:</p> <pre><code>S3Store(..., credential_provider=get_credentials)\n</code></pre>"},{"location":"authentication/#advanced-example","title":"Advanced Example","text":"<p>More advanced credential providers can be class based. A class can act as a callable, just like a function callback, as long as it implements a <code>__call__</code> method.</p> <p>Below is an example custom credential provider for accessing NASA Earthdata.</p> <p>NASA Earthdata supports public in-region direct S3 access. This credential provider automatically manages refreshing the S3 credentials before they expire.</p> <p>Note that you must be in the same AWS region (<code>us-west-2</code>) to use this provider.</p> <pre><code>from __future__ import annotations\n\nfrom datetime import datetime\nfrom typing import TYPE_CHECKING\n\nimport requests\n\nif TYPE_CHECKING:\n    from obstore.store import S3Credential\n\nCREDENTIALS_API = \"https://archive.podaac.earthdata.nasa.gov/s3credentials\"\n\n\nclass NasaEarthdataCredentialProvider:\n    \"\"\"A credential provider for accessing [NASA Earthdata].\n\n    NASA Earthdata supports public [in-region direct S3\n    access](https://archive.podaac.earthdata.nasa.gov/s3credentialsREADME). This\n    credential provider automatically manages the S3 credentials.\n\n    !!! note\n\n        Note that you must be in the same AWS region (`us-west-2`) to use the\n        credentials returned from this provider.\n\n    [NASA Earthdata]: https://www.earthdata.nasa.gov/\n    \"\"\"\n\n    def __init__(\n        self,\n        username: str,\n        password: str,\n    ) -&gt; None:\n        \"\"\"Create a new NasaEarthdataCredentialProvider.\n\n        Args:\n            username: Username to NASA Earthdata.\n            password: Password to NASA Earthdata.\n\n        \"\"\"\n        self.session = requests.Session()\n        self.session.auth = (username, password)\n\n    def __call__(self) -&gt; S3Credential:\n        \"\"\"Request updated credentials.\"\"\"\n        resp = self.session.get(CREDENTIALS_API, allow_redirects=True, timeout=15)\n        auth_resp = self.session.get(resp.url, allow_redirects=True, timeout=15)\n        creds = auth_resp.json()\n        return {\n            \"access_key_id\": creds[\"accessKeyId\"],\n            \"secret_access_key\": creds[\"secretAccessKey\"],\n            \"token\": creds[\"sessionToken\"],\n            \"expires_at\": datetime.fromisoformat(creds[\"expiration\"]),\n        }\n</code></pre> <p>Or asynchronously:</p> <pre><code>from __future__ import annotations\n\nimport json\nfrom datetime import datetime\nfrom typing import TYPE_CHECKING\n\nfrom aiohttp import BasicAuth, ClientSession\n\nif TYPE_CHECKING:\n    from obstore.store import S3Credential\n\nCREDENTIALS_API = \"https://archive.podaac.earthdata.nasa.gov/s3credentials\"\n\n\nclass NasaEarthdataAsyncCredentialProvider:\n    \"\"\"A credential provider for accessing [NASA Earthdata].\n\n    NASA Earthdata supports public [in-region direct S3\n    access](https://archive.podaac.earthdata.nasa.gov/s3credentialsREADME). This\n    credential provider automatically manages the S3 credentials.\n\n    !!! note\n\n        Note that you must be in the same AWS region (`us-west-2`) to use the\n        credentials returned from this provider.\n\n    [NASA Earthdata]: https://www.earthdata.nasa.gov/\n    \"\"\"\n\n    def __init__(\n        self,\n        username: str,\n        password: str,\n    ) -&gt; None:\n        \"\"\"Create a new NasaEarthdataAsyncCredentialProvider.\n\n        Args:\n            username: Username to NASA Earthdata.\n            password: Password to NASA Earthdata.\n\n        \"\"\"\n        self.session = ClientSession(auth=BasicAuth(username, password))\n\n    async def __call__(self) -&gt; S3Credential:\n        \"\"\"Request updated credentials.\"\"\"\n        async with self.session.get(CREDENTIALS_API, allow_redirects=True) as resp:\n            auth_url = resp.url\n        async with self.session.get(auth_url, allow_redirects=True) as auth_resp:\n            # Note: We parse the JSON manually instead of using `resp.json()` because\n            # the response mimetype is incorrectly set to text/html.\n            creds = json.loads(await auth_resp.text())\n        return {\n            \"access_key_id\": creds[\"accessKeyId\"],\n            \"secret_access_key\": creds[\"secretAccessKey\"],\n            \"token\": creds[\"sessionToken\"],\n            \"expires_at\": datetime.fromisoformat(creds[\"expiration\"]),\n        }\n\n    async def close(self):\n        \"\"\"Close the underlying session.\n\n        You should call this method after you've finished all obstore calls.\n        \"\"\"\n        await self.session.close()\n</code></pre> <p>Then call it with</p> <pre><code>credential_provider = NasaEarthdataCredentialProvider(username=\"...\", password=\"...\")\nstore = S3Store(\"bucket_name\", credential_provider=credential_provider)\n</code></pre>"},{"location":"cookbook/","title":"Cookbook","text":""},{"location":"cookbook/#list-objects","title":"List objects","text":"<p>Use the <code>obstore.list</code> method.</p> <pre><code>store = ... # store of your choice\n\n# Recursively list all files below the 'data' path.\n# 1. On AWS S3 this would be the 'data/' prefix\n# 2. On a local filesystem, this would be the 'data' directory\nprefix = \"data\"\n\n# Get a stream of metadata objects:\nlist_stream = store.list(prefix)\n\n# Print info\nfor batch in list_stream:\n    for meta in batch:\n        print(f'Name: {meta[\"path\"]}, size: {meta[\"size\"]}')\n</code></pre>"},{"location":"cookbook/#list-objects-as-arrow","title":"List objects as Arrow","text":"<p>The default <code>list</code> behavior creates many small Python <code>dict</code>s. When listing a large bucket, generating these Python objects can add up to a lot of overhead.</p> <p>Instead, you may consider passing <code>return_arrow=True</code> to <code>obstore.list</code> to return each chunk of list results as an Arrow <code>RecordBatch</code>. This can be much faster than materializing Python objects for each row because Arrow can be shared zero-copy between Rust and Python.</p> <p>This Arrow integration requires the <code>arro3-core</code> dependency, a lightweight Arrow implementation. You can pass the emitted <code>RecordBatch</code> to <code>pyarrow</code> (zero-copy) by passing it to <code>pyarrow.record_batch</code> or to <code>polars</code> (also zero-copy) by passing it to <code>polars.DataFrame</code>.</p> <pre><code>store = ... # store of your choice\n\n# Get a stream of Arrow RecordBatches of metadata\nlist_stream = store.list(prefix=\"data\", return_arrow=True)\nfor record_batch in list_stream:\n    # Perform zero-copy conversion to your arrow-backed library of choice\n    #\n    # To pyarrow:\n    # pyarrow.record_batch(record_batch)\n    #\n    # To polars:\n    # polars.DataFrame(record_batch)\n    #\n    # To pandas (with Arrow-backed data-types):\n    # pyarrow.record_batch(record_batch).to_pandas(types_mapper=pd.ArrowDtype)\n    #\n    # To arro3:\n    # arro3.core.RecordBatch(record_batch)\n    print(record_batch.num_rows)\n</code></pre> <p>Here's a working example with the <code>sentinel-cogs</code> bucket in AWS Open Data:</p> <pre><code>import pandas as pd\nimport pyarrow as pa\nfrom obstore.store import S3Store\n\nstore = S3Store(\"sentinel-cogs\", region=\"us-west-2\", skip_signature=True)\nstream = store.list(chunk_size=20, return_arrow=True)\n\nfor record_batch in stream:\n    # Convert to pyarrow (zero-copy), then to pandas for easy export to a\n    # Markdown table\n    df = pa.record_batch(record_batch).to_pandas()\n    print(df.iloc[:5].to_markdown(index=False))\n    break\n</code></pre> <p>The Arrow record batch looks like the following:</p> path last_modified size e_tag version sentinel-s2-l2a-cogs/1/C/CV/2018/10/S2B_1CCV_20181004_0_L2A/AOT.tif 2020-09-30 20:25:56+00:00 50510 \"2e24c2ee324ea478f2f272dbd3f5ce69\" sentinel-s2-l2a-cogs/1/C/CV/2018/10/S2B_1CCV_20181004_0_L2A/B01.tif 2020-09-30 20:22:48+00:00 1455332 \"a31b78e96748ccc2b21b827bef9850c1\" sentinel-s2-l2a-cogs/1/C/CV/2018/10/S2B_1CCV_20181004_0_L2A/B02.tif 2020-09-30 20:23:19+00:00 38149405 \"d7a92f88ad19761081323165649ce799-5\" sentinel-s2-l2a-cogs/1/C/CV/2018/10/S2B_1CCV_20181004_0_L2A/B03.tif 2020-09-30 20:23:52+00:00 38123224 \"4b938b6969f1c16e5dd685e6599f115f-5\" sentinel-s2-l2a-cogs/1/C/CV/2018/10/S2B_1CCV_20181004_0_L2A/B04.tif 2020-09-30 20:24:21+00:00 39033591 \"4781b581cd32b2169d0b3d22bf40a8ef-5\""},{"location":"cookbook/#fetch-objects","title":"Fetch objects","text":"<p>Use the <code>get</code> method to fetch data bytes from remote storage or files in the local filesystem.</p> <pre><code>store = ... # store of your choice\n\n# Retrieve a specific file\npath = \"data/file01.parquet\"\n\n# Fetch just the file metadata\nmeta = store.head(path)\nprint(meta)\n\n# Fetch the object including metadata\nresult = store.get(path)\nassert result.meta == meta\n\n# Buffer the entire object in memory\nbuffer = result.bytes()\nassert len(buffer) == meta.size\n\n# Alternatively stream the bytes from object storage\nstream = store.get(path).stream()\n\n# We can now iterate over the stream\ntotal_buffer_len = 0\nfor chunk in stream:\n    total_buffer_len += len(chunk)\n\nassert total_buffer_len == meta.size\n</code></pre>"},{"location":"cookbook/#download-to-disk","title":"Download to disk","text":"<p>Using the response as an iterator ensures that we don't buffer the entire file into memory.</p> <pre><code>resp = store.get(path)\n\nwith open(\"output/file\", \"wb\") as f:\n    for chunk in resp:\n        f.write(chunk)\n</code></pre>"},{"location":"cookbook/#put-object","title":"Put object","text":"<p>Use the <code>obstore.put</code> function to atomically write data. <code>obstore.put</code> will automatically use multipart uploads for large input data.</p> <pre><code>store = ... # store of your choice\npath = \"data/file1\"\ncontent = b\"hello\"\nstore.put(path, content)\n</code></pre> <p>You can also upload local files:</p> <pre><code>from pathlib import Path\n\nstore = ... # store of your choice\npath = \"data/file1\"\ncontent = Path(\"path/to/local/file\")\nstore.put(path, content)\n</code></pre> <p>Or file-like objects:</p> <pre><code>store = ... # store of your choice\npath = \"data/file1\"\nwith open(\"path/to/local/file\", \"rb\") as content:\n    store.put(path, content)\n</code></pre> <p>Or iterables:</p> <pre><code>def bytes_iter():\n    for i in range(5):\n        yield b\"foo\"\n\nstore = ... # store of your choice\npath = \"data/file1\"\ncontent = bytes_iter()\nstore.put(path, content)\n</code></pre> <p>Or async iterables:</p> <pre><code>async def bytes_stream():\n    for i in range(5):\n        yield b\"foo\"\n\nstore = ... # store of your choice\npath = \"data/file1\"\ncontent = bytes_stream()\nstore.put(path, content)\n</code></pre>"},{"location":"cookbook/#copy-objects-from-one-store-to-another","title":"Copy objects from one store to another","text":"<p>Perhaps you have data in one store, say AWS S3, that you need to copy to another, say Google Cloud Storage.</p>"},{"location":"cookbook/#in-memory","title":"In memory","text":"<p>Download the file, collect its bytes in memory, then upload it. Note that this will materialize the entire file in memory.</p> <pre><code>store1 = ... # store of your choice\nstore2 = ... # store of your choice\n\npath1 = \"data/file1\"\npath2 = \"data/file2\"\n\nbuffer = store1.get(path1).bytes()\nstore2.put(path2, buffer)\n</code></pre>"},{"location":"cookbook/#local-file","title":"Local file","text":"<p>First download the file to disk, then upload it.</p> <pre><code>from pathlib import Path\n\nstore1 = ... # store of your choice\nstore2 = ... # store of your choice\n\npath1 = \"data/file1\"\npath2 = \"data/file2\"\n\nresp = store1.get(path1)\n\nwith open(\"temporary_file\", \"wb\") as f:\n    for chunk in resp:\n        f.write(chunk)\n\n# Upload the path\nstore2.put(path2, Path(\"temporary_file\"))\n</code></pre>"},{"location":"cookbook/#streaming","title":"Streaming","text":"<p>It's easy to stream a download from one store directly as the upload to another. Only the given</p> <p>Note</p> <p>Using the async API is currently required to use streaming copies.</p> <pre><code>store1 = ... # store of your choice\nstore2 = ... # store of your choice\n\npath1 = \"data/file1\"\npath2 = \"data/file2\"\n\n# This only constructs the stream, it doesn't materialize the data in memory\nresp = await store1.get_async(path1)\n# A streaming upload is created to copy the file to path2\nawait store2.put_async(path2, resp)\n</code></pre> <p>Or, by customizing the chunk size and the upload concurrency you can control memory overhead.</p> <pre><code>resp = await store1.get_async(path1)\nchunk_size = 5 * 1024 * 1024 # 5MB\nstream = resp.stream(min_chunk_size=chunk_size)\n\n# A streaming upload is created to copy the file to path2\nawait store2.put_async(\n    path2,\n    stream,\n    chunk_size=chunk_size,\n    max_concurrency=12\n)\n</code></pre> <p>This will start up to 12 concurrent uploads, each with around 5MB chunks, giving a total memory usage of up to roughly 60MB for this copy.</p> <p>Note</p> <p>You may need to increase the download timeout for large source files. The timeout defaults to 30 seconds, which may not be long enough to upload the file to the destination.</p> <p>You may set the <code>timeout</code> parameter in the <code>client_options</code> passed when creating the store.</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>There are two parts to <code>obstore</code>:</p> <ol> <li>Constructing a <code>Store</code>, a representation of a remote object store with configuration and credentials.</li> <li>Interacting with the <code>Store</code> to download, upload, move, and delete objects.</li> </ol>"},{"location":"getting-started/#constructing-a-store","title":"Constructing a store","text":"<p>You can use the top-level <code>from_url</code> function to construct a store from a top-level URL. Among others this supports <code>s3://bucket/path</code>, <code>gs://bucket/path</code>, <code>az://account/container/path</code>, and <code>https://mydomain/path</code>.</p> <p>Alternatively, you can construct a store directly:</p> <ul> <li><code>S3Store</code>: Configure a connection to Amazon S3.</li> <li><code>GCSStore</code>: Configure a connection to Google Cloud Storage.</li> <li><code>AzureStore</code>: Configure a connection to Microsoft Azure Blob Storage.</li> <li><code>HTTPStore</code>: Configure a connection to a generic HTTP server</li> <li><code>LocalStore</code>: Local filesystem storage providing the same object store interface.</li> <li><code>MemoryStore</code>: A fully in-memory implementation of ObjectStore.</li> </ul> <p>Each store concept has a variety of constructors, and a host of configuration options.</p> <p>Note that each store is scoped to one bucket, so you'll have to create a separate store instance per bucket, even if they're in the same region.</p> <p>Example:</p> <p>For example, multiple ways to create an anonymous <code>S3Store</code> client (without any credentials, for use with fully public buckets):</p> <pre><code>from obstore.store import S3Store, from_url\n\nfrom_url(\"s3://bucket-name\", region=\"us-east-1\", skip_signature=True)\nfrom_url(\"https://bucket-name.s3.us-east-1.amazonaws.com\", skip_signature=True)\nstore = S3Store(\"bucket-name\", region=\"us-east-1\", skip_signature=True)\n</code></pre> <p>The process is similar for <code>GCSStore</code> and <code>AzureStore</code>.</p>"},{"location":"getting-started/#configuration","title":"Configuration","text":"<p>Each store class above has its own store-specific configuration. Elements of the store configuration can be passed as keyword arguments or as a dictionary through the <code>config</code> named parameter.</p> <ul> <li><code>S3Config</code>: Configuration parameters for Amazon S3.</li> <li><code>GCSConfig</code>: Configuration parameters for Google Cloud Storage.</li> <li><code>AzureConfig</code>: Configuration parameters for Microsoft Azure Blob Storage.</li> </ul> <p>Additionally, each store accepts parameters for the underlying HTTP client (<code>ClientConfig</code>) and parameters for retrying requests that error (<code>RetryConfig</code>).</p>"},{"location":"getting-started/#interacting-with-a-store","title":"Interacting with a store","text":"<p>All operations for interacting with a store are exported as top-level functions (not methods on the <code>store</code> object):</p> <ul> <li><code>copy</code>: Copy an object from one path to another in the same object store.</li> <li><code>delete</code>: Delete the object at the specified location.</li> <li><code>get</code>: Return the bytes that are stored at the specified location.</li> <li><code>head</code>: Return the metadata for the specified location</li> <li><code>list</code>: List all the objects with the given prefix.</li> <li><code>put</code>: Save the provided buffer to the specified location.</li> <li><code>rename</code>: Move an object from one path to another in the same object store.</li> </ul> <p>There are a few additional APIs useful for specific use cases:</p> <ul> <li><code>get_range</code>: Get a specific byte range from a file.</li> <li><code>get_ranges</code>: Get multiple byte ranges from a single file.</li> <li><code>list_with_delimiter</code>: List objects within a specific directory.</li> <li><code>sign</code>: Create a signed URL.</li> </ul> <p>File-like object support is also provided:</p> <ul> <li><code>open_reader</code>: Open a remote object as a readable file-like object, similar to a Python <code>BufferedReader</code>.</li> <li><code>open_writer</code>: Open a remote object as a writable file-like object, similar to a Python <code>BufferedWriter</code></li> <li><code>FsspecStore</code> adapter for use with <code>fsspec</code>.</li> </ul> <p>All operations have a comparable async method with the same name plus an <code>_async</code> suffix.</p>"},{"location":"getting-started/#example","title":"Example","text":"<pre><code>from obstore.store import MemoryStore\n\nstore = MemoryStore()\n\nstore.put(\"file.txt\", b\"hello world!\")\nresponse = store.get(\"file.txt\")\nresponse.meta\n# {'path': 'file.txt',\n#  'last_modified': datetime.datetime(2024, 10, 21, 16, 19, 45, 102620, tzinfo=datetime.timezone.utc),\n#  'size': 12,\n#  'e_tag': '0',\n#  'version': None}\nassert response.bytes() == b\"hello world!\"\n\nbyte_range = store.get_range(\"file.txt\", start=0, end=5)\nassert byte_range == b\"hello\"\n\nstore.copy(\"file.txt\", \"other.txt\")\nassert store.get(\"other.txt\").bytes() == b\"hello world!\"\n</code></pre> <p>All of these methods also have <code>async</code> counterparts, suffixed with <code>_async</code>.</p> <pre><code>from obstore.store import MemoryStore\n\nstore = MemoryStore()\n\nawait store.put_async(\"file.txt\", b\"hello world!\")\nresponse = await store.get_async(\"file.txt\")\nresponse.meta\n# {'path': 'file.txt',\n#  'last_modified': datetime.datetime(2024, 10, 21, 16, 20, 36, 477418, tzinfo=datetime.timezone.utc),\n#  'size': 12,\n#  'e_tag': '0',\n#  'version': None}\nassert await response.bytes_async() == b\"hello world!\"\n\nbyte_range = await store.get_range_async(\"file.txt\", start=0, end=5)\nassert byte_range == b\"hello\"\n\nawait store.copy_async(\"file.txt\", \"other.txt\")\nresp = await store.get_async(\"other.txt\")\nassert await resp.bytes_async() == b\"hello world!\"\n</code></pre>"},{"location":"obspec/","title":"Generic storage abstractions with Obspec","text":"<p>Obstore provides an implementation for accessing Amazon S3, Google Cloud Storage, and Azure Storage, but some libraries may want to also support other backends, such as HTTP clients or more obscure things like SFTP or HDFS filesystems.</p> <p>Additionally, there's a bunch of useful behavior that could exist on top of Obstore: caching, metrics, globbing, bulk operations. While all of those operations are useful, we want to keep the core Obstore library as small as possible, tightly coupled with the underlying Rust <code>object_store</code> library.</p> <p>Obspec exists to provide the abstractions for generic programming against object store backends. Obspec is essentially a formalization and generalization of the Obstore API, so if you're already using Obstore, very few changes are needed to use Obspec instead.</p> <p>Downstream libraries can program against the Obspec API to be fully generic around what underlying backend is used at runtime.</p> <p>For further information, refer to the Obspec documentation and the Obspec announcement blog post.</p>"},{"location":"performance/","title":"Performance","text":"<p>Last edited 2025-02-05.</p> <p>Performance is a primary goal of Obstore. Benchmarking is still ongoing, so this document is a mix of what we've learned so far and our untested expectations.</p> <p>tl;dr: Obstore can't magically make your networking hardware faster, but it can reduce overhead, and in cases where that overhead is the limiting factor it can better utilize your available hardware and improve performance.</p>"},{"location":"performance/#non-performance-benefits","title":"Non-performance benefits","text":"<p>Before we get into the weeds of performance, keep in mind that performance is not the only feature of Obstore. There's a strong focus on developer experience as well:</p> <ul> <li>Simple to install with no required Python dependencies.</li> <li>Works the same across AWS S3, Google Cloud Storage, and Azure Storage.</li> <li>Full type hinting, including all store configuration and operations.</li> <li>Downloads that automatically act as iterators and uploads that automatically accept iterators.</li> <li>Automatic pagination of <code>list</code> calls behind the scenes</li> </ul> <p>So you might enjoy using Obstore even in a case where it only marginally improves your performance.</p>"},{"location":"performance/#defining-performance","title":"Defining performance","text":"<p>\"Fast\" can have several definitions in a networking context.</p> <ul> <li>Download latency: the time until the first byte of a download is received.</li> <li>Single-request throughput: the download or upload bytes per second of a single request.</li> <li>Many-request throughput: the combined download or upload bytes per second of multiple concurrent requests.</li> </ul> <p>Furthermore, performance can be different when using obstore's synchronous or asynchronous API.</p> <p>Let's consider the areas where we expect improved, possibly-improved, and equal performance.</p>"},{"location":"performance/#improved-performance","title":"Improved performance","text":"<p>Many-request throughput with the asynchronous API is the primary place where we expect significantly improved performance. Especially when making many requests of relatively small files, we find that obstore can provide significantly higher throughput.</p> <p>For example, preliminary results indicate roughly 9x higher throughput than fsspec and 2.8x higher throughput than aioboto3. That specific benchmark considered fetching the first 16KB of a file many times from an async context.</p>"},{"location":"performance/#possibly-improved-performance","title":"Possibly improved performance","text":"<p>Using the synchronous API. We haven't benchmarked the synchronous API. However, we do release the Python Global Interpreter Lock (GIL) for all synchronous operations, so it may perform better in a thread pool than other Python request libraries.</p>"},{"location":"performance/#equal-performance","title":"Equal performance","text":"<ul> <li> <p>Single-request throughput: if you're making one request, the limiting factor is likely network conditions, not Python overhead, so it's unlikely that obstore will be faster.</p> <p>Keep in mind, however, that what looks like a single request may actually be multiple requests under the hood. <code>obstore.put</code> will use multipart uploads by default, meaning that various parts of a file will be uploaded concurrently, and there may be efficiency gains here. - Latency: this is primarily driven by hardware and network conditions, and we expect Obstore to have similar latency as other Python request libraries.</p> </li> </ul>"},{"location":"performance/#future-research","title":"Future research","text":"<p>In the future, we'd like to benchmark:</p> <ul> <li>Alternate Python event loops, e.g. <code>uvloop</code></li> <li>The obstore synchronous API</li> </ul> <p>If you have any interest in collaborating on this, open an issue.</p>"},{"location":"advanced/pickle/","title":"Pickle Support","text":"<p>Obstore supports pickle, which is commonly used from inside Dask and similar libraries to manage state across distributed workers.</p>"},{"location":"advanced/pickle/#not-for-persistence","title":"Not for persistence","text":"<p>The format used to pickle stores may change across versions. Pickle support is intended for execution frameworks like Dask that need to share state across workers that are using the same environments, including the same version of Python and obstore.</p>"},{"location":"advanced/pickle/#middlewares","title":"Middlewares","text":"<p>Obstore expects to support some sort of middleware in the future, such as for recording request metrics. It's unlikely that middlewares will support pickle.</p>"},{"location":"advanced/pickle/#memorystore-not-implemented","title":"MemoryStore not implemented","text":"<p>Pickling isn't supported for <code>MemoryStore</code> because we don't have a way to access the raw state of the store.</p>"},{"location":"advanced/pickle/#custom-authentication","title":"Custom authentication","text":"<p>As of obstore 0.5.0, custom authentication is supported.</p> <p>Pickling works with a custom authentication provider so long as that Python callback can itself be pickled.</p> <p>So, for example, the boto3 provider cannot be pickled, because a <code>boto3.session.Session</code> cannot be pickled, but a simple function can be.</p>"},{"location":"api/attributes/","title":"Attributes","text":""},{"location":"api/attributes/#obstore.Attribute","title":"obstore.Attribute  <code>module-attribute</code>","text":"<pre><code>Attribute: TypeAlias = (\n    Literal[\n        \"Content-Disposition\",\n        \"Content-Encoding\",\n        \"Content-Language\",\n        \"Content-Type\",\n        \"Cache-Control\",\n    ]\n    | str\n)\n</code></pre> <p>Additional object attribute types.</p> <ul> <li> <p><code>\"Content-Disposition\"</code>: Specifies how the object should be handled by a browser.</p> <p>See Content-Disposition.</p> </li> <li> <p><code>\"Content-Encoding\"</code>: Specifies the encodings applied to the object.</p> <p>See Content-Encoding.</p> </li> <li> <p><code>\"Content-Language\"</code>: Specifies the language of the object.</p> <p>See Content-Language.</p> </li> <li> <p><code>\"Content-Type\"</code>: Specifies the MIME type of the object.</p> <p>This takes precedence over any client configuration.</p> <p>See Content-Type.</p> </li> <li> <p><code>\"Cache-Control\"</code>: Overrides cache control policy of the object.</p> <p>See Cache-Control.</p> </li> </ul> <p>Any other string key specifies a user-defined metadata field for the object.</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore import Attribute\n</code></pre>"},{"location":"api/attributes/#obstore.Attributes","title":"obstore.Attributes  <code>module-attribute</code>","text":"<pre><code>Attributes: TypeAlias = dict[Attribute, str]\n</code></pre> <p>Additional attributes of an object</p> <p>Attributes can be specified in <code>put</code>/<code>put_async</code> and retrieved from <code>get</code>/<code>get_async</code>.</p> <p>Unlike ObjectMeta, Attributes are not returned by listing APIs</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore import Attributes\n</code></pre>"},{"location":"api/copy/","title":"Copy","text":""},{"location":"api/copy/#obstore.copy","title":"obstore.copy","text":"<pre><code>copy(\n    store: ObjectStore, from_: str, to: str, *, overwrite: bool = True\n) -&gt; None\n</code></pre> <p>Copy an object from one path to another in the same object store.</p> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>ObjectStore</code>)           \u2013            <p>The ObjectStore instance to use.</p> </li> <li> <code>from_</code>               (<code>str</code>)           \u2013            <p>Source path</p> </li> <li> <code>to</code>               (<code>str</code>)           \u2013            <p>Destination path</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>overwrite</code>               (<code>bool</code>)           \u2013            <p>If <code>True</code>, if there exists an object at the destination, it will     be overwritten.</p> <p>If <code>False</code>: will copy only if destination is empty. Performs an atomic operation if the underlying object storage supports it. If atomic operations are not supported by the underlying object storage (like S3) it will return an error.</p> <p>Will return an error if the destination already has an object.</p> </li> </ul>"},{"location":"api/copy/#obstore.copy_async","title":"obstore.copy_async  <code>async</code>","text":"<pre><code>copy_async(\n    store: ObjectStore, from_: str, to: str, *, overwrite: bool = True\n) -&gt; None\n</code></pre> <p>Call <code>copy</code> asynchronously.</p> <p>Refer to the documentation for copy.</p>"},{"location":"api/delete/","title":"Delete","text":""},{"location":"api/delete/#obstore.delete","title":"obstore.delete","text":"<pre><code>delete(store: ObjectStore, paths: str | Sequence[str]) -&gt; None\n</code></pre> <p>Delete the object at the specified location(s).</p> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>ObjectStore</code>)           \u2013            <p>The ObjectStore instance to use.</p> </li> <li> <code>paths</code>               (<code>str | Sequence[str]</code>)           \u2013            <p>The path or paths within the store to delete.</p> <p>When supported by the underlying store, this method will use bulk operations that delete more than one object per a request.</p> <p>If the object did not exist, the result may be an error or a success, depending on the behavior of the underlying store. For example, local filesystems, GCP, and Azure return an error, while S3 and in-memory will return Ok.</p> </li> </ul>"},{"location":"api/delete/#obstore.delete_async","title":"obstore.delete_async  <code>async</code>","text":"<pre><code>delete_async(store: ObjectStore, paths: str | Sequence[str]) -&gt; None\n</code></pre> <p>Call <code>delete</code> asynchronously.</p> <p>Refer to the documentation for delete.</p>"},{"location":"api/exceptions/","title":"Exceptions","text":""},{"location":"api/exceptions/#obstore.exceptions","title":"obstore.exceptions","text":""},{"location":"api/exceptions/#obstore.exceptions.AlreadyExistsError","title":"AlreadyExistsError","text":"<p>               Bases: <code>BaseError</code></p> <p>Error when the object already exists.</p>"},{"location":"api/exceptions/#obstore.exceptions.BaseError","title":"BaseError","text":"<p>               Bases: <code>Exception</code></p> <p>The base exception class.</p> <p>Note</p> <p>Some operations also raise a built-in <code>ValueError</code> or <code>FileNotFoundError</code>.</p>"},{"location":"api/exceptions/#obstore.exceptions.GenericError","title":"GenericError","text":"<p>               Bases: <code>BaseError</code></p> <p>A fallback error type when no variant matches.</p>"},{"location":"api/exceptions/#obstore.exceptions.InvalidPathError","title":"InvalidPathError","text":"<p>               Bases: <code>BaseError</code></p> <p>Error for invalid path.</p>"},{"location":"api/exceptions/#obstore.exceptions.JoinError","title":"JoinError","text":"<p>               Bases: <code>BaseError</code></p> <p>Error when <code>tokio::spawn</code> failed.</p>"},{"location":"api/exceptions/#obstore.exceptions.NotFoundError","title":"NotFoundError","text":"<p>               Bases: <code>BaseError</code></p> <p>Error when the object is not found at given location.</p>"},{"location":"api/exceptions/#obstore.exceptions.NotModifiedError","title":"NotModifiedError","text":"<p>               Bases: <code>BaseError</code></p> <p>Error when the object at the location isn't modified.</p>"},{"location":"api/exceptions/#obstore.exceptions.NotSupportedError","title":"NotSupportedError","text":"<p>               Bases: <code>BaseError</code></p> <p>Error when the attempted operation is not supported.</p>"},{"location":"api/exceptions/#obstore.exceptions.PermissionDeniedError","title":"PermissionDeniedError","text":"<p>               Bases: <code>BaseError</code></p> <p>Permission denied.</p> <p>Error when the used credentials don't have enough permission to perform the requested operation.</p>"},{"location":"api/exceptions/#obstore.exceptions.PreconditionError","title":"PreconditionError","text":"<p>               Bases: <code>BaseError</code></p> <p>Error when the required conditions failed for the operation.</p>"},{"location":"api/exceptions/#obstore.exceptions.UnauthenticatedError","title":"UnauthenticatedError","text":"<p>               Bases: <code>BaseError</code></p> <p>Error when the used credentials lack valid authentication.</p>"},{"location":"api/exceptions/#obstore.exceptions.UnknownConfigurationKeyError","title":"UnknownConfigurationKeyError","text":"<p>               Bases: <code>BaseError</code></p> <p>Error when a configuration key is invalid for the store used.</p>"},{"location":"api/file/","title":"File-like Object","text":"<p>Native support for reading from object stores as a file-like object.</p> <p>Use <code>obstore.open_reader</code> or <code>obstore.open_reader_async</code> to open readable files. Use <code>obstore.open_writer</code> or <code>obstore.open_writer_async</code> to open writable files.</p>"},{"location":"api/file/#obstore.open_reader","title":"obstore.open_reader","text":"<pre><code>open_reader(\n    store: ObjectStore, path: str, *, buffer_size: int = 1024 * 1024\n) -&gt; ReadableFile\n</code></pre> <p>Open a readable file object from the specified location.</p> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>ObjectStore</code>)           \u2013            <p>The ObjectStore instance to use.</p> </li> <li> <code>path</code>               (<code>str</code>)           \u2013            <p>The path within ObjectStore to retrieve.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>buffer_size</code>               (<code>int</code>)           \u2013            <p>The minimum number of bytes to read in a single request. Up to <code>buffer_size</code> bytes will be buffered in memory.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ReadableFile</code>           \u2013            <p>ReadableFile</p> </li> </ul>"},{"location":"api/file/#obstore.open_reader_async","title":"obstore.open_reader_async  <code>async</code>","text":"<pre><code>open_reader_async(\n    store: ObjectStore, path: str, *, buffer_size: int = 1024 * 1024\n) -&gt; AsyncReadableFile\n</code></pre> <p>Call <code>open_reader</code> asynchronously, returning a readable file object with asynchronous operations.</p> <p>Refer to the documentation for open_reader.</p>"},{"location":"api/file/#obstore.open_writer","title":"obstore.open_writer","text":"<pre><code>open_writer(\n    store: ObjectStore,\n    path: str,\n    *,\n    attributes: Attributes | None = None,\n    buffer_size: int = 10 * 1024 * 1024,\n    tags: dict[str, str] | None = None,\n    max_concurrency: int = 12,\n) -&gt; WritableFile\n</code></pre> <p>Open a writable file object at the specified location.</p> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>ObjectStore</code>)           \u2013            <p>The ObjectStore instance to use.</p> </li> <li> <code>path</code>               (<code>str</code>)           \u2013            <p>The path within ObjectStore to retrieve.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>attributes</code>               (<code>Attributes | None</code>)           \u2013            <p>Provide a set of <code>Attributes</code>. Defaults to <code>None</code>.</p> </li> <li> <code>buffer_size</code>               (<code>int</code>)           \u2013            <p>The underlying buffer size to use. Up to <code>buffer_size</code> bytes will be buffered in memory. If <code>buffer_size</code> is exceeded, data will be uploaded as a multipart upload in chunks of <code>buffer_size</code>.</p> </li> <li> <code>tags</code>               (<code>dict[str, str] | None</code>)           \u2013            <p>Provide tags for this object. Defaults to <code>None</code>.</p> </li> <li> <code>max_concurrency</code>               (<code>int</code>)           \u2013            <p>The maximum number of chunks to upload concurrently. Defaults to 12.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>WritableFile</code>           \u2013            <p>ReadableFile</p> </li> </ul>"},{"location":"api/file/#obstore.open_writer_async","title":"obstore.open_writer_async","text":"<pre><code>open_writer_async(\n    store: ObjectStore,\n    path: str,\n    *,\n    attributes: Attributes | None = None,\n    buffer_size: int = 10 * 1024 * 1024,\n    tags: dict[str, str] | None = None,\n    max_concurrency: int = 12,\n) -&gt; AsyncWritableFile\n</code></pre> <p>Open an asynchronous writable file object at the specified location.</p> <p>Refer to the documentation for open_writer.</p>"},{"location":"api/file/#obstore.ReadableFile","title":"obstore.ReadableFile","text":"<p>A synchronous-buffered reader that implements a similar interface as a Python <code>BufferedReader</code>.</p> <p>Internally this maintains a buffer of the requested size, and uses <code>get_range</code> to populate its internal buffer once depleted. This buffer is cleared on seek.</p> <p>Whilst simple, this interface will typically be outperformed by the native <code>obstore</code> methods that better map to the network APIs. This is because most object stores have very high first-byte latencies, on the order of 100-200ms, and so avoiding unnecessary round-trips is critical to throughput.</p> <p>Systems looking to sequentially scan a file should instead consider using <code>get</code>, or <code>get_range</code> to read a particular range.</p> <p>Systems looking to read multiple ranges of a file should instead consider using <code>get_ranges</code>, which will optimise the vectored IO.</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore import ReadableFile\n</code></pre>"},{"location":"api/file/#obstore.ReadableFile.meta","title":"meta  <code>property</code>","text":"<pre><code>meta: ObjectMeta\n</code></pre> <p>Access the metadata of the underlying file.</p>"},{"location":"api/file/#obstore.ReadableFile.size","title":"size  <code>property</code>","text":"<pre><code>size: int\n</code></pre> <p>The size in bytes of the object.</p>"},{"location":"api/file/#obstore.ReadableFile.close","title":"close","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the current file.</p> <p>This is currently a no-op.</p>"},{"location":"api/file/#obstore.ReadableFile.read","title":"read","text":"<pre><code>read(size: int | None = None) -&gt; Bytes\n</code></pre> <p>Read up to <code>size</code> bytes from the object and return them.</p> <p>As a convenience, if size is unspecified or <code>None</code>, all bytes until EOF are returned.</p>"},{"location":"api/file/#obstore.ReadableFile.readall","title":"readall","text":"<pre><code>readall() -&gt; Bytes\n</code></pre> <p>Read and return all the bytes from the stream until EOF.</p>"},{"location":"api/file/#obstore.ReadableFile.readline","title":"readline","text":"<pre><code>readline() -&gt; Bytes\n</code></pre> <p>Read a single line of the file, up until the next newline character.</p>"},{"location":"api/file/#obstore.ReadableFile.readlines","title":"readlines","text":"<pre><code>readlines(hint: int = -1) -&gt; list[Bytes]\n</code></pre> <p>Read all remaining lines into a list of buffers.</p>"},{"location":"api/file/#obstore.ReadableFile.seek","title":"seek","text":"<pre><code>seek(offset: int, whence: int = ...) -&gt; int\n</code></pre> <p>Change the stream position.</p> <p>Change the stream position to the given byte <code>offset</code>, interpreted relative to the position indicated by <code>whence</code>, and return the new absolute position. Values for <code>whence</code> are:</p> <ul> <li><code>os.SEEK_SET</code> or 0: start of the stream (the default); <code>offset</code> should be zero or positive</li> <li><code>os.SEEK_CUR</code> or 1: current stream position; <code>offset</code> may be negative</li> <li><code>os.SEEK_END</code> or 2: end of the stream; <code>offset</code> is usually negative</li> </ul>"},{"location":"api/file/#obstore.ReadableFile.seekable","title":"seekable","text":"<pre><code>seekable() -&gt; bool\n</code></pre> <p>Return True if the stream supports random access.</p>"},{"location":"api/file/#obstore.ReadableFile.tell","title":"tell","text":"<pre><code>tell() -&gt; int\n</code></pre> <p>Return the current stream position.</p>"},{"location":"api/file/#obstore.AsyncReadableFile","title":"obstore.AsyncReadableFile","text":"<p>An async-buffered reader that implements a similar interface as a Python <code>BufferedReader</code>.</p> <p>Internally this maintains a buffer of the requested size, and uses <code>get_range</code> to populate its internal buffer once depleted. This buffer is cleared on seek.</p> <p>Whilst simple, this interface will typically be outperformed by the native <code>obstore</code> methods that better map to the network APIs. This is because most object stores have very high first-byte latencies, on the order of 100-200ms, and so avoiding unnecessary round-trips is critical to throughput.</p> <p>Systems looking to sequentially scan a file should instead consider using <code>get</code>, or <code>get_range</code> to read a particular range.</p> <p>Systems looking to read multiple ranges of a file should instead consider using <code>get_ranges</code>, which will optimise the vectored IO.</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore import AsyncReadableFile\n</code></pre>"},{"location":"api/file/#obstore.AsyncReadableFile.meta","title":"meta  <code>property</code>","text":"<pre><code>meta: ObjectMeta\n</code></pre> <p>Access the metadata of the underlying file.</p>"},{"location":"api/file/#obstore.AsyncReadableFile.size","title":"size  <code>property</code>","text":"<pre><code>size: int\n</code></pre> <p>The size in bytes of the object.</p>"},{"location":"api/file/#obstore.AsyncReadableFile.close","title":"close","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the current file.</p> <p>This is currently a no-op.</p>"},{"location":"api/file/#obstore.AsyncReadableFile.read","title":"read  <code>async</code>","text":"<pre><code>read(size: int | None = None) -&gt; Bytes\n</code></pre> <p>Read up to <code>size</code> bytes from the object and return them.</p> <p>As a convenience, if size is unspecified or <code>None</code>, all bytes until EOF are returned.</p>"},{"location":"api/file/#obstore.AsyncReadableFile.readall","title":"readall  <code>async</code>","text":"<pre><code>readall() -&gt; Bytes\n</code></pre> <p>Read and return all the bytes from the stream until EOF.</p>"},{"location":"api/file/#obstore.AsyncReadableFile.readline","title":"readline  <code>async</code>","text":"<pre><code>readline() -&gt; Bytes\n</code></pre> <p>Read a single line of the file, up until the next newline character.</p>"},{"location":"api/file/#obstore.AsyncReadableFile.readlines","title":"readlines  <code>async</code>","text":"<pre><code>readlines(hint: int = -1) -&gt; list[Bytes]\n</code></pre> <p>Read all remaining lines into a list of buffers.</p>"},{"location":"api/file/#obstore.AsyncReadableFile.seek","title":"seek  <code>async</code>","text":"<pre><code>seek(offset: int, whence: int = ...) -&gt; int\n</code></pre> <p>Change the stream position.</p> <p>Change the stream position to the given byte <code>offset</code>, interpreted relative to the position indicated by <code>whence</code>, and return the new absolute position. Values for <code>whence</code> are:</p> <ul> <li><code>os.SEEK_SET</code> or 0: start of the stream (the default); <code>offset</code> should be zero or positive</li> <li><code>os.SEEK_CUR</code> or 1: current stream position; <code>offset</code> may be negative</li> <li><code>os.SEEK_END</code> or 2: end of the stream; <code>offset</code> is usually negative</li> </ul>"},{"location":"api/file/#obstore.AsyncReadableFile.seekable","title":"seekable","text":"<pre><code>seekable() -&gt; bool\n</code></pre> <p>Return True if the stream supports random access.</p>"},{"location":"api/file/#obstore.AsyncReadableFile.tell","title":"tell  <code>async</code>","text":"<pre><code>tell() -&gt; int\n</code></pre> <p>Return the current stream position.</p>"},{"location":"api/file/#obstore.WritableFile","title":"obstore.WritableFile","text":"<p>               Bases: <code>AbstractContextManager</code></p> <p>A buffered writable file object with synchronous operations.</p> <p>This implements a similar interface as a Python <code>BufferedWriter</code>.</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore import WritableFile\n</code></pre>"},{"location":"api/file/#obstore.WritableFile.close","title":"close","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the current file.</p>"},{"location":"api/file/#obstore.WritableFile.closed","title":"closed","text":"<pre><code>closed() -&gt; bool\n</code></pre> <p>Check whether this file has been closed.</p> <p>Note that this is a method, not an attribute.</p>"},{"location":"api/file/#obstore.WritableFile.flush","title":"flush","text":"<pre><code>flush() -&gt; None\n</code></pre> <p>Flushes this output stream, ensuring that all intermediately buffered contents reach their destination.</p>"},{"location":"api/file/#obstore.WritableFile.write","title":"write","text":"<pre><code>write(buffer: bytes | Buffer) -&gt; int\n</code></pre> <p>Write the bytes-like object, <code>buffer</code>, and return the number of bytes written.</p>"},{"location":"api/file/#obstore.AsyncWritableFile","title":"obstore.AsyncWritableFile","text":"<p>               Bases: <code>AbstractAsyncContextManager</code></p> <p>A buffered writable file object with asynchronous operations.</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore import AsyncWritableFile\n</code></pre>"},{"location":"api/file/#obstore.AsyncWritableFile.close","title":"close  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close the current file.</p>"},{"location":"api/file/#obstore.AsyncWritableFile.closed","title":"closed  <code>async</code>","text":"<pre><code>closed() -&gt; bool\n</code></pre> <p>Check whether this file has been closed.</p> <p>Note that this is an async method, not an attribute.</p>"},{"location":"api/file/#obstore.AsyncWritableFile.flush","title":"flush  <code>async</code>","text":"<pre><code>flush() -&gt; None\n</code></pre> <p>Flushes this output stream, ensuring that all intermediately buffered contents reach their destination.</p>"},{"location":"api/file/#obstore.AsyncWritableFile.write","title":"write  <code>async</code>","text":"<pre><code>write(buffer: bytes | Buffer) -&gt; int\n</code></pre> <p>Write the bytes-like object, <code>buffer</code>, and return the number of bytes written.</p>"},{"location":"api/fsspec/","title":"obstore.fsspec","text":""},{"location":"api/fsspec/#obstore.fsspec","title":"obstore.fsspec","text":"<p>Integration with the fsspec library.</p> <p>The fsspec integration is best effort and may not provide the same performance as the rest of obstore. If you find any bugs with this integration, please file an issue.</p> <p>The underlying <code>object_store</code> Rust crate cautions against relying too strongly on stateful filesystem representations of object stores:</p> <p>The ObjectStore interface is designed to mirror the APIs of object stores and not filesystems, and thus has stateless APIs instead of cursor based interfaces such as Read or Seek available in filesystems.</p> <p>This design provides the following advantages:</p> <ul> <li>All operations are atomic, and readers cannot observe partial and/or failed writes</li> <li>Methods map directly to object store APIs, providing both efficiency and   predictability</li> <li>Abstracts away filesystem and operating system specific quirks, ensuring portability</li> <li>Allows for functionality not native to filesystems, such as operation preconditions   and atomic multipart uploads</li> </ul> <p>Where possible, implementations should use the underlying <code>obstore</code> APIs directly. Only where this is not possible should users fall back to this fsspec integration.</p>"},{"location":"api/fsspec/#obstore.fsspec.SUPPORTED_PROTOCOLS","title":"SUPPORTED_PROTOCOLS  <code>module-attribute</code>","text":"<pre><code>SUPPORTED_PROTOCOLS: set[str] = {\n    \"abfs\",\n    \"abfss\",\n    \"adl\",\n    \"az\",\n    \"azure\",\n    \"file\",\n    \"gcs\",\n    \"gs\",\n    \"http\",\n    \"https\",\n    \"memory\",\n    \"s3\",\n    \"s3a\",\n}\n</code></pre> <p>All supported protocols.</p>"},{"location":"api/fsspec/#obstore.fsspec.SUPPORTED_PROTOCOLS_T","title":"SUPPORTED_PROTOCOLS_T  <code>module-attribute</code>","text":"<pre><code>SUPPORTED_PROTOCOLS_T = Literal[\n    \"abfs\",\n    \"abfss\",\n    \"adl\",\n    \"az\",\n    \"azure\",\n    \"file\",\n    \"gcs\",\n    \"gs\",\n    \"http\",\n    \"https\",\n    \"memory\",\n    \"s3\",\n    \"s3a\",\n]\n</code></pre> <p>A type hint for all supported protocols.</p>"},{"location":"api/fsspec/#obstore.fsspec.BufferedFile","title":"BufferedFile","text":"<p>               Bases: <code>AbstractBufferedFile</code></p> <p>A buffered readable or writable file.</p> <p>This is a wrapper around <code>obstore.ReadableFile</code> and <code>obstore.WritableFile</code>. If you don't have a need to use the fsspec integration, you may be better served by using <code>open_reader</code> or <code>open_writer</code> directly.</p>"},{"location":"api/fsspec/#obstore.fsspec.BufferedFile.loc","title":"loc  <code>property</code> <code>writable</code>","text":"<pre><code>loc: int\n</code></pre> <p>Get current file location.</p>"},{"location":"api/fsspec/#obstore.fsspec.BufferedFile.__init__","title":"__init__","text":"<pre><code>__init__(\n    fs: FsspecStore,\n    path: str,\n    mode: Literal[\"rb\"] = \"rb\",\n    *,\n    buffer_size: int = 1024 * 1024,\n    **kwargs: Any,\n) -&gt; None\n</code></pre><pre><code>__init__(\n    fs: FsspecStore,\n    path: str,\n    mode: Literal[\"wb\"],\n    *,\n    buffer_size: int = 10 * 1024 * 1024,\n    attributes: Attributes | None = None,\n    tags: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; None\n</code></pre> <pre><code>__init__(\n    fs: FsspecStore,\n    path: str,\n    mode: Literal[\"rb\", \"wb\"] = \"rb\",\n    *,\n    buffer_size: int | None = None,\n    attributes: Attributes | None = None,\n    tags: dict[str, str] | None = None,\n    **kwargs: Any,\n) -&gt; None\n</code></pre> <p>Create new buffered file.</p> <p>Parameters:</p> <ul> <li> <code>fs</code>               (<code>FsspecStore</code>)           \u2013            <p>The underlying fsspec store to read from.</p> </li> <li> <code>path</code>               (<code>str</code>)           \u2013            <p>The path within the store to use.</p> </li> <li> <code>mode</code>               (<code>Literal['rb', 'wb']</code>, default:                   <code>'rb'</code> )           \u2013            <p><code>\"rb\"</code> for a readable binary file or <code>\"wb\"</code> for a writable binary file. Defaults to \"rb\".</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>attributes</code>               (<code>Attributes | None</code>)           \u2013            <p>Provide a set of <code>Attributes</code>. Only used when writing. Defaults to <code>None</code>.</p> </li> <li> <code>buffer_size</code>               (<code>int | None</code>)           \u2013            <p>Up to <code>buffer_size</code> bytes will be buffered in memory. When reading: The minimum number of bytes to read in a single request. When writing:  If <code>buffer_size</code> is exceeded, data will be uploaded as a multipart upload in chunks of <code>buffer_size</code>. Defaults to None.</p> </li> <li> <code>tags</code>               (<code>dict[str, str] | None</code>)           \u2013            <p>Provide tags for this object. Only used when writing. Defaults to <code>None</code>.</p> </li> <li> <code>kwargs</code>               (<code>Any</code>)           \u2013            <p>Keyword arguments passed on to <code>fsspec.spec.AbstractBufferedFile</code>.</p> </li> </ul>"},{"location":"api/fsspec/#obstore.fsspec.BufferedFile.close","title":"close","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close file. Ensure flushing the buffer.</p>"},{"location":"api/fsspec/#obstore.fsspec.BufferedFile.flush","title":"flush","text":"<pre><code>flush(force: bool = False) -&gt; None\n</code></pre> <p>Write buffered data to backend store.</p> <p>Writes the current buffer, if it is larger than the block-size, or if the file is being closed.</p> <p>Parameters:</p> <ul> <li> <code>force</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Unused.</p> </li> </ul>"},{"location":"api/fsspec/#obstore.fsspec.BufferedFile.read","title":"read","text":"<pre><code>read(length: int = -1) -&gt; bytes\n</code></pre> <p>Return bytes from the remote file.</p> <p>Parameters:</p> <ul> <li> <code>length</code>               (<code>int</code>, default:                   <code>-1</code> )           \u2013            <p>if positive, returns up to this many bytes; if negative, return all remaining bytes.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bytes</code>           \u2013            <p>Data in bytes</p> </li> </ul>"},{"location":"api/fsspec/#obstore.fsspec.BufferedFile.readline","title":"readline","text":"<pre><code>readline() -&gt; bytes\n</code></pre> <p>Read until first occurrence of newline character.</p>"},{"location":"api/fsspec/#obstore.fsspec.BufferedFile.readlines","title":"readlines","text":"<pre><code>readlines() -&gt; list[bytes]\n</code></pre> <p>Return all data, split by the newline character.</p>"},{"location":"api/fsspec/#obstore.fsspec.BufferedFile.seek","title":"seek","text":"<pre><code>seek(loc: int, whence: int = 0) -&gt; int\n</code></pre> <p>Set current file location.</p> <p>Parameters:</p> <ul> <li> <code>loc</code>               (<code>int</code>)           \u2013            <p>byte location</p> </li> <li> <code>whence</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>Either - <code>0</code>: from start of file - <code>1</code>: current location - <code>2</code>: end of file</p> </li> </ul>"},{"location":"api/fsspec/#obstore.fsspec.BufferedFile.tell","title":"tell","text":"<pre><code>tell() -&gt; int\n</code></pre> <p>Get current file location.</p>"},{"location":"api/fsspec/#obstore.fsspec.BufferedFile.write","title":"write","text":"<pre><code>write(data: bytes) -&gt; int\n</code></pre> <p>Write data to buffer.</p> <p>Parameters:</p> <ul> <li> <code>data</code>               (<code>bytes</code>)           \u2013            <p>Set of bytes to be written.</p> </li> </ul>"},{"location":"api/fsspec/#obstore.fsspec.FsspecStore","title":"FsspecStore","text":"<p>               Bases: <code>AsyncFileSystem</code></p> <p>An fsspec implementation based on a obstore Store.</p> <p>You should be able to pass an instance of this class into any API that expects an fsspec-style object.</p>"},{"location":"api/fsspec/#obstore.fsspec.FsspecStore.__init__","title":"__init__","text":"<pre><code>__init__(\n    protocol: Literal[\"s3\", \"s3a\"],\n    *args: Any,\n    config: S3Config | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    credential_provider: S3CredentialProvider | None = None,\n    asynchronous: bool = False,\n    max_cache_size: int = 10,\n    loop: Any = None,\n    batch_size: int | None = None,\n    **kwargs: Unpack[S3Config],\n) -&gt; None\n</code></pre><pre><code>__init__(\n    protocol: Literal[\"gs\"],\n    *args: Any,\n    config: GCSConfig | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    credential_provider: GCSCredentialProvider | None = None,\n    asynchronous: bool = False,\n    max_cache_size: int = 10,\n    loop: Any = None,\n    batch_size: int | None = None,\n    **kwargs: Unpack[GCSConfig],\n) -&gt; None\n</code></pre><pre><code>__init__(\n    protocol: Literal[\"az\", \"adl\", \"azure\", \"abfs\", \"abfss\"],\n    *args: Any,\n    config: AzureConfig | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    credential_provider: AzureCredentialProvider | None = None,\n    asynchronous: bool = False,\n    max_cache_size: int = 10,\n    loop: Any = None,\n    batch_size: int | None = None,\n    **kwargs: Unpack[AzureConfig],\n) -&gt; None\n</code></pre><pre><code>__init__(\n    protocol: Literal[\"file\"],\n    *args: Any,\n    config: None = None,\n    client_options: None = None,\n    retry_config: None = None,\n    asynchronous: bool = False,\n    max_cache_size: int = 10,\n    loop: Any = None,\n    batch_size: int | None = None,\n    automatic_cleanup: bool = False,\n    mkdir: bool = False,\n) -&gt; None\n</code></pre> <pre><code>__init__(\n    protocol: SUPPORTED_PROTOCOLS_T | str | None = None,\n    *args: Any,\n    config: S3Config | GCSConfig | AzureConfig | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    credential_provider: S3CredentialProvider\n    | GCSCredentialProvider\n    | AzureCredentialProvider\n    | None = None,\n    asynchronous: bool = False,\n    max_cache_size: int = 10,\n    loop: Any = None,\n    batch_size: int | None = None,\n    **kwargs: Any,\n) -&gt; None\n</code></pre> <p>Construct a new FsspecStore.</p> <p>Parameters:</p> <ul> <li> <code>protocol</code>               (<code>SUPPORTED_PROTOCOLS_T | str | None</code>, default:                   <code>None</code> )           \u2013            <p>The storage protocol to use, such as \"s3\", \"gcs\", or \"abfs\". If <code>None</code>, the default class-level protocol is used. Default to None.</p> </li> <li> <code>args</code>               (<code>Any</code>, default:                   <code>()</code> )           \u2013            <p>positional arguments passed on to the <code>fsspec.asyn.AsyncFileSystem</code> constructor.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>config</code>               (<code>S3Config | GCSConfig | AzureConfig | None</code>)           \u2013            <p>Configuration for the cloud storage provider, which can be one of S3Config, GCSConfig, AzureConfig, or AzureConfigInput. Any of these values will be applied after checking for environment variables. If <code>None</code>, no cloud storage configuration is applied beyond what is found in environment variables.</p> </li> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>Additional options for configuring the client.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Configuration for handling request errors.</p> </li> <li> <code>credential_provider</code>               (<code>S3CredentialProvider | GCSCredentialProvider | AzureCredentialProvider | None</code>)           \u2013            <p>A callback to provide custom credentials to the underlying store classes.</p> </li> <li> <code>asynchronous</code>               (<code>bool</code>)           \u2013            <p>Set to <code>True</code> if this instance is meant to be be called using the fsspec async API. This should only be set to true when running within a coroutine.</p> </li> <li> <code>max_cache_size</code>               (<code>int</code>)           \u2013            <p>The maximum number of stores the cache should keep. A cached store is kept internally for each bucket name. Defaults to 10.</p> </li> <li> <code>loop</code>               (<code>Any</code>)           \u2013            <p>since both fsspec/python and tokio/rust may be using loops, this should be kept <code>None</code> for now, and will not be used.</p> </li> <li> <code>batch_size</code>               (<code>int | None</code>)           \u2013            <p>some operations on many files will batch their requests; if you are seeing timeouts, you may want to set this number smaller than the defaults, which are determined in <code>fsspec.asyn._get_batch_size</code>.</p> </li> <li> <code>kwargs</code>               (<code>Any</code>)           \u2013            <p>per-store configuration passed down to store-specific builders.</p> </li> </ul> <p>Examples:</p> <pre><code>from obstore.fsspec import FsspecStore\n\nstore = FsspecStore(\"https\")\nresp = store.cat_file(\"https://raw.githubusercontent.com/developmentseed/obstore/refs/heads/main/README.md\")\nassert resp.startswith(b\"# obstore\")\n</code></pre>"},{"location":"api/fsspec/#obstore.fsspec.FsspecStore.modified","title":"modified","text":"<pre><code>modified(path: str) -&gt; datetime\n</code></pre> <p>Return the modified timestamp of a file as a <code>datetime.datetime</code>.</p>"},{"location":"api/fsspec/#obstore.fsspec.register","title":"register","text":"<pre><code>register(\n    protocol: SUPPORTED_PROTOCOLS_T\n    | str\n    | Iterable[SUPPORTED_PROTOCOLS_T]\n    | Iterable[str]\n    | None = None,\n    *,\n    asynchronous: bool = False,\n) -&gt; None\n</code></pre> <p>Dynamically register a subclass of FsspecStore for the given protocol(s).</p> <p>This function creates a new subclass of FsspecStore with the specified protocol and registers it with fsspec. If multiple protocols are provided, the function registers each one individually.</p> <p>Parameters:</p> <ul> <li> <code>protocol</code>               (<code>SUPPORTED_PROTOCOLS_T | str | Iterable[SUPPORTED_PROTOCOLS_T] | Iterable[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>A single protocol (e.g., \"s3\", \"gcs\", \"abfs\") or a list of protocols to register FsspecStore for.</p> <p>Defaults to <code>None</code>, which will register <code>obstore</code> as the provider for all supported protocols except for <code>file://</code> and <code>memory://</code>. If you wish to use <code>obstore</code> via fsspec for <code>file://</code> or <code>memory://</code> URLs, list them explicitly.</p> </li> <li> <code>asynchronous</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If <code>True</code>, the registered store will support asynchronous operations. Defaults to <code>False</code>.</p> </li> </ul> <p>Example: <pre><code># Register obstore as the default handler for all supported protocols except for\n# `memory://` and `file://`\nregister()\n\nregister(\"s3\")\n\n# Registers an async store for \"s3\"\nregister(\"s3\", asynchronous=True)\n\n# Registers both \"gcs\" and \"abfs\"\nregister([\"gcs\", \"abfs\"])\n</code></pre></p> Notes <ul> <li>Each protocol gets a dynamically generated subclass named   <code>FsspecStore_&lt;protocol&gt;</code>. This avoids modifying the original   FsspecStore class.</li> </ul>"},{"location":"api/get/","title":"Get","text":""},{"location":"api/get/#obstore.get","title":"obstore.get","text":"<pre><code>get(\n    store: ObjectStore, path: str, *, options: GetOptions | None = None\n) -&gt; GetResult\n</code></pre> <p>Return the bytes that are stored at the specified location.</p> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>ObjectStore</code>)           \u2013            <p>The ObjectStore instance to use.</p> </li> <li> <code>path</code>               (<code>str</code>)           \u2013            <p>The path within ObjectStore to retrieve.</p> </li> <li> <code>options</code>               (<code>GetOptions | None</code>, default:                   <code>None</code> )           \u2013            <p>options for accessing the file. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>GetResult</code>           \u2013            <p>GetResult</p> </li> </ul>"},{"location":"api/get/#obstore.get_async","title":"obstore.get_async  <code>async</code>","text":"<pre><code>get_async(\n    store: ObjectStore, path: str, *, options: GetOptions | None = None\n) -&gt; GetResult\n</code></pre> <p>Call <code>get</code> asynchronously.</p> <p>Refer to the documentation for get.</p>"},{"location":"api/get/#obstore.get_range","title":"obstore.get_range","text":"<pre><code>get_range(\n    store: ObjectStore,\n    path: str,\n    *,\n    start: int,\n    end: int | None = None,\n    length: int | None = None,\n) -&gt; Bytes\n</code></pre> <p>Return the bytes that are stored at the specified location in the given byte range.</p> <p>If the given range is zero-length or starts after the end of the object, an error will be returned. Additionally, if the range ends after the end of the object, the entire remainder of the object will be returned. Otherwise, the exact requested range will be returned.</p> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>ObjectStore</code>)           \u2013            <p>The ObjectStore instance to use.</p> </li> <li> <code>path</code>               (<code>str</code>)           \u2013            <p>The path within ObjectStore to retrieve.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>start</code>               (<code>int</code>)           \u2013            <p>The start of the byte range.</p> </li> <li> <code>end</code>               (<code>int | None</code>)           \u2013            <p>The end of the byte range (exclusive). Either <code>end</code> or <code>length</code> must be non-None.</p> </li> <li> <code>length</code>               (<code>int | None</code>)           \u2013            <p>The number of bytes of the byte range. Either <code>end</code> or <code>length</code> must be non-None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Bytes</code>           \u2013            <p>A <code>Bytes</code> object implementing the Python buffer protocol, allowing zero-copy access to the underlying memory provided by Rust.</p> </li> </ul>"},{"location":"api/get/#obstore.get_range_async","title":"obstore.get_range_async  <code>async</code>","text":"<pre><code>get_range_async(\n    store: ObjectStore,\n    path: str,\n    *,\n    start: int,\n    end: int | None = None,\n    length: int | None = None,\n) -&gt; Bytes\n</code></pre> <p>Call <code>get_range</code> asynchronously.</p> <p>Refer to the documentation for get_range.</p>"},{"location":"api/get/#obstore.get_ranges","title":"obstore.get_ranges","text":"<pre><code>get_ranges(\n    store: ObjectStore,\n    path: str,\n    *,\n    starts: Sequence[int],\n    ends: Sequence[int] | None = None,\n    lengths: Sequence[int] | None = None,\n) -&gt; list[Bytes]\n</code></pre> <p>Return the bytes stored at the specified location in the given byte ranges.</p> <p>To improve performance this will:</p> <ul> <li>Transparently combine ranges less than 1MB apart into a single underlying request</li> <li>Make multiple <code>fetch</code> requests in parallel (up to maximum of 10)</li> </ul> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>ObjectStore</code>)           \u2013            <p>The ObjectStore instance to use.</p> </li> <li> <code>path</code>               (<code>str</code>)           \u2013            <p>The path within ObjectStore to retrieve.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>starts</code>               (<code>Sequence[int]</code>)           \u2013            <p>A sequence of <code>int</code> where each offset starts.</p> </li> <li> <code>ends</code>               (<code>Sequence[int] | None</code>)           \u2013            <p>A sequence of <code>int</code> where each offset ends (exclusive). Either <code>ends</code> or <code>lengths</code> must be non-None.</p> </li> <li> <code>lengths</code>               (<code>Sequence[int] | None</code>)           \u2013            <p>A sequence of <code>int</code> with the number of bytes of each byte range. Either <code>ends</code> or <code>lengths</code> must be non-None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[Bytes]</code>           \u2013            <p>A sequence of <code>Bytes</code>, one for each range. This <code>Bytes</code> object implements the Python buffer protocol, allowing zero-copy access to the underlying memory provided by Rust.</p> </li> </ul>"},{"location":"api/get/#obstore.get_ranges_async","title":"obstore.get_ranges_async  <code>async</code>","text":"<pre><code>get_ranges_async(\n    store: ObjectStore,\n    path: str,\n    *,\n    starts: Sequence[int],\n    ends: Sequence[int] | None = None,\n    lengths: Sequence[int] | None = None,\n) -&gt; list[Bytes]\n</code></pre> <p>Call <code>get_ranges</code> asynchronously.</p> <p>Refer to the documentation for get_ranges.</p>"},{"location":"api/get/#obstore.GetOptions","title":"obstore.GetOptions","text":"<p>               Bases: <code>TypedDict</code></p> <p>Options for a get request.</p> <p>All options are optional.</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore import GetOptions\n</code></pre>"},{"location":"api/get/#obstore.GetOptions.head","title":"head  <code>instance-attribute</code>","text":"<pre><code>head: bool\n</code></pre> <p>Request transfer of no content datatracker.ietf.org/doc/html/rfc9110#name-head</p>"},{"location":"api/get/#obstore.GetOptions.if_match","title":"if_match  <code>instance-attribute</code>","text":"<pre><code>if_match: str | None\n</code></pre> <p>Request will succeed if the <code>ObjectMeta::e_tag</code> matches otherwise returning <code>PreconditionError</code>. See datatracker.ietf.org/doc/html/rfc9110#name-if-match Examples: <pre><code>If-Match: \"xyzzy\"\nIf-Match: \"xyzzy\", \"r2d2xxxx\", \"c3piozzzz\"\nIf-Match: *\n</code></pre></p>"},{"location":"api/get/#obstore.GetOptions.if_modified_since","title":"if_modified_since  <code>instance-attribute</code>","text":"<pre><code>if_modified_since: datetime | None\n</code></pre> <p>Request will succeed if the object has not been modified since otherwise returning <code>PreconditionError</code>. Some stores, such as S3, will only return <code>NotModified</code> for exact timestamp matches, instead of for any timestamp greater than or equal. datatracker.ietf.org/doc/html/rfc9110#section-13.1.4</p>"},{"location":"api/get/#obstore.GetOptions.if_none_match","title":"if_none_match  <code>instance-attribute</code>","text":"<pre><code>if_none_match: str | None\n</code></pre> <p>Request will succeed if the <code>ObjectMeta::e_tag</code> does not match otherwise returning <code>NotModifiedError</code>. See datatracker.ietf.org/doc/html/rfc9110#section-13.1.2 Examples: <pre><code>If-None-Match: \"xyzzy\"\nIf-None-Match: \"xyzzy\", \"r2d2xxxx\", \"c3piozzzz\"\nIf-None-Match: *\n</code></pre></p>"},{"location":"api/get/#obstore.GetOptions.if_unmodified_since","title":"if_unmodified_since  <code>instance-attribute</code>","text":"<pre><code>if_unmodified_since: datetime | None\n</code></pre> <p>Request will succeed if the object has been modified since datatracker.ietf.org/doc/html/rfc9110#section-13.1.3</p>"},{"location":"api/get/#obstore.GetOptions.range","title":"range  <code>instance-attribute</code>","text":"<pre><code>range: tuple[int, int] | Sequence[int] | OffsetRange | SuffixRange\n</code></pre> <p>Request transfer of only the specified range of bytes otherwise returning <code>NotModifiedError</code>. The semantics of this tuple are: - <code>(int, int)</code>: Request a specific range of bytes <code>(start, end)</code>.     If the given range is zero-length or starts after the end of the object, an     error will be returned. Additionally, if the range ends after the end of the     object, the entire remainder of the object will be returned. Otherwise, the     exact requested range will be returned.     The <code>end</code> offset is exclusive. - <code>{\"offset\": int}</code>: Request all bytes starting from a given byte offset.     This is equivalent to <code>bytes={int}-</code> as an HTTP header. - <code>{\"suffix\": int}</code>: Request the last <code>int</code> bytes. Note that here, <code>int</code> is the     size of the request, not the byte offset. This is equivalent to <code>bytes=-{int}</code>     as an HTTP header. datatracker.ietf.org/doc/html/rfc9110#name-range</p>"},{"location":"api/get/#obstore.GetOptions.version","title":"version  <code>instance-attribute</code>","text":"<pre><code>version: str | None\n</code></pre> <p>Request a particular object version</p>"},{"location":"api/get/#obstore.GetResult","title":"obstore.GetResult","text":"<p>Result for a get request.</p> <p>You can materialize the entire buffer by using either <code>bytes</code> or <code>bytes_async</code>, or you can stream the result using <code>stream</code>. <code>__iter__</code> and <code>__aiter__</code> are implemented as aliases to <code>stream</code>, so you can alternatively call <code>iter()</code> or <code>aiter()</code> on <code>GetResult</code> to start an iterator.</p> <p>Using as an async iterator: <pre><code>resp = await obs.get_async(store, path)\n# 5MB chunk size in stream\nstream = resp.stream(min_chunk_size=5 * 1024 * 1024)\nasync for buf in stream:\n    print(len(buf))\n</code></pre></p> <p>Using as a sync iterator: <pre><code>resp = obs.get(store, path)\n# 20MB chunk size in stream\nstream = resp.stream(min_chunk_size=20 * 1024 * 1024)\nfor buf in stream:\n    print(len(buf))\n</code></pre></p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore import GetResult\n</code></pre>"},{"location":"api/get/#obstore.GetResult.attributes","title":"attributes  <code>property</code>","text":"<pre><code>attributes: Attributes\n</code></pre> <p>Additional object attributes.</p>"},{"location":"api/get/#obstore.GetResult.meta","title":"meta  <code>property</code>","text":"<pre><code>meta: ObjectMeta\n</code></pre> <p>The ObjectMeta for this object.</p>"},{"location":"api/get/#obstore.GetResult.range","title":"range  <code>property</code>","text":"<pre><code>range: tuple[int, int]\n</code></pre> <p>The range of bytes returned by this request.</p> <p>Note that this is <code>(start, stop)</code> not <code>(start, length)</code>.</p>"},{"location":"api/get/#obstore.GetResult.__aiter__","title":"__aiter__","text":"<pre><code>__aiter__() -&gt; BytesStream\n</code></pre> <p>Return a chunked stream over the result's bytes.</p> <p>Uses the default (10MB) chunk size.</p>"},{"location":"api/get/#obstore.GetResult.__iter__","title":"__iter__","text":"<pre><code>__iter__() -&gt; BytesStream\n</code></pre> <p>Return a chunked stream over the result's bytes.</p> <p>Uses the default (10MB) chunk size.</p>"},{"location":"api/get/#obstore.GetResult.buffer","title":"buffer","text":"<pre><code>buffer() -&gt; Bytes\n</code></pre> <p>Collect the data into a <code>Bytes</code> object.</p> <p>This is an alias of the <code>bytes()</code> method to comply with the <code>obspec.Get</code> protocol.</p>"},{"location":"api/get/#obstore.GetResult.buffer_async","title":"buffer_async  <code>async</code>","text":"<pre><code>buffer_async() -&gt; Bytes\n</code></pre> <p>Collect the data into a <code>Bytes</code> object.</p> <p>This is an alias of the <code>bytes_async()</code> method to comply with the <code>obspec.GetAsync</code> protocol.</p>"},{"location":"api/get/#obstore.GetResult.bytes","title":"bytes","text":"<pre><code>bytes() -&gt; Bytes\n</code></pre> <p>Collect the data into a <code>Bytes</code> object.</p> <p>This implements the Python buffer protocol. You can copy the buffer to Python memory by passing to <code>bytes</code>.</p>"},{"location":"api/get/#obstore.GetResult.bytes_async","title":"bytes_async  <code>async</code>","text":"<pre><code>bytes_async() -&gt; Bytes\n</code></pre> <p>Collect the data into a <code>Bytes</code> object.</p> <p>This implements the Python buffer protocol. You can copy the buffer to Python memory by passing to <code>bytes</code>.</p>"},{"location":"api/get/#obstore.GetResult.stream","title":"stream","text":"<pre><code>stream(min_chunk_size: int = 10 * 1024 * 1024) -&gt; BytesStream\n</code></pre> <p>Return a chunked stream over the result's bytes.</p> <p>Parameters:</p> <ul> <li> <code>min_chunk_size</code>               (<code>int</code>, default:                   <code>10 * 1024 * 1024</code> )           \u2013            <p>The minimum size in bytes for each chunk in the returned <code>BytesStream</code>. All chunks except for the last chunk will be at least this size. Defaults to 10*1024*1024 (10MB).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>BytesStream</code>           \u2013            <p>A chunked stream</p> </li> </ul>"},{"location":"api/get/#obstore.BytesStream","title":"obstore.BytesStream","text":"<p>An async stream of bytes.</p> <p>Request timeouts</p> <p>The underlying stream needs to stay alive until the last chunk is polled. If the file is large, it may exceed the default timeout of 30 seconds. In this case, you may see an error like:</p> <pre><code>GenericError: Generic {\n    store: \"HTTP\",\n    source: reqwest::Error {\n        kind: Decode,\n        source: reqwest::Error {\n            kind: Body,\n            source: TimedOut,\n        },\n    },\n}\n</code></pre> <p>To fix this, set the <code>timeout</code> parameter in the <code>client_options</code> passed when creating the store.</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore import BytesStream\n</code></pre>"},{"location":"api/get/#obstore.BytesStream.__aiter__","title":"__aiter__","text":"<pre><code>__aiter__() -&gt; BytesStream\n</code></pre> <p>Return <code>Self</code> as an async iterator.</p>"},{"location":"api/get/#obstore.BytesStream.__anext__","title":"__anext__  <code>async</code>","text":"<pre><code>__anext__() -&gt; bytes\n</code></pre> <p>Return the next chunk of bytes in the stream.</p>"},{"location":"api/get/#obstore.BytesStream.__iter__","title":"__iter__","text":"<pre><code>__iter__() -&gt; BytesStream\n</code></pre> <p>Return <code>Self</code> as an async iterator.</p>"},{"location":"api/get/#obstore.BytesStream.__next__","title":"__next__","text":"<pre><code>__next__() -&gt; bytes\n</code></pre> <p>Return the next chunk of bytes in the stream.</p>"},{"location":"api/get/#obstore.Bytes","title":"obstore.Bytes","text":"<p>               Bases: <code>Buffer</code></p> <p>A <code>bytes</code>-like buffer.</p> <p>This implements the Python buffer protocol, allowing zero-copy access to underlying Rust memory.</p> <p>You can pass this to <code>memoryview</code> for a zero-copy view into the underlying data or to <code>bytes</code> to copy the underlying data into a Python <code>bytes</code>.</p> <p>Many methods from the Python <code>bytes</code> class are implemented on this,</p>"},{"location":"api/get/#obstore.Bytes.__init__","title":"__init__","text":"<pre><code>__init__(buf: Buffer = b'') -&gt; None\n</code></pre> <p>Construct a new Bytes object.</p> <p>This will be a zero-copy view on the Python byte slice.</p>"},{"location":"api/get/#obstore.Bytes.isalnum","title":"isalnum","text":"<pre><code>isalnum() -&gt; bool\n</code></pre> <p>Return <code>True</code> if all bytes in the sequence are alphabetical ASCII characters or ASCII decimal digits and the sequence is not empty, <code>False</code> otherwise.</p> <p>Alphabetic ASCII characters are those byte values in the sequence <code>b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'</code>. ASCII decimal digits are those byte values in the sequence <code>b'0123456789'</code>.</p>"},{"location":"api/get/#obstore.Bytes.isalpha","title":"isalpha","text":"<pre><code>isalpha() -&gt; bool\n</code></pre> <p>Return <code>True</code> if all bytes in the sequence are alphabetic ASCII characters and the sequence is not empty, <code>False</code> otherwise.</p> <p>Alphabetic ASCII characters are those byte values in the sequence <code>b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'</code>.</p>"},{"location":"api/get/#obstore.Bytes.isascii","title":"isascii","text":"<pre><code>isascii() -&gt; bool\n</code></pre> <p>Return <code>True</code> if the sequence is empty or all bytes in the sequence are ASCII, <code>False</code> otherwise.</p> <p>ASCII bytes are in the range <code>0-0x7F</code>.</p>"},{"location":"api/get/#obstore.Bytes.isdigit","title":"isdigit","text":"<pre><code>isdigit() -&gt; bool\n</code></pre> <p>Return <code>True</code> if all bytes in the sequence are ASCII decimal digits and the sequence is not empty, <code>False</code> otherwise.</p> <p>ASCII decimal digits are those byte values in the sequence <code>b'0123456789'</code>.</p>"},{"location":"api/get/#obstore.Bytes.islower","title":"islower","text":"<pre><code>islower() -&gt; bool\n</code></pre> <p>Return <code>True</code> if there is at least one lowercase ASCII character in the sequence and no uppercase ASCII characters, <code>False</code> otherwise.</p>"},{"location":"api/get/#obstore.Bytes.isspace","title":"isspace","text":"<pre><code>isspace() -&gt; bool\n</code></pre> <p>Return <code>True</code> if all bytes in the sequence are ASCII whitespace and the sequence is not empty, <code>False</code> otherwise.</p> <p>ASCII whitespace characters are those byte values in the sequence <code>b' \\t\\n\\r\\x0b\\f'</code> (space, tab, newline, carriage return, vertical tab, form feed).</p>"},{"location":"api/get/#obstore.Bytes.isupper","title":"isupper","text":"<pre><code>isupper() -&gt; bool\n</code></pre> <p>Return <code>True</code> if there is at least one uppercase alphabetic ASCII character in the sequence and no lowercase ASCII characters, <code>False</code> otherwise.</p>"},{"location":"api/get/#obstore.Bytes.lower","title":"lower","text":"<pre><code>lower() -&gt; Bytes\n</code></pre> <p>Return a copy of the sequence with all the uppercase ASCII characters converted to their corresponding lowercase counterpart.</p>"},{"location":"api/get/#obstore.Bytes.removeprefix","title":"removeprefix","text":"<pre><code>removeprefix(prefix: Buffer) -&gt; Bytes\n</code></pre> <p>If the binary data starts with the prefix string, return <code>bytes[len(prefix):]</code>. Otherwise, return the original binary data.</p>"},{"location":"api/get/#obstore.Bytes.removesuffix","title":"removesuffix","text":"<pre><code>removesuffix(suffix: Buffer) -&gt; Bytes\n</code></pre> <p>If the binary data ends with the suffix string and that suffix is not empty, return <code>bytes[:-len(suffix)]</code>. Otherwise, return the original binary data.</p>"},{"location":"api/get/#obstore.Bytes.to_bytes","title":"to_bytes","text":"<pre><code>to_bytes() -&gt; bytes\n</code></pre> <p>Copy this buffer's contents into a Python <code>bytes</code> object.</p>"},{"location":"api/get/#obstore.Bytes.upper","title":"upper","text":"<pre><code>upper() -&gt; Bytes\n</code></pre> <p>Return a copy of the sequence with all the lowercase ASCII characters converted to their corresponding uppercase counterpart.</p>"},{"location":"api/get/#obstore.OffsetRange","title":"obstore.OffsetRange","text":"<p>               Bases: <code>TypedDict</code></p> <p>Request all bytes starting from a given byte offset.</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore import OffsetRange\n</code></pre>"},{"location":"api/get/#obstore.OffsetRange.offset","title":"offset  <code>instance-attribute</code>","text":"<pre><code>offset: int\n</code></pre> <p>The byte offset for the offset range request.</p>"},{"location":"api/get/#obstore.SuffixRange","title":"obstore.SuffixRange","text":"<p>               Bases: <code>TypedDict</code></p> <p>Request up to the last <code>n</code> bytes.</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore import SuffixRange\n</code></pre>"},{"location":"api/get/#obstore.SuffixRange.suffix","title":"suffix  <code>instance-attribute</code>","text":"<pre><code>suffix: int\n</code></pre> <p>The number of bytes from the suffix to request.</p>"},{"location":"api/head/","title":"Head","text":""},{"location":"api/head/#obstore.head","title":"obstore.head","text":"<pre><code>head(store: ObjectStore, path: str) -&gt; ObjectMeta\n</code></pre> <p>Return the metadata for the specified location.</p> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>ObjectStore</code>)           \u2013            <p>The ObjectStore instance to use.</p> </li> <li> <code>path</code>               (<code>str</code>)           \u2013            <p>The path within ObjectStore to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ObjectMeta</code>           \u2013            <p>ObjectMeta</p> </li> </ul>"},{"location":"api/head/#obstore.head_async","title":"obstore.head_async  <code>async</code>","text":"<pre><code>head_async(store: ObjectStore, path: str) -&gt; ObjectMeta\n</code></pre> <p>Call <code>head</code> asynchronously.</p> <p>Refer to the documentation for head.</p>"},{"location":"api/list/","title":"List","text":""},{"location":"api/list/#obstore.list","title":"obstore.list","text":"<pre><code>list(\n    store: ObjectStore,\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n) -&gt; ListStream[Sequence[ObjectMeta]]\n</code></pre><pre><code>list(\n    store: ObjectStore,\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[True],\n) -&gt; ListStream[RecordBatch]\n</code></pre><pre><code>list(\n    store: ObjectStore,\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[False],\n) -&gt; ListStream[Sequence[ObjectMeta]]\n</code></pre><pre><code>list(\n    store: ObjectStore,\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: bool,\n) -&gt; ListStream[RecordBatch] | ListStream[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list(\n    store: ObjectStore,\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: bool = False,\n) -&gt; ListStream[RecordBatch] | ListStream[Sequence[ObjectMeta]]\n</code></pre> <p>List all the objects with the given prefix.</p> <p>Prefixes are evaluated on a path segment basis, i.e. <code>foo/bar/</code> is a prefix of <code>foo/bar/x</code> but not of <code>foo/bar_baz/x</code>. List is recursive, i.e. <code>foo/bar/more/x</code> will be included.</p> <p>Examples:</p> <p>Synchronously iterate through list results:</p> <pre><code>from obstore.store import MemoryStore\n\nstore = MemoryStore()\nfor i in range(100):\n    store.put(f\"file{i}.txt\", b\"foo\")\n\nstream = store.list(chunk_size=10)\nfor list_result in stream:\n    print(list_result[0])\n    # {'path': 'file0.txt', 'last_modified': datetime.datetime(2024, 10, 23, 19, 19, 28, 781723, tzinfo=datetime.timezone.utc), 'size': 3, 'e_tag': '0', 'version': None}\n    break\n</code></pre> <p>Asynchronously iterate through list results. Just change <code>for</code> to <code>async for</code>:</p> <pre><code>stream = store.list(chunk_size=10)\nasync for list_result in stream:\n    print(list_result[2])\n    # {'path': 'file10.txt', 'last_modified': datetime.datetime(2024, 10, 23, 19, 21, 46, 224725, tzinfo=datetime.timezone.utc), 'size': 3, 'e_tag': '10', 'version': None}\n    break\n</code></pre> <p>Return large list results as Arrow. This is only a performance optimization; it returns the same information in columnar table form. This is most useful with large list operations (you may also want to increase the <code>chunk_size</code> parameter to increase the number of items per emitted record batch).</p> <pre><code>stream = store.list(chunk_size=1000, return_arrow=True)\n# Stream is now an iterable/async iterable of `RecordBatch`es\nfor batch in stream:\n    print(batch.num_rows) # 100\n\n    # If desired, convert to a pyarrow RecordBatch (zero-copy) with\n    # `pyarrow.record_batch(batch)`\n    break\n</code></pre> <p>Collect all list results into a single Arrow <code>RecordBatch</code>.</p> <pre><code>stream = store.list(return_arrow=True)\nbatch = stream.collect()\n</code></pre> <p>Note</p> <p>The order of returned <code>ObjectMeta</code> is not guaranteed</p> <p>Note</p> <p>There is no async version of this method, because <code>list</code> is not async under the hood, rather it only instantiates a stream, which can be polled in synchronous or asynchronous fashion. See <code>ListStream</code>.</p> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>ObjectStore</code>)           \u2013            <p>The ObjectStore instance to use.</p> </li> <li> <code>prefix</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>The prefix within ObjectStore to use for listing. Defaults to None.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>offset</code>               (<code>str | None</code>)           \u2013            <p>If provided, list all the objects with the given prefix and a location greater than <code>offset</code>. Defaults to <code>None</code>.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The number of items to collect per chunk in the returned (async) iterator. All chunks except for the last one will have this many items. This is ignored in the <code>collect</code> and <code>collect_async</code> methods of <code>ListStream</code>.</p> </li> <li> <code>return_arrow</code>               (<code>bool</code>)           \u2013            <p>If <code>True</code>, return each batch of list items as an Apache Arrow <code>RecordBatch</code> instead of a list of Python <code>dict</code>s. This is a performance optimization. Arrow removes serialization overhead between Rust and Python and so setting <code>return_arrow=True</code> can significantly reduce Python interpreter overhead for large list operations. Defaults to <code>False</code>.</p> <p>If this is <code>True</code>, the <code>arro3-core</code> Python package must be installed.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ListStream[RecordBatch] | ListStream[Sequence[ObjectMeta]]</code>           \u2013            <p>A ListStream, which you can iterate through to access list results.</p> </li> </ul>"},{"location":"api/list/#obstore.list_with_delimiter","title":"obstore.list_with_delimiter","text":"<pre><code>list_with_delimiter(\n    store: ObjectStore,\n    prefix: str | None = None,\n    *,\n    return_arrow: Literal[True],\n) -&gt; ListResult[Table]\n</code></pre><pre><code>list_with_delimiter(\n    store: ObjectStore,\n    prefix: str | None = None,\n    *,\n    return_arrow: Literal[False] = False,\n) -&gt; ListResult[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list_with_delimiter(\n    store: ObjectStore, prefix: str | None = None, *, return_arrow: bool = False\n) -&gt; ListResult[Table] | ListResult[Sequence[ObjectMeta]]\n</code></pre> <p>List objects with the given prefix and an implementation specific delimiter.</p> <p>Returns common prefixes (directories) in addition to object metadata.</p> <p>Prefixes are evaluated on a path segment basis, i.e. <code>foo/bar/</code> is a prefix of <code>foo/bar/x</code> but not of <code>foo/bar_baz/x</code>. This list is not recursive, i.e. <code>foo/bar/more/x</code> will not be included.</p> <p>Note</p> <p>Any prefix supplied to this <code>prefix</code> parameter will not be stripped off the paths in the result.</p> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>ObjectStore</code>)           \u2013            <p>The ObjectStore instance to use.</p> </li> <li> <code>prefix</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>The prefix within ObjectStore to use for listing. Defaults to None.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>return_arrow</code>               (<code>bool</code>)           \u2013            <p>If <code>True</code>, return each batch of list items as an Apache Arrow <code>RecordBatch</code> instead of a list of Python <code>dict</code>s. This is a performance optimization. Arrow removes serialization overhead between Rust and Python and so setting <code>return_arrow=True</code> can significantly reduce Python interpreter overhead for large list operations. Defaults to <code>False</code>.</p> <p>If this is <code>True</code>, the <code>arro3-core</code> Python package must be installed.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ListResult[Table] | ListResult[Sequence[ObjectMeta]]</code>           \u2013            <p>ListResult</p> </li> </ul>"},{"location":"api/list/#obstore.list_with_delimiter_async","title":"obstore.list_with_delimiter_async  <code>async</code>","text":"<pre><code>list_with_delimiter_async(\n    store: ObjectStore,\n    prefix: str | None = None,\n    *,\n    return_arrow: Literal[True],\n) -&gt; ListResult[Table]\n</code></pre><pre><code>list_with_delimiter_async(\n    store: ObjectStore,\n    prefix: str | None = None,\n    *,\n    return_arrow: Literal[False] = False,\n) -&gt; ListResult[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list_with_delimiter_async(\n    store: ObjectStore, prefix: str | None = None, *, return_arrow: bool = False\n) -&gt; ListResult[Table] | ListResult[Sequence[ObjectMeta]]\n</code></pre> <p>Call <code>list_with_delimiter</code> asynchronously.</p> <p>Refer to the documentation for list_with_delimiter.</p>"},{"location":"api/list/#obstore.ObjectMeta","title":"obstore.ObjectMeta","text":"<p>               Bases: <code>TypedDict</code></p> <p>The metadata that describes an object.</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore import ObjectMeta\n</code></pre>"},{"location":"api/list/#obstore.ObjectMeta.e_tag","title":"e_tag  <code>instance-attribute</code>","text":"<pre><code>e_tag: str | None\n</code></pre> <p>The unique identifier for the object datatracker.ietf.org/doc/html/rfc9110#name-etag</p>"},{"location":"api/list/#obstore.ObjectMeta.last_modified","title":"last_modified  <code>instance-attribute</code>","text":"<pre><code>last_modified: datetime\n</code></pre> <p>The last modified time</p>"},{"location":"api/list/#obstore.ObjectMeta.path","title":"path  <code>instance-attribute</code>","text":"<pre><code>path: str\n</code></pre> <p>The full path to the object</p>"},{"location":"api/list/#obstore.ObjectMeta.size","title":"size  <code>instance-attribute</code>","text":"<pre><code>size: int\n</code></pre> <p>The size in bytes of the object</p>"},{"location":"api/list/#obstore.ObjectMeta.version","title":"version  <code>instance-attribute</code>","text":"<pre><code>version: str | None\n</code></pre> <p>A version indicator for this object</p>"},{"location":"api/list/#obstore.ListResult","title":"obstore.ListResult","text":"<p>               Bases: <code>TypedDict</code>, <code>Generic[ListChunkType]</code></p> <p>Result of a list call.</p> <p>Includes objects, prefixes (directories) and a token for the next set of results. Individual result sets may be limited to 1,000 objects based on the underlying object storage's limitations.</p> <p>This implements <code>obstore.ListResult</code>.</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore import ListResult\n</code></pre>"},{"location":"api/list/#obstore.ListResult.common_prefixes","title":"common_prefixes  <code>instance-attribute</code>","text":"<pre><code>common_prefixes: Sequence[str]\n</code></pre> <p>Prefixes that are common (like directories)</p>"},{"location":"api/list/#obstore.ListResult.objects","title":"objects  <code>instance-attribute</code>","text":"<pre><code>objects: ListChunkType\n</code></pre> <p>Object metadata for the listing</p>"},{"location":"api/list/#obstore.ListStream","title":"obstore.ListStream","text":"<p>               Bases: <code>Generic[ListChunkType]</code></p> <p>A stream of ObjectMeta that can be polled in a sync or async fashion.</p> <p>This implements <code>obstore.ListStream</code>.</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore import ListStream\n</code></pre>"},{"location":"api/list/#obstore.ListStream.__aiter__","title":"__aiter__","text":"<pre><code>__aiter__() -&gt; Self\n</code></pre> <p>Return <code>Self</code> as an async iterator.</p>"},{"location":"api/list/#obstore.ListStream.__anext__","title":"__anext__  <code>async</code>","text":"<pre><code>__anext__() -&gt; ListChunkType\n</code></pre> <p>Return the next chunk of ObjectMeta in the stream.</p>"},{"location":"api/list/#obstore.ListStream.__iter__","title":"__iter__","text":"<pre><code>__iter__() -&gt; Self\n</code></pre> <p>Return <code>Self</code> as an async iterator.</p>"},{"location":"api/list/#obstore.ListStream.__next__","title":"__next__","text":"<pre><code>__next__() -&gt; ListChunkType\n</code></pre> <p>Return the next chunk of ObjectMeta in the stream.</p>"},{"location":"api/list/#obstore.ListStream.collect","title":"collect","text":"<pre><code>collect() -&gt; ListChunkType\n</code></pre> <p>Collect all remaining ObjectMeta objects in the stream.</p> <p>This ignores the <code>chunk_size</code> parameter from the <code>list</code> call and collects all remaining data into a single chunk.</p>"},{"location":"api/list/#obstore.ListStream.collect_async","title":"collect_async  <code>async</code>","text":"<pre><code>collect_async() -&gt; ListChunkType\n</code></pre> <p>Collect all remaining ObjectMeta objects in the stream.</p> <p>This ignores the <code>chunk_size</code> parameter from the <code>list</code> call and collects all remaining data into a single chunk.</p>"},{"location":"api/list/#obstore.ListChunkType","title":"obstore.ListChunkType  <code>module-attribute</code>","text":"<pre><code>ListChunkType = TypeVar('ListChunkType', covariant=True)\n</code></pre> <p>The data structure used for holding list results.</p> <p>By default, listing APIs return a <code>list</code> of <code>ObjectMeta</code>. However for improved performance when listing large buckets, you can pass <code>return_arrow=True</code>. Then an Arrow <code>RecordBatch</code> will be returned instead, with columns containing the same information as would be contained in the Python <code>ObjectMeta</code>.</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore import ListChunkType\n</code></pre>"},{"location":"api/put/","title":"Put","text":""},{"location":"api/put/#obstore.put","title":"obstore.put","text":"<pre><code>put(\n    store: ObjectStore,\n    path: str,\n    file: IO[bytes]\n    | Path\n    | bytes\n    | Buffer\n    | Iterator[Buffer]\n    | Iterable[Buffer],\n    *,\n    attributes: Attributes | None = None,\n    tags: dict[str, str] | None = None,\n    mode: PutMode | None = None,\n    use_multipart: bool | None = None,\n    chunk_size: int = ...,\n    max_concurrency: int = 12,\n) -&gt; PutResult\n</code></pre> <p>Save the provided bytes to the specified location.</p> <p>The operation is guaranteed to be atomic, it will either successfully write the entirety of <code>file</code> to <code>location</code>, or fail. No clients should be able to observe a partially written object.</p> <p>Aborted multipart uploads</p> <p>This function will automatically use multipart uploads under the hood for large file objects (whenever the length of the file is greater than <code>chunk_size</code>) or for iterable or async iterable input.</p> <p>Multipart uploads have a variety of advantages, including performance and reliability.</p> <p>However, aborted or incomplete multipart uploads can leave partial content in a hidden state in your bucket, silently adding to your storage costs. It's recommended to configure lifecycle rules to automatically delete aborted multipart uploads. See here for the AWS S3 documentation, for example.</p> <p>You can turn off multipart uploads by passing <code>use_multipart=False</code>.</p> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>ObjectStore</code>)           \u2013            <p>The ObjectStore instance to use.</p> </li> <li> <code>path</code>               (<code>str</code>)           \u2013            <p>The path within ObjectStore for where to save the file.</p> </li> <li> <code>file</code>               (<code>IO[bytes] | Path | bytes | Buffer | Iterator[Buffer] | Iterable[Buffer]</code>)           \u2013            <p>The object to upload. Supports various input:</p> <ul> <li>A file-like object opened in binary read mode</li> <li>A <code>Path</code> to a local file</li> <li>A <code>bytes</code> object.</li> <li>An object implementing the Python buffer   protocol (includes <code>bytes</code>   but also <code>memoryview</code>, numpy arrays, and more). Note that only   1-dimensional, contiguous, uint8-typed buffers are supported.</li> <li>An iterator or iterable of objects implementing the Python buffer   protocol.</li> </ul> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>mode</code>               (<code>PutMode | None</code>)           \u2013            <p>Configure the <code>PutMode</code> for this operation. Refer to the <code>PutMode</code> docstring for more information.</p> <p>If this provided and is not <code>\"overwrite\"</code>, a non-multipart upload will be performed. Defaults to <code>\"overwrite\"</code>.</p> </li> <li> <code>attributes</code>               (<code>Attributes | None</code>)           \u2013            <p>Provide a set of <code>Attributes</code>. Defaults to <code>None</code>.</p> </li> <li> <code>tags</code>               (<code>dict[str, str] | None</code>)           \u2013            <p>Provide tags for this object. Defaults to <code>None</code>.</p> </li> <li> <code>use_multipart</code>               (<code>bool | None</code>)           \u2013            <p>Whether to use a multipart upload under the hood. Defaults using a multipart upload if the length of the file is greater than <code>chunk_size</code>. When <code>use_multipart</code> is <code>False</code>, the entire input will be materialized in memory as part of the upload.</p> </li> <li> <code>chunk_size</code>               (<code>int</code>)           \u2013            <p>The size of chunks to use within each part of the multipart upload. Defaults to 5 MB.</p> </li> <li> <code>max_concurrency</code>               (<code>int</code>)           \u2013            <p>The maximum number of chunks to upload concurrently. Defaults to 12.</p> </li> </ul>"},{"location":"api/put/#obstore.put_async","title":"obstore.put_async  <code>async</code>","text":"<pre><code>put_async(\n    store: ObjectStore,\n    path: str,\n    file: IO[bytes]\n    | Path\n    | bytes\n    | Buffer\n    | AsyncIterator[Buffer]\n    | AsyncIterable[Buffer]\n    | Iterator[Buffer]\n    | Iterable[Buffer],\n    *,\n    attributes: Attributes | None = None,\n    tags: dict[str, str] | None = None,\n    mode: PutMode | None = None,\n    use_multipart: bool | None = None,\n    chunk_size: int = ...,\n    max_concurrency: int = 12,\n) -&gt; PutResult\n</code></pre> <p>Call <code>put</code> asynchronously.</p> <p>Refer to the documentation for <code>put</code>. In addition to what the synchronous <code>put</code> allows for the <code>file</code> parameter, this also supports an async iterator or iterable of buffers.</p> <p>This means, for example, you can pass the result of <code>get_async</code> directly to <code>put_async</code>, and the request will be streamed through Python during the put operation:</p> <pre><code># This only constructs the stream, it doesn't materialize the data in memory\nresp = await store1.get_async(path1)\n# A streaming upload is created to copy the file to path2\nawait store2.put_async(path2)\n</code></pre>"},{"location":"api/put/#obstore.PutResult","title":"obstore.PutResult","text":"<p>               Bases: <code>TypedDict</code></p> <p>Result for a put request.</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore import PutResult\n</code></pre>"},{"location":"api/put/#obstore.PutResult.e_tag","title":"e_tag  <code>instance-attribute</code>","text":"<pre><code>e_tag: str | None\n</code></pre> <p>The unique identifier for the newly created object datatracker.ietf.org/doc/html/rfc9110#name-etag</p>"},{"location":"api/put/#obstore.PutResult.version","title":"version  <code>instance-attribute</code>","text":"<pre><code>version: str | None\n</code></pre> <p>A version indicator for the newly created object.</p>"},{"location":"api/put/#obstore.UpdateVersion","title":"obstore.UpdateVersion","text":"<p>               Bases: <code>TypedDict</code></p> <p>Uniquely identifies a version of an object to update.</p> <p>Stores will use differing combinations of <code>e_tag</code> and <code>version</code> to provide conditional updates, and it is therefore recommended applications preserve both</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore import UpdateVersion\n</code></pre>"},{"location":"api/put/#obstore.UpdateVersion.e_tag","title":"e_tag  <code>instance-attribute</code>","text":"<pre><code>e_tag: str | None\n</code></pre> <p>The unique identifier for the newly created object. datatracker.ietf.org/doc/html/rfc9110#name-etag</p>"},{"location":"api/put/#obstore.UpdateVersion.version","title":"version  <code>instance-attribute</code>","text":"<pre><code>version: str | None\n</code></pre> <p>A version indicator for the newly created object.</p>"},{"location":"api/put/#obstore.PutMode","title":"obstore.PutMode  <code>module-attribute</code>","text":"<pre><code>PutMode: TypeAlias = Literal['create', 'overwrite'] | UpdateVersion\n</code></pre> <p>Configure preconditions for the put operation There are three modes: - Overwrite: Perform an atomic write operation, overwriting any object present at the   provided path. - Create: Perform an atomic write operation, returning   <code>AlreadyExistsError</code> if an object already   exists at the provided path. - Update: Perform an atomic write operation if the current version of the object matches   the provided <code>UpdateVersion</code>, returning   <code>PreconditionError</code> otherwise. If a string is provided, it must be one of: - <code>\"overwrite\"</code> - <code>\"create\"</code> If a <code>dict</code> is provided, it must meet the criteria of <code>UpdateVersion</code>.</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore import PutMode\n</code></pre>"},{"location":"api/rename/","title":"Rename","text":""},{"location":"api/rename/#obstore.rename","title":"obstore.rename","text":"<pre><code>rename(\n    store: ObjectStore, from_: str, to: str, *, overwrite: bool = True\n) -&gt; None\n</code></pre> <p>Move an object from one path to another in the same object store.</p> <p>By default, this is implemented as a copy and then delete source. It may not check when deleting source that it was the same object that was originally copied.</p> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>ObjectStore</code>)           \u2013            <p>The ObjectStore instance to use.</p> </li> <li> <code>from_</code>               (<code>str</code>)           \u2013            <p>Source path</p> </li> <li> <code>to</code>               (<code>str</code>)           \u2013            <p>Destination path</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>overwrite</code>               (<code>bool</code>)           \u2013            <p>If <code>True</code>, if there exists an object at the destination, it will be overwritten. If <code>False</code>, will return an error if the destination already has an object.</p> </li> </ul>"},{"location":"api/rename/#obstore.rename_async","title":"obstore.rename_async  <code>async</code>","text":"<pre><code>rename_async(\n    store: ObjectStore, from_: str, to: str, *, overwrite: bool = True\n) -&gt; None\n</code></pre> <p>Call <code>rename</code> asynchronously.</p> <p>Refer to the documentation for rename.</p>"},{"location":"api/sign/","title":"Sign","text":""},{"location":"api/sign/#obstore.sign","title":"obstore.sign","text":"<pre><code>sign(\n    store: SignCapableStore,\n    method: HTTP_METHOD,\n    paths: str,\n    expires_in: timedelta,\n) -&gt; str\n</code></pre><pre><code>sign(\n    store: SignCapableStore,\n    method: HTTP_METHOD,\n    paths: Sequence[str],\n    expires_in: timedelta,\n) -&gt; Sequence[str]\n</code></pre> <pre><code>sign(\n    store: SignCapableStore,\n    method: HTTP_METHOD,\n    paths: str | Sequence[str],\n    expires_in: timedelta,\n) -&gt; str | Sequence[str]\n</code></pre> <p>Create a signed URL.</p> <p>Given the intended <code>method</code> and <code>paths</code> to use and the desired length of time for which the URL should be valid, return a signed URL created with the object store implementation's credentials such that the URL can be handed to something that doesn't have access to the object store's credentials, to allow limited access to the object store.</p> <p>Parameters:</p> <ul> <li> <code>store</code>               (<code>SignCapableStore</code>)           \u2013            <p>The ObjectStore instance to use.</p> </li> <li> <code>method</code>               (<code>HTTP_METHOD</code>)           \u2013            <p>The HTTP method to use.</p> </li> <li> <code>paths</code>               (<code>str | Sequence[str]</code>)           \u2013            <p>The path(s) within ObjectStore to retrieve. If</p> </li> <li> <code>expires_in</code>               (<code>timedelta</code>)           \u2013            <p>How long the signed URL(s) should be valid.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str | Sequence[str]</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/sign/#obstore.sign_async","title":"obstore.sign_async  <code>async</code>","text":"<pre><code>sign_async(\n    store: SignCapableStore,\n    method: HTTP_METHOD,\n    paths: str,\n    expires_in: timedelta,\n) -&gt; str\n</code></pre><pre><code>sign_async(\n    store: SignCapableStore,\n    method: HTTP_METHOD,\n    paths: Sequence[str],\n    expires_in: timedelta,\n) -&gt; Sequence[str]\n</code></pre> <pre><code>sign_async(\n    store: SignCapableStore,\n    method: HTTP_METHOD,\n    paths: str | Sequence[str],\n    expires_in: timedelta,\n) -&gt; str | Sequence[str]\n</code></pre> <p>Call <code>sign</code> asynchronously.</p> <p>Refer to the documentation for sign.</p>"},{"location":"api/sign/#obstore.SignCapableStore","title":"obstore.SignCapableStore  <code>module-attribute</code>","text":"<pre><code>SignCapableStore: TypeAlias = AzureStore | GCSStore | S3Store\n</code></pre> <p>ObjectStore instances that are capable of signing.</p>"},{"location":"api/sign/#obstore.HTTP_METHOD","title":"obstore.HTTP_METHOD  <code>module-attribute</code>","text":"<pre><code>HTTP_METHOD: TypeAlias = Literal[\n    \"GET\",\n    \"PUT\",\n    \"POST\",\n    \"HEAD\",\n    \"PATCH\",\n    \"TRACE\",\n    \"DELETE\",\n    \"OPTIONS\",\n    \"CONNECT\",\n]\n</code></pre> <p>Allowed HTTP Methods for signing.</p>"},{"location":"api/auth/azure/","title":"Azure","text":""},{"location":"api/auth/azure/#obstore.auth.azure.DEFAULT_SCOPES","title":"obstore.auth.azure.DEFAULT_SCOPES  <code>module-attribute</code>","text":"<pre><code>DEFAULT_SCOPES = ('https://storage.azure.com/.default',)\n</code></pre> <p>Default scopes used for Azure credential providers.</p>"},{"location":"api/auth/azure/#obstore.auth.azure.AzureCredentialProvider","title":"obstore.auth.azure.AzureCredentialProvider","text":"<p>A CredentialProvider for AzureStore that uses <code>azure.identity</code>.</p> <p>This credential provider uses <code>azure-identity</code>, and will error if this cannot be imported.</p> <p>Example:</p> <pre><code>from obstore.auth.azure import AzureCredentialProvider\nfrom obstore.store import AzureStore\n\ncredential_provider = AzureCredentialProvider(credential=...)\nstore = AzureStore(\"container\", credential_provider=credential_provider)\n</code></pre>"},{"location":"api/auth/azure/#obstore.auth.azure.AzureCredentialProvider.__init__","title":"__init__","text":"<pre><code>__init__(\n    credential: AuthorizationCodeCredential\n    | AzureCliCredential\n    | AzureDeveloperCliCredential\n    | AzurePipelinesCredential\n    | AzurePowerShellCredential\n    | CertificateCredential\n    | ChainedTokenCredential\n    | ClientAssertionCredential\n    | ClientSecretCredential\n    | DefaultAzureCredential\n    | DeviceCodeCredential\n    | EnvironmentCredential\n    | InteractiveBrowserCredential\n    | ManagedIdentityCredential\n    | OnBehalfOfCredential\n    | SharedTokenCacheCredential\n    | UsernamePasswordCredential\n    | VisualStudioCodeCredential\n    | WorkloadIdentityCredential\n    | None = None,\n    *,\n    scopes: Iterable[str] = DEFAULT_SCOPES,\n    tenant_id: str | None = None,\n) -&gt; None\n</code></pre> <p>Create a new AzureCredentialProvider.</p> <p>Parameters:</p> <ul> <li> <code>credential</code>               (<code>AuthorizationCodeCredential | AzureCliCredential | AzureDeveloperCliCredential | AzurePipelinesCredential | AzurePowerShellCredential | CertificateCredential | ChainedTokenCredential | ClientAssertionCredential | ClientSecretCredential | DefaultAzureCredential | DeviceCodeCredential | EnvironmentCredential | InteractiveBrowserCredential | ManagedIdentityCredential | OnBehalfOfCredential | SharedTokenCacheCredential | UsernamePasswordCredential | VisualStudioCodeCredential | WorkloadIdentityCredential | None</code>, default:                   <code>None</code> )           \u2013            <p>Credential to use for this provider. Defaults to <code>None</code>, in which case <code>azure.identity.DefaultAzureCredential</code> will be called to find default credentials.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>scopes</code>               (<code>Iterable[str]</code>)           \u2013            <p>Scopes required by the access token.</p> </li> <li> <code>tenant_id</code>               (<code>str | None</code>)           \u2013            <p>Optionally specify the Azure Tenant ID which will be passed to the credential's <code>get_token</code> method.</p> </li> </ul>"},{"location":"api/auth/azure/#obstore.auth.azure.AzureCredentialProvider.__call__","title":"__call__","text":"<pre><code>__call__() -&gt; AzureCredential\n</code></pre> <p>Fetch the credential.</p>"},{"location":"api/auth/azure/#obstore.auth.azure.AzureAsyncCredentialProvider","title":"obstore.auth.azure.AzureAsyncCredentialProvider","text":"<p>An async CredentialProvider for AzureStore that uses <code>azure.identity</code>.</p> <p>This credential provider uses <code>azure-identity</code> and <code>aiohttp</code>, and will error if these cannot be imported.</p> <p>Example:</p> <pre><code>import asyncio\nimport obstore\nfrom obstore.auth.azure import AzureAsyncCredentialProvider\nfrom obstore.store import AzureStore\n\ncredential_provider = AzureAsyncCredentialProvider(credential=...)\nstore = AzureStore(\"container\", credential_provider=credential_provider)\n\nasync def fetch_blobs():\n    blobs = await obstore.list(store).collect_async()\n    print(blobs)\n\nasyncio.run(fetch_blobs())\n</code></pre>"},{"location":"api/auth/azure/#obstore.auth.azure.AzureAsyncCredentialProvider.__init__","title":"__init__","text":"<pre><code>__init__(\n    credential: AuthorizationCodeCredential\n    | AzureCliCredential\n    | AzureDeveloperCliCredential\n    | AzurePipelinesCredential\n    | AzurePowerShellCredential\n    | CertificateCredential\n    | ChainedTokenCredential\n    | ClientAssertionCredential\n    | ClientSecretCredential\n    | DefaultAzureCredential\n    | EnvironmentCredential\n    | ManagedIdentityCredential\n    | OnBehalfOfCredential\n    | SharedTokenCacheCredential\n    | VisualStudioCodeCredential\n    | WorkloadIdentityCredential\n    | None = None,\n    *,\n    scopes: Iterable[str] = DEFAULT_SCOPES,\n    tenant_id: str | None = None,\n) -&gt; None\n</code></pre> <p>Create a new AzureAsyncCredentialProvider.</p> <p>Parameters:</p> <ul> <li> <code>credential</code>               (<code>AuthorizationCodeCredential | AzureCliCredential | AzureDeveloperCliCredential | AzurePipelinesCredential | AzurePowerShellCredential | CertificateCredential | ChainedTokenCredential | ClientAssertionCredential | ClientSecretCredential | DefaultAzureCredential | EnvironmentCredential | ManagedIdentityCredential | OnBehalfOfCredential | SharedTokenCacheCredential | VisualStudioCodeCredential | WorkloadIdentityCredential | None</code>, default:                   <code>None</code> )           \u2013            <p>Credential to use for this provider. Defaults to <code>None</code>, in which case <code>azure.identity.aio.DefaultAzureCredential</code> will be called to find default credentials.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>scopes</code>               (<code>Iterable[str]</code>)           \u2013            <p>Scopes required by the access token.</p> </li> <li> <code>tenant_id</code>               (<code>str | None</code>)           \u2013            <p>Optionally specify the Azure Tenant ID which will be passed to the credential's <code>get_token</code> method.</p> </li> </ul>"},{"location":"api/auth/azure/#obstore.auth.azure.AzureAsyncCredentialProvider.__call__","title":"__call__  <code>async</code>","text":"<pre><code>__call__() -&gt; AzureCredential\n</code></pre> <p>Fetch the credential.</p>"},{"location":"api/auth/boto3/","title":"Boto3","text":""},{"location":"api/auth/boto3/#obstore.auth.boto3.Boto3CredentialProvider","title":"obstore.auth.boto3.Boto3CredentialProvider","text":"<p>A CredentialProvider for S3Store that uses <code>boto3.session.Session</code>.</p> <p>If the provided session has a <code>region_name</code> set, that will be passed down to the store.</p>"},{"location":"api/auth/boto3/#obstore.auth.boto3.Boto3CredentialProvider.__init__","title":"__init__","text":"<pre><code>__init__(\n    session: Session | Session | None = None,\n    *,\n    ttl: timedelta = timedelta(minutes=30),\n) -&gt; None\n</code></pre> <p>Create a new Boto3CredentialProvider.</p> <p>This will call <code>session.get_credentials</code> to get a <code>botocore.credentials.Credentials</code> object. Each token refresh will call <code>credentials.get_frozen_credentials</code>.</p> <p>Parameters:</p> <ul> <li> <code>session</code>               (<code>Session | Session | None</code>, default:                   <code>None</code> )           \u2013            <p>A boto3 session to use for providing credentials. Defaults to None, in which case a new <code>boto3.Session</code> will be used.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>ttl</code>               (<code>timedelta</code>)           \u2013            <p>The length of time each result from <code>get_frozen_credentials</code> should live. Defaults to timedelta(minutes=30).</p> </li> </ul>"},{"location":"api/auth/boto3/#obstore.auth.boto3.Boto3CredentialProvider.__call__","title":"__call__","text":"<pre><code>__call__() -&gt; S3Credential\n</code></pre> <p>Fetch credentials.</p>"},{"location":"api/auth/boto3/#obstore.auth.boto3.StsCredentialProvider","title":"obstore.auth.boto3.StsCredentialProvider","text":"<p>A CredentialProvider for S3Store that uses <code>STS.Client.assume_role</code>.</p> <p>If the provided session has a <code>region_name</code> set, that will be passed down to the store.</p>"},{"location":"api/auth/boto3/#obstore.auth.boto3.StsCredentialProvider.__init__","title":"__init__","text":"<pre><code>__init__(\n    session: Session | None = None,\n    **kwargs: Unpack[AssumeRoleRequestRequestTypeDef],\n) -&gt; None\n</code></pre> <p>Create a new StsCredentialProvider.</p> <p>Parameters:</p> <ul> <li> <code>session</code>               (<code>Session | None</code>, default:                   <code>None</code> )           \u2013            <p>A boto3 session to use for providing credentials. Defaults to None, in which case a new <code>boto3.Session</code> will be used.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>kwargs</code>               (<code>Unpack[AssumeRoleRequestRequestTypeDef]</code>)           \u2013            <p>arguments passed on to <code>STS.Client.assume_role</code>.</p> </li> </ul>"},{"location":"api/auth/boto3/#obstore.auth.boto3.StsCredentialProvider.__call__","title":"__call__","text":"<pre><code>__call__() -&gt; S3Credential\n</code></pre> <p>Fetch credentials.</p>"},{"location":"api/auth/earthdata/","title":"NASA Earthdata","text":""},{"location":"api/auth/earthdata/#obstore.auth.earthdata","title":"obstore.auth.earthdata","text":"<p>Credential providers for accessing NASA Earthdata.</p>"},{"location":"api/auth/earthdata/#obstore.auth.earthdata.DEFAULT_EARTHDATA_HOST","title":"DEFAULT_EARTHDATA_HOST  <code>module-attribute</code>","text":"<pre><code>DEFAULT_EARTHDATA_HOST = 'urs.earthdata.nasa.gov'\n</code></pre> <p>Hostname of the NASA Earthdata Login primary operational (OPS) system.</p> <p>This is the default host used during credential authorization.</p>"},{"location":"api/auth/earthdata/#obstore.auth.earthdata.NasaEarthdataCredentialProvider","title":"NasaEarthdataCredentialProvider","text":"<p>A credential provider for accessing NASA Earthdata data resources with an S3Store.</p> <p>This credential provider uses <code>requests</code>, and will error if that cannot be imported.</p> <p>NASA Earthdata supports public in-region direct S3 access. This credential provider automatically manages the S3 credentials.</p> <p>Note</p> <p>You must be in the same AWS region (<code>us-west-2</code>) to use the credentials returned from this provider.</p> <p>Examples:</p> <pre><code>from obstore.store import S3Store\nfrom obstore.auth.earthdata import NasaEarthdataCredentialProvider\n\n# Obtain an S3 credentials URL and an S3 data/download URL, typically\n# via metadata returned from a NASA CMR collection or granule query.\ncredentials_url = \"https://data.ornldaac.earthdata.nasa.gov/s3credentials\"\ndata_url = (\n    \"s3://ornl-cumulus-prod-protected/gedi/GEDI_L4A_AGB_Density_V2_1/data/\"\n    \"GEDI04_A_2024332225741_O33764_03_T01289_02_004_01_V002.h5\"\n)\ndata_prefix_url, filename = data_url.rsplit(\"/\", 1)\n\n# Since no NASA Earthdata credentials are specified in this example,\n# environment variables or netrc will be used to locate them in order to\n# obtain S3 credentials from the URL.\ncp = NasaEarthdataCredentialProvider(credentials_url)\n\nstore = S3Store.from_url(data_prefix_url, credential_provider=cp)\n\n# Download the file by streaming chunks\ntry:\n    result = obstore.get(store, filename)\n    with open(filename, \"wb\") as f:\n        for chunk in iter(result):\n            f.write(chunk)\nfinally:\n    cp.close()\n</code></pre>"},{"location":"api/auth/earthdata/#obstore.auth.earthdata.NasaEarthdataCredentialProvider.session","title":"session  <code>property</code>","text":"<pre><code>session: Session\n</code></pre> <p>Return the underlying session used for HTTP requests.</p> <p>Return either the session supplied at construction, or the default session created during initialization, if no session was supplied.</p> <p>Returns:</p> <ul> <li> <code>Session</code>           \u2013            <p>The session used for HTTP requests.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the credential provider has been closed and the session is unavailable.</p> </li> </ul>"},{"location":"api/auth/earthdata/#obstore.auth.earthdata.NasaEarthdataCredentialProvider.__init__","title":"__init__","text":"<pre><code>__init__(\n    credentials_url: str,\n    *,\n    host: str | None = None,\n    auth: str | tuple[str, str] | None = None,\n    session: Session | None = None,\n) -&gt; None\n</code></pre> <p>Construct a new NasaEarthdataCredentialProvider.</p> <p>Parameters:</p> <ul> <li> <code>credentials_url</code>               (<code>str</code>)           \u2013            <p>Endpoint for obtaining S3 credentials from a NASA DAAC hosting data of interest.  NASA Earthdata credentials are required for obtaining S3 credentials from this endpoint.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>host</code>               (<code>str | None</code>)           \u2013            <p>Hostname for NASA Earthdata authentication.</p> <p>Precedence is as follows:</p> <ol> <li>Uses the specified value, if not <code>None</code>.</li> <li>Uses the environment variable <code>EARTHDATA_HOST</code>, if set.</li> <li>Uses the NASA Earthdata operational host:    DEFAULT_EARTHDATA_HOST</li> </ol> </li> <li> <code>auth</code>               (<code>str | tuple[str, str] | None</code>)           \u2013            <p>Authentication information; can be a NASA Earthdata token (<code>str</code>), NASA Earthdata username/password (tuple), or <code>None</code>.  Defaults to <code>None</code>, in which case, environment variables are used, if set.</p> <p>Precedence is as follows:</p> <ol> <li>Uses the specified value, if not <code>None</code>.</li> <li>Uses the environment variable <code>EARTHDATA_TOKEN</code>, if set.</li> <li>Uses the environment variables <code>EARTHDATA_USERNAME</code> and    <code>EARTHDATA_PASSWORD</code>, if both are set.</li> <li>Uses netrc to locate a username and password for <code>host</code>.    Uses the environment variable <code>NETRC</code>, if set, to locate a    netrc file; otherwise, uses the default netrc file location    (<code>~/.netrc</code> on non-Windows OS or <code>~/_netrc</code> on Windows).</li> </ol> </li> <li> <code>session</code>               (<code>Session | None</code>)           \u2013            <p>The requests session to use for making requests to obtain S3 credentials. Defaults to <code>None</code>, in which case a default session is created internally.  In this case, use this credential provider's <code>close</code> method to release resources when you are finished with it.</p> </li> </ul>"},{"location":"api/auth/earthdata/#obstore.auth.earthdata.NasaEarthdataCredentialProvider.__call__","title":"__call__","text":"<pre><code>__call__() -&gt; S3Credential\n</code></pre> <p>Request updated credentials.</p>"},{"location":"api/auth/earthdata/#obstore.auth.earthdata.NasaEarthdataCredentialProvider.close","title":"close","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Release resources created by this credential provider.</p>"},{"location":"api/auth/earthdata/#obstore.auth.earthdata.NasaEarthdataAsyncCredentialProvider","title":"NasaEarthdataAsyncCredentialProvider","text":"<p>A credential provider for accessing NASA Earthdata data resources with an S3Store.</p> <p>This credential provider uses <code>aiohttp</code>, and will error if that cannot be imported.</p> <p>NASA Earthdata supports public in-region direct S3 access. This credential provider automatically manages the S3 credentials.</p> <p>Note</p> <p>You must be in the same AWS region (<code>us-west-2</code>) to use the credentials returned from this provider.</p> <p>Examples:</p> <pre><code>import obstore\nfrom obstore.auth.earthdata import NasaEarthdataAsyncCredentialProvider\n\n# Obtain an S3 credentials URL and an S3 data/download URL, typically\n# via metadata returned from a NASA CMR collection or granule query.\ncredentials_url = \"https://data.ornldaac.earthdata.nasa.gov/s3credentials\"\ndata_url = (\n    \"s3://ornl-cumulus-prod-protected/gedi/GEDI_L4A_AGB_Density_V2_1/data/\"\n    \"GEDI04_A_2024332225741_O33764_03_T01289_02_004_01_V002.h5\"\n)\ndata_prefix_url, filename = data_url.rsplit(\"/\", 1)\n\n# Since no NASA Earthdata credentials are specified in this example,\n# environment variables or netrc will be used to locate them in order to\n# obtain S3 credentials from the URL.\ncp = NasaEarthdataAsyncCredentialProvider(credentials_url)\n\nstore = obstore.store.from_url(data_prefix_url, credential_provider=cp)\n\n# Download the file by streaming chunks\ntry:\n    result = await obstore.get_async(store, filename)\n    with open(filename, \"wb\") as f:\n        async for chunk in aiter(result):\n            f.write(chunk)\nfinally:\n    await cp.close()\n</code></pre>"},{"location":"api/auth/earthdata/#obstore.auth.earthdata.NasaEarthdataAsyncCredentialProvider.session","title":"session  <code>property</code>","text":"<pre><code>session: ClientSession | RetryClient\n</code></pre> <p>Return the underlying session used for HTTP requests.</p> <p>Return either the session supplied at construction, or the default session created during initialization, if no session was supplied.</p> <p>Returns:</p> <ul> <li> <code>ClientSession | RetryClient</code>           \u2013            <p>The session used for HTTP requests.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If the credential provider has been closed and the session is unavailable.</p> </li> </ul>"},{"location":"api/auth/earthdata/#obstore.auth.earthdata.NasaEarthdataAsyncCredentialProvider.__init__","title":"__init__","text":"<pre><code>__init__(\n    credentials_url: str,\n    *,\n    host: str | None = None,\n    auth: str | tuple[str, str] | None = None,\n    session: ClientSession | RetryClient | None = None,\n) -&gt; None\n</code></pre> <p>Construct a new NasaEarthdataAsyncCredentialProvider.</p> <p>This credential provider uses <code>aiohttp</code>, and will error if that cannot be imported.</p> <p>Refer to NasaEarthdataCredentialProvider for argument explanations.</p>"},{"location":"api/auth/earthdata/#obstore.auth.earthdata.NasaEarthdataAsyncCredentialProvider.__call__","title":"__call__  <code>async</code>","text":"<pre><code>__call__() -&gt; S3Credential\n</code></pre> <p>Request updated credentials.</p>"},{"location":"api/auth/earthdata/#obstore.auth.earthdata.NasaEarthdataAsyncCredentialProvider.close","title":"close  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Release resources created by this credential provider.</p>"},{"location":"api/auth/google/","title":"Google","text":""},{"location":"api/auth/google/#obstore.auth.google.GoogleCredentialProvider","title":"obstore.auth.google.GoogleCredentialProvider","text":"<p>A CredentialProvider for GCSStore that uses <code>google.auth</code>.</p> <p>This credential provider uses <code>google-auth</code> and <code>requests</code>, and will error if those cannot be imported.</p> <p>Example:</p> <pre><code>from obstore.auth.google import GoogleCredentialProvider\nfrom obstore.store import GCSStore\n\ncredential_provider = GoogleCredentialProvider(credentials=...)\nstore = GCSStore(\"bucket_name\", credential_provider=credential_provider)\n</code></pre>"},{"location":"api/auth/google/#obstore.auth.google.GoogleCredentialProvider.__init__","title":"__init__","text":"<pre><code>__init__(\n    credentials: Credentials | None = None,\n    *,\n    request: Request | None = None,\n    refresh_threshold: timedelta = timedelta(minutes=3, seconds=45),\n) -&gt; None\n</code></pre> <p>Create a new GoogleCredentialProvider.</p> <p>Parameters:</p> <ul> <li> <code>credentials</code>               (<code>Credentials | None</code>, default:                   <code>None</code> )           \u2013            <p>Credentials to use for this provider. Defaults to <code>None</code>, in which case <code>google.auth.default</code> will be called to find application default credentials.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>request</code>               (<code>Request | None</code>)           \u2013            <p>The Request instance to use for refreshing the token. This can be set to reuse an existing <code>requests.Session</code>. Defaults to <code>None</code>, in which case a new <code>Request</code> will be instantiated.</p> </li> <li> <code>refresh_threshold</code>               (<code>timedelta</code>)           \u2013            <p>The length of time before the token timeout when a new token should be requested. Defaults to <code>timedelta(minutes=3, seconds=45)</code> (suggested here).</p> </li> </ul>"},{"location":"api/auth/google/#obstore.auth.google.GoogleCredentialProvider.__call__","title":"__call__","text":"<pre><code>__call__() -&gt; GCSCredential\n</code></pre> <p>Fetch the credentials.</p>"},{"location":"api/auth/google/#obstore.auth.google.GoogleAsyncCredentialProvider","title":"obstore.auth.google.GoogleAsyncCredentialProvider","text":"<p>An async CredentialProvider for GCSStore that uses <code>google.auth</code>.</p> <p>This credential provider should be preferred over the synchronous GoogleCredentialProvider whenever you're using async obstore methods.</p> <p>This credential provider uses <code>google-auth</code> and <code>aiohttp</code>, and will error if those cannot be imported.</p> <p>Example:</p> <pre><code>from obstore.auth.google import GoogleAsyncCredentialProvider\nfrom obstore.store import GCSStore\n\ncredential_provider = GoogleAsyncCredentialProvider(credentials=...)\nstore = GCSStore(\"bucket_name\", credential_provider=credential_provider)\n</code></pre>"},{"location":"api/auth/google/#obstore.auth.google.GoogleAsyncCredentialProvider.__init__","title":"__init__","text":"<pre><code>__init__(\n    credentials: Credentials | None = None,\n    *,\n    request: Request | None = None,\n    refresh_threshold: timedelta = timedelta(minutes=3, seconds=45),\n) -&gt; None\n</code></pre> <p>Create a new GoogleCredentialProvider.</p> <p>Parameters:</p> <ul> <li> <code>credentials</code>               (<code>Credentials | None</code>, default:                   <code>None</code> )           \u2013            <p>Credentials to use for this provider. Defaults to <code>None</code>, in which case <code>google.auth._default_async.default_async</code> will be called to find application default credentials.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>request</code>               (<code>Request | None</code>)           \u2013            <p>The Request instance to use for refreshing the token. This can be set to reuse an existing <code>aiohttp.ClientSession</code>. Defaults to <code>None</code>, in which case a new <code>google.auth.transport._aiohttp_requests.Request</code> will be instantiated.</p> </li> <li> <code>refresh_threshold</code>               (<code>timedelta</code>)           \u2013            <p>The length of time before the token timeout when a new token should be requested. Defaults to <code>timedelta(minutes=3, seconds=45)</code> (suggested here).</p> </li> </ul>"},{"location":"api/auth/google/#obstore.auth.google.GoogleAsyncCredentialProvider.__call__","title":"__call__  <code>async</code>","text":"<pre><code>__call__() -&gt; GCSCredential\n</code></pre> <p>Fetch the credentials.</p>"},{"location":"api/auth/planetary-computer/","title":"Planetary Computer","text":""},{"location":"api/auth/planetary-computer/#obstore.auth.planetary_computer.PlanetaryComputerCredentialProvider","title":"obstore.auth.planetary_computer.PlanetaryComputerCredentialProvider","text":"<p>A CredentialProvider for AzureStore for accessing Planetary Computer data resources.</p> <p>This credential provider uses <code>requests</code>, and will error if that cannot be imported.</p> <p>Examples:</p> <pre><code>from obstore.store import AzureStore\nfrom obstore.auth.planetary_computer import PlanetaryComputerCredentialProvider\n\nurl = \"https://naipeuwest.blob.core.windows.net/naip/v002/mt/2023/mt_060cm_2023/\"\n\n# Construct an AzureStore with this credential provider.\n#\n# The account, container, and container prefix are passed down to AzureStore\n# automatically.\nstore = AzureStore(credential_provider=PlanetaryComputerCredentialProvider(url))\n\n# List some items in the container\nitems = next(store.list())\n\n# Fetch a thumbnail\npath = \"44106/m_4410602_nw_13_060_20230712_20240103.200.jpg\"\nimage_content = store.get(path).bytes()\n\n# Write out the image content to a file in the current directory\nwith open(\"thumbnail.jpg\", \"wb\") as f:\n    f.write(image_content)\n</code></pre>"},{"location":"api/auth/planetary-computer/#obstore.auth.planetary_computer.PlanetaryComputerCredentialProvider.__init__","title":"__init__","text":"<pre><code>__init__(\n    url: str | None = None,\n    *,\n    account_name: str | None = None,\n    container_name: str | None = None,\n    session: Session | None = None,\n    subscription_key: str | None = None,\n    sas_url: str | None = None,\n) -&gt; None\n</code></pre> <p>Construct a new PlanetaryComputerCredentialProvider.</p> <p>Parameters:</p> <ul> <li> <code>url</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Either the <code>https</code> or <code>abfs</code> URL of blob storage to mount to, such as <code>\"https://daymeteuwest.blob.core.windows.net/daymet-zarr/daily\"</code> or <code>\"abfs://daymet-zarr/daily/hi.zarr\"</code>.</p> <p>For <code>abfs</code> URLs, <code>account_name</code> must be provided.</p> <p>For <code>https</code> URLs, neither <code>account_name</code> nor <code>container_name</code> may be provided.</p> <p>If <code>url</code> is not provided, <code>account_name</code> and <code>container_name</code> must be provided. Defaults to <code>None</code>.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>account_name</code>               (<code>str | None</code>)           \u2013            <p>The Azure storage account name. Must be provided for <code>abfs</code> URLs. If <code>url</code> is not provided, both this and <code>container_name</code> must be provided. Defaults to <code>None</code>.</p> </li> <li> <code>container_name</code>               (<code>str | None</code>)           \u2013            <p>The Azure storage container name. If <code>url</code> is not provided, both this and <code>account_name</code> must be provided. Defaults to <code>None</code>.</p> </li> <li> <code>session</code>               (<code>Session | None</code>)           \u2013            <p>The requests session to use for making requests to the Planetary Computer token API. Defaults to <code>None</code>.</p> </li> <li> <code>subscription_key</code>               (<code>str | None</code>)           \u2013            <p>A Planetary Computer subscription key.</p> <p>Precedence is as follows:</p> <ol> <li>Uses the passed-in value if not <code>None</code>.</li> <li>Uses the environment variable <code>PC_SDK_SUBSCRIPTION_KEY</code> if set.</li> <li>Uses the value of <code>PC_SDK_SUBSCRIPTION_KEY</code> in    <code>~/.planetarycomputer/settings.env</code>, if that file exists (requires    <code>python-dotenv</code> as a dependency).</li> <li>Defaults to <code>None</code>, which may apply request throttling.</li> </ol> </li> <li> <code>sas_url</code>               (<code>str | None</code>)           \u2013            <p>The URL base for requesting new Planetary Computer SAS tokens.</p> <p>Precedence is as follows:</p> <ol> <li>Uses the passed-in value if not <code>None</code>.</li> <li>Uses the environment variable <code>PC_SDK_SAS_URL</code> if set.</li> <li>Uses the value of <code>PC_SDK_SAS_URL</code> in    <code>~/.planetarycomputer/settings.env</code>, if that file exists (requires    <code>python-dotenv</code> as a dependency).</li> <li>Defaults to <code>\"https://planetarycomputer.microsoft.com/api/sas/v1/token\"</code>.</li> </ol> </li> </ul>"},{"location":"api/auth/planetary-computer/#obstore.auth.planetary_computer.PlanetaryComputerCredentialProvider.from_asset","title":"from_asset  <code>classmethod</code>","text":"<pre><code>from_asset(\n    asset: Asset | dict[str, Any],\n    *,\n    session: Session | None = None,\n    subscription_key: str | None = None,\n    sas_url: str | None = None,\n) -&gt; Self\n</code></pre> <p>Create from a STAC Asset.</p> <p>Parameters:</p> <ul> <li> <code>asset</code>               (<code>Asset | dict[str, Any]</code>)           \u2013            <p>Planetary Computer STAC Asset.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>session</code>               (<code>Session | None</code>)           \u2013            <p>The requests session, passed on as a keyword argument to <code>__init__</code>.</p> </li> <li> <code>subscription_key</code>               (<code>str | None</code>)           \u2013            <p>A Planetary Computer subscription key, passed on as a keyword argument to <code>__init__</code>.</p> </li> <li> <code>sas_url</code>               (<code>str | None</code>)           \u2013            <p>The URL base for requesting new Planetary Computer SAS tokens, passed on as a keyword argument to <code>__init__</code>.</p> </li> </ul> <p>Examples:</p> <pre><code>import pystac_client\n\nfrom obstore.auth.planetary_computer import PlanetaryComputerCredentialProvider\n\nstac_url = \"https://planetarycomputer.microsoft.com/api/stac/v1/\"\ncatalog = pystac_client.Client.open(stac_url)\n\ncollection = catalog.get_collection(\"daymet-daily-hi\")\nasset = collection.assets[\"zarr-abfs\"]\n\ncredential_provider = PlanetaryComputerCredentialProvider.from_asset(asset)\n</code></pre>"},{"location":"api/auth/planetary-computer/#obstore.auth.planetary_computer.PlanetaryComputerCredentialProvider.__call__","title":"__call__","text":"<pre><code>__call__() -&gt; AzureSASToken\n</code></pre> <p>Fetch a new token.</p>"},{"location":"api/auth/planetary-computer/#obstore.auth.planetary_computer.PlanetaryComputerAsyncCredentialProvider","title":"obstore.auth.planetary_computer.PlanetaryComputerAsyncCredentialProvider","text":"<p>A CredentialProvider for AzureStore for accessing Planetary Computer data resources.</p>"},{"location":"api/auth/planetary-computer/#obstore.auth.planetary_computer.PlanetaryComputerAsyncCredentialProvider.__init__","title":"__init__","text":"<pre><code>__init__(\n    url: str | None = None,\n    *,\n    account_name: str | None = None,\n    container_name: str | None = None,\n    session: ClientSession | None = None,\n    subscription_key: str | None = None,\n    sas_url: str | None = None,\n) -&gt; None\n</code></pre> <p>Construct a new PlanetaryComputerAsyncCredentialProvider.</p> <p>This credential provider uses <code>aiohttp</code>, and will error if that cannot be imported.</p> <p>Refer to PlanetaryComputerCredentialProvider for argument explanations.</p>"},{"location":"api/auth/planetary-computer/#obstore.auth.planetary_computer.PlanetaryComputerAsyncCredentialProvider.from_asset","title":"from_asset  <code>classmethod</code>","text":"<pre><code>from_asset(\n    asset: Asset | dict[str, Any],\n    *,\n    session: ClientSession | None = None,\n    subscription_key: str | None = None,\n    sas_url: str | None = None,\n) -&gt; Self\n</code></pre> <p>Create from a STAC Asset.</p> <p>Refer to PlanetaryComputerCredentialProvider.from_asset for argument explanations.</p>"},{"location":"api/auth/planetary-computer/#obstore.auth.planetary_computer.PlanetaryComputerAsyncCredentialProvider.__call__","title":"__call__  <code>async</code>","text":"<pre><code>__call__() -&gt; AzureSASToken\n</code></pre> <p>Fetch a new token.</p>"},{"location":"api/store/","title":"ObjectStore","text":""},{"location":"api/store/#obstore.store.from_url","title":"obstore.store.from_url","text":"<pre><code>from_url(\n    url: str,\n    *,\n    config: S3Config | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    credential_provider: S3CredentialProvider | None = None,\n    **kwargs: Unpack[S3Config],\n) -&gt; ObjectStore\n</code></pre><pre><code>from_url(\n    url: str,\n    *,\n    config: GCSConfig | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    credential_provider: GCSCredentialProvider | None = None,\n    **kwargs: Unpack[GCSConfig],\n) -&gt; ObjectStore\n</code></pre><pre><code>from_url(\n    url: str,\n    *,\n    config: AzureConfig | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    credential_provider: AzureCredentialProvider | None = None,\n    **kwargs: Unpack[AzureConfig],\n) -&gt; ObjectStore\n</code></pre><pre><code>from_url(\n    url: str,\n    *,\n    config: None = None,\n    client_options: None = None,\n    retry_config: None = None,\n    automatic_cleanup: bool = False,\n    mkdir: bool = False,\n) -&gt; ObjectStore\n</code></pre> <pre><code>from_url(\n    url: str,\n    *,\n    config: S3Config | GCSConfig | AzureConfig | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    credential_provider: S3CredentialProvider\n    | GCSCredentialProvider\n    | AzureCredentialProvider\n    | None = None,\n    **kwargs: Any,\n) -&gt; ObjectStore\n</code></pre> <p>Easy construction of store by URL, identifying the relevant store.</p> <p>This will defer to a store-specific <code>from_url</code> constructor based on the provided <code>url</code>. E.g. passing <code>\"s3://bucket/path\"</code> will defer to <code>S3Store.from_url</code>.</p> <p>Any path on the URL will be assigned as the <code>prefix</code> for the store. So if you pass <code>s3://bucket/path/to/directory</code>, the store will be created with a prefix of <code>path/to/directory</code>, and all further operations will use paths relative to that prefix.</p> <p>Supported formats:</p> <ul> <li><code>file:///path/</code> -&gt; <code>LocalStore</code></li> <li><code>memory:///</code> -&gt; <code>MemoryStore</code></li> <li><code>s3://bucket/path</code> -&gt; <code>S3Store</code> (also supports <code>s3a</code>)</li> <li><code>gs://bucket/path</code> -&gt; <code>GCSStore</code></li> <li><code>az://account/container/path</code> -&gt; <code>AzureStore</code> (also   supports <code>adl</code>, <code>azure</code>, <code>abfs</code>, <code>abfss</code>)</li> <li><code>http://mydomain/path</code> -&gt; <code>HTTPStore</code></li> <li><code>https://mydomain/path</code> -&gt; <code>HTTPStore</code></li> </ul> <p>There are also special cases for AWS and Azure for <code>https://{host?}/path</code> paths:</p> <ul> <li><code>dfs.core.windows.net</code>, <code>blob.core.windows.net</code>, <code>dfs.fabric.microsoft.com</code>,   <code>blob.fabric.microsoft.com</code> -&gt; <code>AzureStore</code></li> <li><code>amazonaws.com</code> -&gt; <code>S3Store</code></li> <li><code>r2.cloudflarestorage.com</code> -&gt; <code>S3Store</code></li> </ul> <p>Note</p> <p>For best static typing, use the constructors on individual store classes directly.</p> <p>Parameters:</p> <ul> <li> <code>url</code>               (<code>str</code>)           \u2013            <p>well-known storage URL.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>config</code>               (<code>S3Config | GCSConfig | AzureConfig | None</code>)           \u2013            <p>per-store Configuration. Values in this config will override values inferred from the url. Defaults to None.</p> </li> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> <li> <code>credential_provider</code>               (<code>S3CredentialProvider | GCSCredentialProvider | AzureCredentialProvider | None</code>)           \u2013            <p>A callback to provide custom credentials to the underlying store classes.</p> </li> <li> <code>kwargs</code>               (<code>Any</code>)           \u2013            <p>per-store configuration passed down to store-specific builders.</p> </li> </ul>"},{"location":"api/store/#obstore.store.ObjectStore","title":"obstore.store.ObjectStore  <code>module-attribute</code>","text":"<pre><code>ObjectStore: TypeAlias = Union[\n    AzureStore, GCSStore, HTTPStore, S3Store, LocalStore, MemoryStore\n]\n</code></pre> <p>All supported ObjectStore implementations.</p>"},{"location":"api/store/aws/","title":"AWS S3","text":""},{"location":"api/store/aws/#obstore.store.S3Store","title":"obstore.store.S3Store","text":"<p>Interface to an Amazon S3 bucket.</p> <p>All constructors will check for environment variables. Refer to <code>S3Config</code> for valid environment variables.</p> <p>Examples:</p> <p>Using requester-pays buckets:</p> <p>Pass <code>request_payer=True</code> as a keyword argument or have <code>AWS_REQUESTER_PAYS=True</code> set in the environment.</p> <p>Anonymous requests:</p> <p>Pass <code>skip_signature=True</code> as a keyword argument or have <code>AWS_SKIP_SIGNATURE=True</code> set in the environment.</p>"},{"location":"api/store/aws/#obstore.store.S3Store.client_options","title":"client_options  <code>property</code>","text":"<pre><code>client_options: ClientConfig | None\n</code></pre> <p>Get the store's client configuration.</p>"},{"location":"api/store/aws/#obstore.store.S3Store.config","title":"config  <code>property</code>","text":"<pre><code>config: S3Config\n</code></pre> <p>Get the underlying S3 config parameters.</p>"},{"location":"api/store/aws/#obstore.store.S3Store.credential_provider","title":"credential_provider  <code>property</code>","text":"<pre><code>credential_provider: S3CredentialProvider | None\n</code></pre> <p>Get the store's credential provider.</p>"},{"location":"api/store/aws/#obstore.store.S3Store.prefix","title":"prefix  <code>property</code>","text":"<pre><code>prefix: str | None\n</code></pre> <p>Get the prefix applied to all operations in this store, if any.</p>"},{"location":"api/store/aws/#obstore.store.S3Store.retry_config","title":"retry_config  <code>property</code>","text":"<pre><code>retry_config: RetryConfig | None\n</code></pre> <p>Get the store's retry configuration.</p>"},{"location":"api/store/aws/#obstore.store.S3Store.__init__","title":"__init__","text":"<pre><code>__init__(\n    bucket: str | None = None,\n    *,\n    prefix: str | None = None,\n    config: S3Config | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    credential_provider: S3CredentialProvider | None = None,\n    **kwargs: Unpack[S3Config],\n) -&gt; None\n</code></pre> <p>Create a new S3Store.</p> <p>Parameters:</p> <ul> <li> <code>bucket</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>The AWS bucket to use.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>prefix</code>               (<code>str | None</code>)           \u2013            <p>A prefix within the bucket to use for all operations.</p> </li> <li> <code>config</code>               (<code>S3Config | None</code>)           \u2013            <p>AWS configuration. Values in this config will override values inferred from the environment. Defaults to None.</p> </li> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> <li> <code>credential_provider</code>               (<code>S3CredentialProvider | None</code>)           \u2013            <p>A callback to provide custom S3 credentials.</p> </li> <li> <code>kwargs</code>               (<code>Unpack[S3Config]</code>)           \u2013            <p>AWS configuration values. Supports the same values as <code>config</code>, but as named keyword args.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>S3Store</p> </li> </ul>"},{"location":"api/store/aws/#obstore.store.S3Store.copy","title":"copy","text":"<pre><code>copy(from_: str, to: str, *, overwrite: bool = True) -&gt; None\n</code></pre> <p>Copy an object from one path to another in the same object store.</p> <p>Refer to the documentation for copy.</p>"},{"location":"api/store/aws/#obstore.store.S3Store.copy_async","title":"copy_async  <code>async</code>","text":"<pre><code>copy_async(from_: str, to: str, *, overwrite: bool = True) -&gt; None\n</code></pre> <p>Call <code>copy</code> asynchronously.</p> <p>Refer to the documentation for copy.</p>"},{"location":"api/store/aws/#obstore.store.S3Store.delete","title":"delete","text":"<pre><code>delete(paths: str | Sequence[str]) -&gt; None\n</code></pre> <p>Delete the object at the specified location(s).</p> <p>Refer to the documentation for delete.</p>"},{"location":"api/store/aws/#obstore.store.S3Store.delete_async","title":"delete_async  <code>async</code>","text":"<pre><code>delete_async(paths: str | Sequence[str]) -&gt; None\n</code></pre> <p>Call <code>delete</code> asynchronously.</p> <p>Refer to the documentation for delete.</p>"},{"location":"api/store/aws/#obstore.store.S3Store.from_url","title":"from_url  <code>classmethod</code>","text":"<pre><code>from_url(\n    url: str,\n    *,\n    config: S3Config | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    credential_provider: S3CredentialProvider | None = None,\n    **kwargs: Unpack[S3Config],\n) -&gt; Self\n</code></pre> <p>Parse available connection info from a well-known storage URL.</p> <p>Any path on the URL will be assigned as the <code>prefix</code> for the store. So if you pass <code>s3://bucket/path/to/directory</code>, the store will be created with a prefix of <code>path/to/directory</code>, and all further operations will use paths relative to that prefix.</p> <p>The supported url schemes are:</p> <ul> <li><code>s3://&lt;bucket&gt;/&lt;path&gt;</code></li> <li><code>s3a://&lt;bucket&gt;/&lt;path&gt;</code></li> <li><code>https://s3.&lt;region&gt;.amazonaws.com/&lt;bucket&gt;</code></li> <li><code>https://&lt;bucket&gt;.s3.&lt;region&gt;.amazonaws.com</code></li> <li><code>https://ACCOUNT_ID.r2.cloudflarestorage.com/bucket</code></li> </ul> <p>Parameters:</p> <ul> <li> <code>url</code>               (<code>str</code>)           \u2013            <p>well-known storage URL.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>config</code>               (<code>S3Config | None</code>)           \u2013            <p>AWS Configuration. Values in this config will override values inferred from the url. Defaults to None.</p> </li> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> <li> <code>credential_provider</code>               (<code>S3CredentialProvider | None</code>)           \u2013            <p>A callback to provide custom S3 credentials.</p> </li> <li> <code>kwargs</code>               (<code>Unpack[S3Config]</code>)           \u2013            <p>AWS configuration values. Supports the same values as <code>config</code>, but as named keyword args.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Self</code>           \u2013            <p>S3Store</p> </li> </ul>"},{"location":"api/store/aws/#obstore.store.S3Store.get","title":"get","text":"<pre><code>get(path: str, *, options: GetOptions | None = None) -&gt; GetResult\n</code></pre> <p>Return the bytes that are stored at the specified location.</p> <p>Refer to the documentation for get.</p>"},{"location":"api/store/aws/#obstore.store.S3Store.get_async","title":"get_async  <code>async</code>","text":"<pre><code>get_async(path: str, *, options: GetOptions | None = None) -&gt; GetResult\n</code></pre> <p>Call <code>get</code> asynchronously.</p> <p>Refer to the documentation for get.</p>"},{"location":"api/store/aws/#obstore.store.S3Store.get_range","title":"get_range","text":"<pre><code>get_range(\n    path: str, *, start: int, end: int | None = None, length: int | None = None\n) -&gt; Bytes\n</code></pre> <p>Return the bytes stored at the specified location in the given byte range.</p> <p>Refer to the documentation for get_range.</p>"},{"location":"api/store/aws/#obstore.store.S3Store.get_range_async","title":"get_range_async  <code>async</code>","text":"<pre><code>get_range_async(\n    path: str, *, start: int, end: int | None = None, length: int | None = None\n) -&gt; Bytes\n</code></pre> <p>Call <code>get_range</code> asynchronously.</p> <p>Refer to the documentation for get_range.</p>"},{"location":"api/store/aws/#obstore.store.S3Store.get_ranges","title":"get_ranges","text":"<pre><code>get_ranges(\n    path: str,\n    *,\n    starts: Sequence[int],\n    ends: Sequence[int] | None = None,\n    lengths: Sequence[int] | None = None,\n) -&gt; list[Bytes]\n</code></pre> <p>Return the bytes stored at the specified location in the given byte ranges.</p> <p>Refer to the documentation for get_ranges.</p>"},{"location":"api/store/aws/#obstore.store.S3Store.get_ranges_async","title":"get_ranges_async  <code>async</code>","text":"<pre><code>get_ranges_async(\n    path: str,\n    *,\n    starts: Sequence[int],\n    ends: Sequence[int] | None = None,\n    lengths: Sequence[int] | None = None,\n) -&gt; list[Bytes]\n</code></pre> <p>Call <code>get_ranges</code> asynchronously.</p> <p>Refer to the documentation for get_ranges.</p>"},{"location":"api/store/aws/#obstore.store.S3Store.head","title":"head","text":"<pre><code>head(path: str) -&gt; ObjectMeta\n</code></pre> <p>Return the metadata for the specified location.</p> <p>Refer to the documentation for head.</p>"},{"location":"api/store/aws/#obstore.store.S3Store.head_async","title":"head_async  <code>async</code>","text":"<pre><code>head_async(path: str) -&gt; ObjectMeta\n</code></pre> <p>Call <code>head</code> asynchronously.</p> <p>Refer to the documentation for head_async.</p>"},{"location":"api/store/aws/#obstore.store.S3Store.list","title":"list","text":"<pre><code>list(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[True],\n) -&gt; ListStream[RecordBatch]\n</code></pre><pre><code>list(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[False] = False,\n) -&gt; ListStream[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: bool = False,\n) -&gt; ListStream[RecordBatch] | ListStream[Sequence[ObjectMeta]]\n</code></pre> <p>List all the objects with the given prefix.</p> <p>Refer to the documentation for list.</p>"},{"location":"api/store/aws/#obstore.store.S3Store.list_async","title":"list_async","text":"<pre><code>list_async(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[True],\n) -&gt; ListStream[RecordBatch]\n</code></pre><pre><code>list_async(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[False] = False,\n) -&gt; ListStream[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list_async(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: bool = False,\n) -&gt; ListStream[RecordBatch] | ListStream[Sequence[ObjectMeta]]\n</code></pre> <p>List all the objects with the given prefix.</p> <p>Refer to the documentation for list.</p> <p>Note</p> <p>This is an alias for <code>list</code>, provided to match the <code>ListAsync</code> protocol in obspec. There is no difference in functionality between this and the <code>list</code> method.</p>"},{"location":"api/store/aws/#obstore.store.S3Store.list_with_delimiter","title":"list_with_delimiter","text":"<pre><code>list_with_delimiter(\n    prefix: str | None = None, *, return_arrow: Literal[True]\n) -&gt; ListResult[Table]\n</code></pre><pre><code>list_with_delimiter(\n    prefix: str | None = None, *, return_arrow: Literal[False] = False\n) -&gt; ListResult[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list_with_delimiter(\n    prefix: str | None = None, *, return_arrow: bool = False\n) -&gt; ListResult[Table] | ListResult[Sequence[ObjectMeta]]\n</code></pre> <p>List objects with the given prefix and an implementation specific delimiter.</p> <p>Refer to the documentation for list_with_delimiter.</p>"},{"location":"api/store/aws/#obstore.store.S3Store.list_with_delimiter_async","title":"list_with_delimiter_async  <code>async</code>","text":"<pre><code>list_with_delimiter_async(\n    prefix: str | None = None, *, return_arrow: Literal[True]\n) -&gt; ListResult[Table]\n</code></pre><pre><code>list_with_delimiter_async(\n    prefix: str | None = None, *, return_arrow: Literal[False] = False\n) -&gt; ListResult[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list_with_delimiter_async(\n    prefix: str | None = None, *, return_arrow: bool = False\n) -&gt; ListResult[Table] | ListResult[Sequence[ObjectMeta]]\n</code></pre> <p>Call <code>list_with_delimiter</code> asynchronously.</p> <p>Refer to the documentation for list_with_delimiter.</p>"},{"location":"api/store/aws/#obstore.store.S3Store.put","title":"put","text":"<pre><code>put(\n    path: str,\n    file: IO[bytes]\n    | Path\n    | bytes\n    | Buffer\n    | Iterator[Buffer]\n    | Iterable[Buffer],\n    *,\n    attributes: Attributes | None = None,\n    tags: dict[str, str] | None = None,\n    mode: PutMode | None = None,\n    use_multipart: bool | None = None,\n    chunk_size: int = 5 * 1024 * 1024,\n    max_concurrency: int = 12,\n) -&gt; PutResult\n</code></pre> <p>Save the provided bytes to the specified location.</p> <p>Refer to the documentation for put.</p>"},{"location":"api/store/aws/#obstore.store.S3Store.put_async","title":"put_async  <code>async</code>","text":"<pre><code>put_async(\n    path: str,\n    file: IO[bytes]\n    | Path\n    | bytes\n    | Buffer\n    | AsyncIterator[Buffer]\n    | AsyncIterable[Buffer]\n    | Iterator[Buffer]\n    | Iterable[Buffer],\n    *,\n    attributes: Attributes | None = None,\n    tags: dict[str, str] | None = None,\n    mode: PutMode | None = None,\n    use_multipart: bool | None = None,\n    chunk_size: int = 5 * 1024 * 1024,\n    max_concurrency: int = 12,\n) -&gt; PutResult\n</code></pre> <p>Call <code>put</code> asynchronously.</p> <p>Refer to the documentation for <code>put</code>. In addition to what the synchronous <code>put</code> allows for the <code>file</code> parameter, this also supports an async iterator or iterable of objects implementing the Python buffer protocol.</p> <p>This means, for example, you can pass the result of <code>get_async</code> directly to <code>put_async</code>, and the request will be streamed through Python during the put operation:</p> <pre><code>import obstore as obs\n\n# This only constructs the stream, it doesn't materialize the data in memory\nresp = await obs.get_async(store1, path1)\n# A streaming upload is created to copy the file to path2\nawait obs.put_async(store2, path2)\n</code></pre>"},{"location":"api/store/aws/#obstore.store.S3Store.rename","title":"rename","text":"<pre><code>rename(from_: str, to: str, *, overwrite: bool = True) -&gt; None\n</code></pre> <p>Move an object from one path to another in the same object store.</p> <p>Refer to the documentation for rename.</p>"},{"location":"api/store/aws/#obstore.store.S3Store.rename_async","title":"rename_async  <code>async</code>","text":"<pre><code>rename_async(from_: str, to: str, *, overwrite: bool = True) -&gt; None\n</code></pre> <p>Call <code>rename</code> asynchronously.</p> <p>Refer to the documentation for rename.</p>"},{"location":"api/store/aws/#obstore.store.S3Config","title":"obstore.store.S3Config","text":"<p>               Bases: <code>TypedDict</code></p> <p>Configuration parameters for S3Store.</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore.store import S3Config\n</code></pre>"},{"location":"api/store/aws/#obstore.store.S3Config.access_key_id","title":"access_key_id  <code>instance-attribute</code>","text":"<pre><code>access_key_id: str\n</code></pre> <p>AWS Access Key.</p> <p>Environment variable: <code>AWS_ACCESS_KEY_ID</code>.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.bucket","title":"bucket  <code>instance-attribute</code>","text":"<pre><code>bucket: str\n</code></pre> <p>Bucket name (required).</p> <p>Environment variables:</p> <ul> <li><code>AWS_BUCKET</code></li> <li><code>AWS_BUCKET_NAME</code></li> </ul>"},{"location":"api/store/aws/#obstore.store.S3Config.checksum_algorithm","title":"checksum_algorithm  <code>instance-attribute</code>","text":"<pre><code>checksum_algorithm: S3ChecksumAlgorithm | str\n</code></pre> <p>Sets the checksum algorithm which has to be used for object integrity check during upload.</p> <p>Environment variable: <code>AWS_CHECKSUM_ALGORITHM</code>.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.conditional_put","title":"conditional_put  <code>instance-attribute</code>","text":"<pre><code>conditional_put: str\n</code></pre> <p>Configure how to provide conditional put support</p> <p>Supported values:</p> <ul> <li> <p><code>\"etag\"</code> (default): Supported for S3-compatible stores that support conditional     put using the standard HTTP precondition headers <code>If-Match</code> and     <code>If-None-Match</code>.</p> </li> <li> <p><code>\"dynamo:&lt;TABLE_NAME&gt;\"</code> or <code>\"dynamo:&lt;TABLE_NAME&gt;:&lt;TIMEOUT_MILLIS&gt;\"</code>: The name of a DynamoDB table to use for coordination.</p> <p>This will use the same region, credentials and endpoint as configured for S3.</p> </li> </ul> <p>Environment variable: <code>AWS_CONDITIONAL_PUT</code>.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.container_credentials_relative_uri","title":"container_credentials_relative_uri  <code>instance-attribute</code>","text":"<pre><code>container_credentials_relative_uri: str\n</code></pre> <p>Set the container credentials relative URI</p> <p>docs.aws.amazon.com/AmazonECS/latest/developerguide/task-iam-roles.html</p> <p>Environment variable: <code>AWS_CONTAINER_CREDENTIALS_RELATIVE_URI</code>.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.copy_if_not_exists","title":"copy_if_not_exists  <code>instance-attribute</code>","text":"<pre><code>copy_if_not_exists: Literal['multipart'] | str\n</code></pre> <p>Configure how to provide \"copy if not exists\".</p> <p>Supported values:</p> <ul> <li> <p><code>\"multipart\"</code>:</p> <p>Native Amazon S3 supports copy if not exists through a multipart upload where the upload copies an existing object and is completed only if the new object does not already exist.</p> <p>Warning</p> <p>When using this mode, <code>copy_if_not_exists</code> does not copy tags or attributes from the source object.</p> <p>Warning</p> <p>When using this mode, <code>copy_if_not_exists</code> makes only a best effort attempt to clean up the multipart upload if the copy operation fails. Consider using a lifecycle rule to automatically clean up abandoned multipart uploads.</p> </li> <li> <p><code>\"header:&lt;HEADER_NAME&gt;:&lt;HEADER_VALUE&gt;\"</code>:</p> <p>Some S3-compatible stores, such as Cloudflare R2, support copy if not exists semantics through custom headers.</p> <p>If set, <code>copy_if_not_exists</code> will perform a normal copy operation with the provided header pair, and expect the store to fail with <code>412 Precondition Failed</code> if the destination file already exists.</p> <p>For example <code>header: cf-copy-destination-if-none-match: *</code>, would set the header <code>cf-copy-destination-if-none-match</code> to <code>*</code>.</p> </li> <li> <p><code>\"header-with-status:&lt;HEADER_NAME&gt;:&lt;HEADER_VALUE&gt;:&lt;STATUS&gt;\"</code>:</p> <p>The same as the header variant above but allows custom status code checking, for object stores that return values other than 412.</p> </li> <li> <p><code>\"dynamo:&lt;TABLE_NAME&gt;\"</code> or <code>\"dynamo:&lt;TABLE_NAME&gt;:&lt;TIMEOUT_MILLIS&gt;\"</code>:</p> <p>The name of a DynamoDB table to use for coordination.</p> <p>The default timeout is used if not specified. This will use the same region, credentials and endpoint as configured for S3.</p> </li> </ul> <p>Environment variable: <code>AWS_COPY_IF_NOT_EXISTS</code>.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.default_region","title":"default_region  <code>instance-attribute</code>","text":"<pre><code>default_region: S3Regions | str\n</code></pre> <p>Default region.</p> <p>Environment variable: <code>AWS_DEFAULT_REGION</code>.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.disable_tagging","title":"disable_tagging  <code>instance-attribute</code>","text":"<pre><code>disable_tagging: bool\n</code></pre> <p>Disable tagging objects. This can be desirable if not supported by the backing store.</p> <p>Environment variable: <code>AWS_DISABLE_TAGGING</code>.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.endpoint","title":"endpoint  <code>instance-attribute</code>","text":"<pre><code>endpoint: str\n</code></pre> <p>The endpoint for communicating with AWS S3.</p> <p>Defaults to the region endpoint.</p> <p>For example, this might be set to <code>\"http://localhost:4566:</code> for testing against a localstack instance.</p> <p>The <code>endpoint</code> field should be consistent with <code>with_virtual_hosted_style_request</code>, i.e. if <code>virtual_hosted_style_request</code> is set to <code>True</code> then <code>endpoint</code> should have the bucket name included.</p> <p>By default, only HTTPS schemes are enabled. To connect to an HTTP endpoint, enable <code>allow_http</code> in the client options.</p> <p>Environment variables:</p> <ul> <li><code>AWS_ENDPOINT_URL</code></li> <li><code>AWS_ENDPOINT</code></li> </ul>"},{"location":"api/store/aws/#obstore.store.S3Config.imdsv1_fallback","title":"imdsv1_fallback  <code>instance-attribute</code>","text":"<pre><code>imdsv1_fallback: bool\n</code></pre> <p>Fall back to ImdsV1.</p> <p>By default instance credentials will only be fetched over IMDSv2, as AWS recommends against having IMDSv1 enabled on EC2 instances as it is vulnerable to SSRF attack</p> <p>However, certain deployment environments, such as those running old versions of kube2iam, may not support IMDSv2. This option will enable automatic fallback to using IMDSv1 if the token endpoint returns a 403 error indicating that IMDSv2 is not supported.</p> <p>This option has no effect if not using instance credentials.</p> <p>Environment variable: <code>AWS_IMDSV1_FALLBACK</code>.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.metadata_endpoint","title":"metadata_endpoint  <code>instance-attribute</code>","text":"<pre><code>metadata_endpoint: str\n</code></pre> <p>Set the [instance metadata endpoint], used primarily within AWS EC2.</p> <p>This defaults to the IPv4 endpoint: <code>http://169.254.169.254</code>. One can alternatively use the IPv6 endpoint <code>http://fd00:ec2::254</code>.</p> <p>Environment variable: <code>AWS_METADATA_ENDPOINT</code>.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.region","title":"region  <code>instance-attribute</code>","text":"<pre><code>region: S3Regions | str\n</code></pre> <p>The region, defaults to <code>us-east-1</code></p> <p>Environment variable: <code>AWS_REGION</code>.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.request_payer","title":"request_payer  <code>instance-attribute</code>","text":"<pre><code>request_payer: bool\n</code></pre> <p>If <code>True</code>, enable operations on requester-pays buckets.</p> <p>docs.aws.amazon.com/AmazonS3/latest/userguide/RequesterPaysBuckets.html</p> <p>Environment variable: <code>AWS_REQUEST_PAYER</code>.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.s3_express","title":"s3_express  <code>instance-attribute</code>","text":"<pre><code>s3_express: bool\n</code></pre> <p>Enable Support for S3 Express One Zone.</p> <p>Environment variable: <code>AWS_S3_EXPRESS</code>.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.secret_access_key","title":"secret_access_key  <code>instance-attribute</code>","text":"<pre><code>secret_access_key: str\n</code></pre> <p>Secret Access Key.</p> <p>Environment variable: <code>AWS_SECRET_ACCESS_KEY</code>.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.server_side_encryption","title":"server_side_encryption  <code>instance-attribute</code>","text":"<pre><code>server_side_encryption: S3EncryptionAlgorithm | str\n</code></pre> <p>Type of encryption to use.</p> <p>If set, must be one of:</p> <ul> <li><code>\"AES256\"</code> (SSE-S3)</li> <li><code>\"aws:kms\"</code> (SSE-KMS)</li> <li><code>\"aws:kms:dsse\"</code> (DSSE-KMS)</li> <li><code>\"sse-c\"</code></li> </ul> <p>Environment variable: <code>AWS_SERVER_SIDE_ENCRYPTION</code>.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.session_token","title":"session_token  <code>instance-attribute</code>","text":"<pre><code>session_token: str\n</code></pre> <p>Token to use for requests (passed to underlying provider).</p> <p>Environment variables:</p> <ul> <li><code>AWS_SESSION_TOKEN</code></li> <li><code>AWS_TOKEN</code></li> </ul>"},{"location":"api/store/aws/#obstore.store.S3Config.skip_signature","title":"skip_signature  <code>instance-attribute</code>","text":"<pre><code>skip_signature: bool\n</code></pre> <p>If <code>True</code>, S3Store will not fetch credentials and will not sign requests.</p> <p>This can be useful when interacting with public S3 buckets that deny authorized requests.</p> <p>Environment variable: <code>AWS_SKIP_SIGNATURE</code>.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.sse_bucket_key_enabled","title":"sse_bucket_key_enabled  <code>instance-attribute</code>","text":"<pre><code>sse_bucket_key_enabled: bool\n</code></pre> <p>Set whether to enable bucket key for server side encryption.</p> <p>This overrides the bucket default setting for bucket keys.</p> <ul> <li>When <code>False</code>, each object is encrypted with a unique data key.</li> <li>When <code>True</code>, a single data key is used for the entire bucket,   reducing overhead of encryption.</li> </ul> <p>Environment variable: <code>AWS_SSE_BUCKET_KEY_ENABLED</code>.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.sse_customer_key_base64","title":"sse_customer_key_base64  <code>instance-attribute</code>","text":"<pre><code>sse_customer_key_base64: str\n</code></pre> <p>The base64 encoded, 256-bit customer encryption key to use for server-side encryption. If set, the server side encryption config value must be <code>\"sse-c\"</code>.</p> <p>Environment variable: <code>AWS_SSE_CUSTOMER_KEY_BASE64</code>.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.sse_kms_key_id","title":"sse_kms_key_id  <code>instance-attribute</code>","text":"<pre><code>sse_kms_key_id: str\n</code></pre> <p>The KMS key ID to use for server-side encryption.</p> <p>If set, the server side encryption config value must be <code>\"aws:kms\"</code> or <code>\"aws:kms:dsse\"</code>.</p> <p>Environment variable: <code>AWS_SSE_KMS_KEY_ID</code>.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.unsigned_payload","title":"unsigned_payload  <code>instance-attribute</code>","text":"<pre><code>unsigned_payload: bool\n</code></pre> <p>Avoid computing payload checksum when calculating signature.</p> <p>See unsigned payload option.</p> <ul> <li><code>False</code> (default): Signed payload option is used, where the checksum for the request body is computed and included when constructing a canonical request.</li> <li><code>True</code>: Unsigned payload option is used. <code>UNSIGNED-PAYLOAD</code> literal is included when constructing a canonical request,</li> </ul> <p>Environment variable: <code>AWS_UNSIGNED_PAYLOAD</code>.</p>"},{"location":"api/store/aws/#obstore.store.S3Config.virtual_hosted_style_request","title":"virtual_hosted_style_request  <code>instance-attribute</code>","text":"<pre><code>virtual_hosted_style_request: bool\n</code></pre> <p>If virtual hosted style request has to be used.</p> <p>If <code>virtual_hosted_style_request</code> is:</p> <ul> <li><code>False</code> (default):  Path style request is used</li> <li><code>True</code>:  Virtual hosted style request is used</li> </ul> <p>If the <code>endpoint</code> is provided then it should be consistent with <code>virtual_hosted_style_request</code>. i.e. if <code>virtual_hosted_style_request</code> is set to <code>True</code> then <code>endpoint</code> should have bucket name included.</p> <p>Environment variable: <code>AWS_VIRTUAL_HOSTED_STYLE_REQUEST</code>.</p>"},{"location":"api/store/aws/#obstore.store.S3Credential","title":"obstore.store.S3Credential","text":"<p>               Bases: <code>TypedDict</code></p> <p>An S3 credential.</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore.store import S3Credential\n</code></pre>"},{"location":"api/store/aws/#obstore.store.S3Credential.access_key_id","title":"access_key_id  <code>instance-attribute</code>","text":"<pre><code>access_key_id: str\n</code></pre> <p>AWS access key ID.</p>"},{"location":"api/store/aws/#obstore.store.S3Credential.expires_at","title":"expires_at  <code>instance-attribute</code>","text":"<pre><code>expires_at: datetime | None\n</code></pre> <p>Expiry datetime of credential. The datetime should have time zone set.</p> <p>If None, the credential will never expire.</p>"},{"location":"api/store/aws/#obstore.store.S3Credential.secret_access_key","title":"secret_access_key  <code>instance-attribute</code>","text":"<pre><code>secret_access_key: str\n</code></pre> <p>AWS secret access key</p>"},{"location":"api/store/aws/#obstore.store.S3Credential.token","title":"token  <code>instance-attribute</code>","text":"<pre><code>token: NotRequired[str | None]\n</code></pre> <p>AWS token.</p>"},{"location":"api/store/aws/#obstore.store.S3CredentialProvider","title":"obstore.store.S3CredentialProvider","text":"<p>               Bases: <code>Protocol</code></p> <p>A type hint for a synchronous or asynchronous callback to provide custom S3 credentials.</p> <p>This should be passed into the <code>credential_provider</code> parameter of <code>S3Store</code>.</p> <p>Examples:</p> <p>Return static credentials that don't expire: <pre><code>def get_credentials() -&gt; S3Credential:\n    return {\n        \"access_key_id\": \"...\",\n        \"secret_access_key\": \"...\",\n        \"token\": None,\n        \"expires_at\": None,\n    }\n</code></pre></p> <p>Return static credentials that are valid for 5 minutes: <pre><code>from datetime import datetime, timedelta, UTC\n\nasync def get_credentials() -&gt; S3Credential:\n    return {\n        \"access_key_id\": \"...\",\n        \"secret_access_key\": \"...\",\n        \"token\": None,\n        \"expires_at\": datetime.now(UTC) + timedelta(minutes=5),\n    }\n</code></pre></p> <p>A class-based credential provider with state:</p> <pre><code>from __future__ import annotations\n\nfrom typing import TYPE_CHECKING\n\nimport boto3\nimport botocore.credentials\n\nif TYPE_CHECKING:\n    from obstore.store import S3Credential\n\n\nclass Boto3CredentialProvider:\n    credentials: botocore.credentials.Credentials\n\n    def __init__(self, session: boto3.session.Session) -&gt; None:\n        credentials = session.get_credentials()\n        if credentials is None:\n            raise ValueError(\"Received None from session.get_credentials\")\n\n        self.credentials = credentials\n\n    def __call__(self) -&gt; S3Credential:\n        frozen_credentials = self.credentials.get_frozen_credentials()\n        return {\n            \"access_key_id\": frozen_credentials.access_key,\n            \"secret_access_key\": frozen_credentials.secret_key,\n            \"token\": frozen_credentials.token,\n            \"expires_at\": None,\n        }\n</code></pre> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore.store import S3CredentialProvider\n</code></pre>"},{"location":"api/store/aws/#obstore.store.S3CredentialProvider.__call__","title":"__call__","text":"<pre><code>__call__() -&gt; S3Credential | Coroutine[Any, Any, S3Credential]\n</code></pre> <p>Return an <code>S3Credential</code>.</p>"},{"location":"api/store/azure/","title":"Microsoft Azure","text":""},{"location":"api/store/azure/#obstore.store.AzureStore","title":"obstore.store.AzureStore","text":"<p>Interface to a Microsoft Azure Blob Storage container.</p> <p>All constructors will check for environment variables. Refer to <code>AzureConfig</code> for valid environment variables.</p>"},{"location":"api/store/azure/#obstore.store.AzureStore.client_options","title":"client_options  <code>property</code>","text":"<pre><code>client_options: ClientConfig | None\n</code></pre> <p>Get the store's client configuration.</p>"},{"location":"api/store/azure/#obstore.store.AzureStore.config","title":"config  <code>property</code>","text":"<pre><code>config: AzureConfig\n</code></pre> <p>Get the underlying Azure config parameters.</p>"},{"location":"api/store/azure/#obstore.store.AzureStore.credential_provider","title":"credential_provider  <code>property</code>","text":"<pre><code>credential_provider: AzureCredentialProvider | None\n</code></pre> <p>Get the store's credential provider.</p>"},{"location":"api/store/azure/#obstore.store.AzureStore.prefix","title":"prefix  <code>property</code>","text":"<pre><code>prefix: str | None\n</code></pre> <p>Get the prefix applied to all operations in this store, if any.</p>"},{"location":"api/store/azure/#obstore.store.AzureStore.retry_config","title":"retry_config  <code>property</code>","text":"<pre><code>retry_config: RetryConfig | None\n</code></pre> <p>Get the store's retry configuration.</p>"},{"location":"api/store/azure/#obstore.store.AzureStore.__init__","title":"__init__","text":"<pre><code>__init__(\n    container_name: str | None = None,\n    *,\n    prefix: str | None = None,\n    config: AzureConfig | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    credential_provider: AzureCredentialProvider | None = None,\n    **kwargs: Unpack[AzureConfig],\n) -&gt; None\n</code></pre> <p>Construct a new AzureStore.</p> <p>Parameters:</p> <ul> <li> <code>container_name</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>the name of the container.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>prefix</code>               (<code>str | None</code>)           \u2013            <p>A prefix within the bucket to use for all operations.</p> </li> <li> <code>config</code>               (<code>AzureConfig | None</code>)           \u2013            <p>Azure Configuration. Values in this config will override values inferred from the url. Defaults to None.</p> </li> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> <li> <code>credential_provider</code>               (<code>AzureCredentialProvider | None</code>)           \u2013            <p>A callback to provide custom Azure credentials.</p> </li> <li> <code>kwargs</code>               (<code>Unpack[AzureConfig]</code>)           \u2013            <p>Azure configuration values. Supports the same values as <code>config</code>, but as named keyword args.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>AzureStore</p> </li> </ul>"},{"location":"api/store/azure/#obstore.store.AzureStore.copy","title":"copy","text":"<pre><code>copy(from_: str, to: str, *, overwrite: bool = True) -&gt; None\n</code></pre> <p>Copy an object from one path to another in the same object store.</p> <p>Refer to the documentation for copy.</p>"},{"location":"api/store/azure/#obstore.store.AzureStore.copy_async","title":"copy_async  <code>async</code>","text":"<pre><code>copy_async(from_: str, to: str, *, overwrite: bool = True) -&gt; None\n</code></pre> <p>Call <code>copy</code> asynchronously.</p> <p>Refer to the documentation for copy.</p>"},{"location":"api/store/azure/#obstore.store.AzureStore.delete","title":"delete","text":"<pre><code>delete(paths: str | Sequence[str]) -&gt; None\n</code></pre> <p>Delete the object at the specified location(s).</p> <p>Refer to the documentation for delete.</p>"},{"location":"api/store/azure/#obstore.store.AzureStore.delete_async","title":"delete_async  <code>async</code>","text":"<pre><code>delete_async(paths: str | Sequence[str]) -&gt; None\n</code></pre> <p>Call <code>delete</code> asynchronously.</p> <p>Refer to the documentation for delete.</p>"},{"location":"api/store/azure/#obstore.store.AzureStore.from_url","title":"from_url  <code>classmethod</code>","text":"<pre><code>from_url(\n    url: str,\n    *,\n    prefix: str | None = None,\n    config: AzureConfig | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    credential_provider: AzureCredentialProvider | None = None,\n    **kwargs: Unpack[AzureConfig],\n) -&gt; Self\n</code></pre> <p>Construct a new AzureStore with values populated from a well-known storage URL.</p> <p>Any path on the URL will be assigned as the <code>prefix</code> for the store. So if you pass <code>https://&lt;account&gt;.blob.core.windows.net/&lt;container&gt;/path/to/directory</code>, the store will be created with a prefix of <code>path/to/directory</code>, and all further operations will use paths relative to that prefix.</p> <p>The supported url schemes are:</p> <ul> <li><code>abfs[s]://&lt;container&gt;/&lt;path&gt;</code> (according to fsspec)</li> <li><code>abfs[s]://&lt;file_system&gt;@&lt;account_name&gt;.dfs.core.windows.net/&lt;path&gt;</code></li> <li><code>abfs[s]://&lt;file_system&gt;@&lt;account_name&gt;.dfs.fabric.microsoft.com/&lt;path&gt;</code></li> <li><code>az://&lt;container&gt;/&lt;path&gt;</code> (according to fsspec)</li> <li><code>adl://&lt;container&gt;/&lt;path&gt;</code> (according to fsspec)</li> <li><code>azure://&lt;container&gt;/&lt;path&gt;</code> (custom)</li> <li><code>https://&lt;account&gt;.dfs.core.windows.net</code></li> <li><code>https://&lt;account&gt;.blob.core.windows.net</code></li> <li><code>https://&lt;account&gt;.blob.core.windows.net/&lt;container&gt;</code></li> <li><code>https://&lt;account&gt;.dfs.fabric.microsoft.com</code></li> <li><code>https://&lt;account&gt;.dfs.fabric.microsoft.com/&lt;container&gt;</code></li> <li><code>https://&lt;account&gt;.blob.fabric.microsoft.com</code></li> <li><code>https://&lt;account&gt;.blob.fabric.microsoft.com/&lt;container&gt;</code></li> </ul> <p>Parameters:</p> <ul> <li> <code>url</code>               (<code>str</code>)           \u2013            <p>well-known storage URL.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>prefix</code>               (<code>str | None</code>)           \u2013            <p>A prefix within the bucket to use for all operations.</p> </li> <li> <code>config</code>               (<code>AzureConfig | None</code>)           \u2013            <p>Azure Configuration. Values in this config will override values inferred from the url. Defaults to None.</p> </li> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> <li> <code>credential_provider</code>               (<code>AzureCredentialProvider | None</code>)           \u2013            <p>A callback to provide custom Azure credentials.</p> </li> <li> <code>kwargs</code>               (<code>Unpack[AzureConfig]</code>)           \u2013            <p>Azure configuration values. Supports the same values as <code>config</code>, but as named keyword args.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Self</code>           \u2013            <p>AzureStore</p> </li> </ul>"},{"location":"api/store/azure/#obstore.store.AzureStore.get","title":"get","text":"<pre><code>get(path: str, *, options: GetOptions | None = None) -&gt; GetResult\n</code></pre> <p>Return the bytes that are stored at the specified location.</p> <p>Refer to the documentation for get.</p>"},{"location":"api/store/azure/#obstore.store.AzureStore.get_async","title":"get_async  <code>async</code>","text":"<pre><code>get_async(path: str, *, options: GetOptions | None = None) -&gt; GetResult\n</code></pre> <p>Call <code>get</code> asynchronously.</p> <p>Refer to the documentation for get.</p>"},{"location":"api/store/azure/#obstore.store.AzureStore.get_range","title":"get_range","text":"<pre><code>get_range(\n    path: str, *, start: int, end: int | None = None, length: int | None = None\n) -&gt; Bytes\n</code></pre> <p>Return the bytes stored at the specified location in the given byte range.</p> <p>Refer to the documentation for get_range.</p>"},{"location":"api/store/azure/#obstore.store.AzureStore.get_range_async","title":"get_range_async  <code>async</code>","text":"<pre><code>get_range_async(\n    path: str, *, start: int, end: int | None = None, length: int | None = None\n) -&gt; Bytes\n</code></pre> <p>Call <code>get_range</code> asynchronously.</p> <p>Refer to the documentation for get_range.</p>"},{"location":"api/store/azure/#obstore.store.AzureStore.get_ranges","title":"get_ranges","text":"<pre><code>get_ranges(\n    path: str,\n    *,\n    starts: Sequence[int],\n    ends: Sequence[int] | None = None,\n    lengths: Sequence[int] | None = None,\n) -&gt; list[Bytes]\n</code></pre> <p>Return the bytes stored at the specified location in the given byte ranges.</p> <p>Refer to the documentation for get_ranges.</p>"},{"location":"api/store/azure/#obstore.store.AzureStore.get_ranges_async","title":"get_ranges_async  <code>async</code>","text":"<pre><code>get_ranges_async(\n    path: str,\n    *,\n    starts: Sequence[int],\n    ends: Sequence[int] | None = None,\n    lengths: Sequence[int] | None = None,\n) -&gt; list[Bytes]\n</code></pre> <p>Call <code>get_ranges</code> asynchronously.</p> <p>Refer to the documentation for get_ranges.</p>"},{"location":"api/store/azure/#obstore.store.AzureStore.head","title":"head","text":"<pre><code>head(path: str) -&gt; ObjectMeta\n</code></pre> <p>Return the metadata for the specified location.</p> <p>Refer to the documentation for head.</p>"},{"location":"api/store/azure/#obstore.store.AzureStore.head_async","title":"head_async  <code>async</code>","text":"<pre><code>head_async(path: str) -&gt; ObjectMeta\n</code></pre> <p>Call <code>head</code> asynchronously.</p> <p>Refer to the documentation for head_async.</p>"},{"location":"api/store/azure/#obstore.store.AzureStore.list","title":"list","text":"<pre><code>list(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[True],\n) -&gt; ListStream[RecordBatch]\n</code></pre><pre><code>list(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[False] = False,\n) -&gt; ListStream[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: bool = False,\n) -&gt; ListStream[RecordBatch] | ListStream[Sequence[ObjectMeta]]\n</code></pre> <p>List all the objects with the given prefix.</p> <p>Refer to the documentation for list.</p>"},{"location":"api/store/azure/#obstore.store.AzureStore.list_async","title":"list_async","text":"<pre><code>list_async(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[True],\n) -&gt; ListStream[RecordBatch]\n</code></pre><pre><code>list_async(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[False] = False,\n) -&gt; ListStream[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list_async(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: bool = False,\n) -&gt; ListStream[RecordBatch] | ListStream[Sequence[ObjectMeta]]\n</code></pre> <p>List all the objects with the given prefix.</p> <p>Refer to the documentation for list.</p> <p>Note</p> <p>This is an alias for <code>list</code>, provided to match the <code>ListAsync</code> protocol in obspec. There is no difference in functionality between this and the <code>list</code> method.</p>"},{"location":"api/store/azure/#obstore.store.AzureStore.list_with_delimiter","title":"list_with_delimiter","text":"<pre><code>list_with_delimiter(\n    prefix: str | None = None, *, return_arrow: Literal[True]\n) -&gt; ListResult[Table]\n</code></pre><pre><code>list_with_delimiter(\n    prefix: str | None = None, *, return_arrow: Literal[False] = False\n) -&gt; ListResult[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list_with_delimiter(\n    prefix: str | None = None, *, return_arrow: bool = False\n) -&gt; ListResult[Table] | ListResult[Sequence[ObjectMeta]]\n</code></pre> <p>List objects with the given prefix and an implementation specific delimiter.</p> <p>Refer to the documentation for list_with_delimiter.</p>"},{"location":"api/store/azure/#obstore.store.AzureStore.list_with_delimiter_async","title":"list_with_delimiter_async  <code>async</code>","text":"<pre><code>list_with_delimiter_async(\n    prefix: str | None = None, *, return_arrow: Literal[True]\n) -&gt; ListResult[Table]\n</code></pre><pre><code>list_with_delimiter_async(\n    prefix: str | None = None, *, return_arrow: Literal[False] = False\n) -&gt; ListResult[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list_with_delimiter_async(\n    prefix: str | None = None, *, return_arrow: bool = False\n) -&gt; ListResult[Table] | ListResult[Sequence[ObjectMeta]]\n</code></pre> <p>Call <code>list_with_delimiter</code> asynchronously.</p> <p>Refer to the documentation for list_with_delimiter.</p>"},{"location":"api/store/azure/#obstore.store.AzureStore.put","title":"put","text":"<pre><code>put(\n    path: str,\n    file: IO[bytes]\n    | Path\n    | bytes\n    | Buffer\n    | Iterator[Buffer]\n    | Iterable[Buffer],\n    *,\n    attributes: Attributes | None = None,\n    tags: dict[str, str] | None = None,\n    mode: PutMode | None = None,\n    use_multipart: bool | None = None,\n    chunk_size: int = 5 * 1024 * 1024,\n    max_concurrency: int = 12,\n) -&gt; PutResult\n</code></pre> <p>Save the provided bytes to the specified location.</p> <p>Refer to the documentation for put.</p>"},{"location":"api/store/azure/#obstore.store.AzureStore.put_async","title":"put_async  <code>async</code>","text":"<pre><code>put_async(\n    path: str,\n    file: IO[bytes]\n    | Path\n    | bytes\n    | Buffer\n    | AsyncIterator[Buffer]\n    | AsyncIterable[Buffer]\n    | Iterator[Buffer]\n    | Iterable[Buffer],\n    *,\n    attributes: Attributes | None = None,\n    tags: dict[str, str] | None = None,\n    mode: PutMode | None = None,\n    use_multipart: bool | None = None,\n    chunk_size: int = 5 * 1024 * 1024,\n    max_concurrency: int = 12,\n) -&gt; PutResult\n</code></pre> <p>Call <code>put</code> asynchronously.</p> <p>Refer to the documentation for <code>put</code>. In addition to what the synchronous <code>put</code> allows for the <code>file</code> parameter, this also supports an async iterator or iterable of objects implementing the Python buffer protocol.</p> <p>This means, for example, you can pass the result of <code>get_async</code> directly to <code>put_async</code>, and the request will be streamed through Python during the put operation:</p> <pre><code>import obstore as obs\n\n# This only constructs the stream, it doesn't materialize the data in memory\nresp = await obs.get_async(store1, path1)\n# A streaming upload is created to copy the file to path2\nawait obs.put_async(store2, path2)\n</code></pre>"},{"location":"api/store/azure/#obstore.store.AzureStore.rename","title":"rename","text":"<pre><code>rename(from_: str, to: str, *, overwrite: bool = True) -&gt; None\n</code></pre> <p>Move an object from one path to another in the same object store.</p> <p>Refer to the documentation for rename.</p>"},{"location":"api/store/azure/#obstore.store.AzureStore.rename_async","title":"rename_async  <code>async</code>","text":"<pre><code>rename_async(from_: str, to: str, *, overwrite: bool = True) -&gt; None\n</code></pre> <p>Call <code>rename</code> asynchronously.</p> <p>Refer to the documentation for rename.</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig","title":"obstore.store.AzureConfig","text":"<p>               Bases: <code>TypedDict</code></p> <p>Configuration parameters for AzureStore.</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore.store import AzureConfig\n</code></pre>"},{"location":"api/store/azure/#obstore.store.AzureConfig.account_key","title":"account_key  <code>instance-attribute</code>","text":"<pre><code>account_key: str\n</code></pre> <p>Master key for accessing storage account.</p> <p>Environment variables:</p> <ul> <li><code>AZURE_STORAGE_ACCOUNT_KEY</code></li> <li><code>AZURE_STORAGE_ACCESS_KEY</code></li> <li><code>AZURE_STORAGE_MASTER_KEY</code></li> </ul>"},{"location":"api/store/azure/#obstore.store.AzureConfig.account_name","title":"account_name  <code>instance-attribute</code>","text":"<pre><code>account_name: str\n</code></pre> <p>The name of the azure storage account. (Required.)</p> <p>Environment variable: <code>AZURE_STORAGE_ACCOUNT_NAME</code>.</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.authority_host","title":"authority_host  <code>instance-attribute</code>","text":"<pre><code>authority_host: str\n</code></pre> <p>Sets an alternative authority host for OAuth based authorization.</p> <p>Defaults to <code>https://login.microsoftonline.com</code>.</p> <p>Common hosts for azure clouds are:</p> <ul> <li>Azure China: <code>\"https://login.chinacloudapi.cn\"</code></li> <li>Azure Germany: <code>\"https://login.microsoftonline.de\"</code></li> <li>Azure Government: <code>\"https://login.microsoftonline.us\"</code></li> <li>Azure Public: <code>\"https://login.microsoftonline.com\"</code></li> </ul> <p>Environment variables:</p> <ul> <li><code>AZURE_STORAGE_AUTHORITY_HOST</code></li> <li><code>AZURE_AUTHORITY_HOST</code></li> </ul>"},{"location":"api/store/azure/#obstore.store.AzureConfig.client_id","title":"client_id  <code>instance-attribute</code>","text":"<pre><code>client_id: str\n</code></pre> <p>The client id for use in client secret or k8s federated credential flow.</p> <p>Environment variables:</p> <ul> <li><code>AZURE_STORAGE_CLIENT_ID</code></li> <li><code>AZURE_CLIENT_ID</code></li> </ul>"},{"location":"api/store/azure/#obstore.store.AzureConfig.client_secret","title":"client_secret  <code>instance-attribute</code>","text":"<pre><code>client_secret: str\n</code></pre> <p>The client secret for use in client secret flow.</p> <p>Environment variables:</p> <ul> <li><code>AZURE_STORAGE_CLIENT_SECRET</code></li> <li><code>AZURE_CLIENT_SECRET</code></li> </ul>"},{"location":"api/store/azure/#obstore.store.AzureConfig.container_name","title":"container_name  <code>instance-attribute</code>","text":"<pre><code>container_name: str\n</code></pre> <p>Container name.</p> <p>Environment variable: <code>AZURE_CONTAINER_NAME</code>.</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.disable_tagging","title":"disable_tagging  <code>instance-attribute</code>","text":"<pre><code>disable_tagging: bool\n</code></pre> <p>If set to <code>True</code> will ignore any tags provided to uploads.</p> <p>Environment variable: <code>AZURE_DISABLE_TAGGING</code>.</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.endpoint","title":"endpoint  <code>instance-attribute</code>","text":"<pre><code>endpoint: str\n</code></pre> <p>Override the endpoint used to communicate with blob storage.</p> <p>Defaults to <code>https://{account}.blob.core.windows.net</code>.</p> <p>By default, only HTTPS schemes are enabled. To connect to an HTTP endpoint, enable <code>allow_http</code> in the client options.</p> <p>Environment variables:</p> <ul> <li><code>AZURE_STORAGE_ENDPOINT</code></li> <li><code>AZURE_ENDPOINT</code></li> </ul>"},{"location":"api/store/azure/#obstore.store.AzureConfig.fabric_cluster_identifier","title":"fabric_cluster_identifier  <code>instance-attribute</code>","text":"<pre><code>fabric_cluster_identifier: str\n</code></pre> <p>Cluster identifier for Fabric OAuth2 authentication.</p> <p>Environment variable: <code>AZURE_FABRIC_CLUSTER_IDENTIFIER</code>.</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.fabric_session_token","title":"fabric_session_token  <code>instance-attribute</code>","text":"<pre><code>fabric_session_token: str\n</code></pre> <p>Session token for Fabric OAuth2 authentication.</p> <p>Environment variable: <code>AZURE_FABRIC_SESSION_TOKEN</code>.</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.fabric_token_service_url","title":"fabric_token_service_url  <code>instance-attribute</code>","text":"<pre><code>fabric_token_service_url: str\n</code></pre> <p>Service URL for Fabric OAuth2 authentication.</p> <p>Environment variable: <code>AZURE_FABRIC_TOKEN_SERVICE_URL</code>.</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.fabric_workload_host","title":"fabric_workload_host  <code>instance-attribute</code>","text":"<pre><code>fabric_workload_host: str\n</code></pre> <p>Workload host for Fabric OAuth2 authentication.</p> <p>Environment variable: <code>AZURE_FABRIC_WORKLOAD_HOST</code>.</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.federated_token_file","title":"federated_token_file  <code>instance-attribute</code>","text":"<pre><code>federated_token_file: str\n</code></pre> <p>Sets a file path for acquiring azure federated identity token in k8s.</p> <p>Requires <code>client_id</code> and <code>tenant_id</code> to be set.</p> <p>Environment variable: <code>AZURE_FEDERATED_TOKEN_FILE</code>.</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.msi_endpoint","title":"msi_endpoint  <code>instance-attribute</code>","text":"<pre><code>msi_endpoint: str\n</code></pre> <p>Endpoint to request a imds managed identity token.</p> <p>Environment variables:</p> <ul> <li><code>AZURE_MSI_ENDPOINT</code></li> <li><code>AZURE_IDENTITY_ENDPOINT</code></li> </ul>"},{"location":"api/store/azure/#obstore.store.AzureConfig.msi_resource_id","title":"msi_resource_id  <code>instance-attribute</code>","text":"<pre><code>msi_resource_id: str\n</code></pre> <p>Msi resource id for use with managed identity authentication.</p> <p>Environment variable: <code>AZURE_MSI_RESOURCE_ID</code>.</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.object_id","title":"object_id  <code>instance-attribute</code>","text":"<pre><code>object_id: str\n</code></pre> <p>Object id for use with managed identity authentication.</p> <p>Environment variable: <code>AZURE_OBJECT_ID</code>.</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.sas_key","title":"sas_key  <code>instance-attribute</code>","text":"<pre><code>sas_key: str\n</code></pre> <p>Shared access signature.</p> <p>The signature is expected to be percent-encoded, <code>much</code>like they are provided in the azure storage explorer or azure portal.</p> <p>Environment variables:</p> <ul> <li><code>AZURE_STORAGE_SAS_KEY</code></li> <li><code>AZURE_STORAGE_SAS_TOKEN</code></li> </ul>"},{"location":"api/store/azure/#obstore.store.AzureConfig.skip_signature","title":"skip_signature  <code>instance-attribute</code>","text":"<pre><code>skip_signature: bool\n</code></pre> <p>If enabled, <code>AzureStore</code> will not fetch credentials and will not sign requests.</p> <p>This can be useful when interacting with public containers.</p> <p>Environment variable: <code>AZURE_SKIP_SIGNATURE</code>.</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.tenant_id","title":"tenant_id  <code>instance-attribute</code>","text":"<pre><code>tenant_id: str\n</code></pre> <p>The tenant id for use in client secret or k8s federated credential flow.</p> <p>Environment variables:</p> <ul> <li><code>AZURE_STORAGE_TENANT_ID</code></li> <li><code>AZURE_STORAGE_AUTHORITY_ID</code></li> <li><code>AZURE_TENANT_ID</code></li> <li><code>AZURE_AUTHORITY_ID</code></li> </ul>"},{"location":"api/store/azure/#obstore.store.AzureConfig.token","title":"token  <code>instance-attribute</code>","text":"<pre><code>token: str\n</code></pre> <p>A static bearer token to be used for authorizing requests.</p> <p>Environment variable: <code>AZURE_STORAGE_TOKEN</code>.</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.use_azure_cli","title":"use_azure_cli  <code>instance-attribute</code>","text":"<pre><code>use_azure_cli: bool\n</code></pre> <p>Set if the Azure Cli should be used for acquiring access token.</p> <p>learn.microsoft.com/en-us/cli/azure/account?view=azure-cli-latest#az-account-get-access-token.</p> <p>Environment variable: <code>AZURE_USE_AZURE_CLI</code>.</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.use_emulator","title":"use_emulator  <code>instance-attribute</code>","text":"<pre><code>use_emulator: bool\n</code></pre> <p>Set if the Azure emulator should be used (defaults to <code>False</code>).</p> <p>Environment variable: <code>AZURE_STORAGE_USE_EMULATOR</code>.</p>"},{"location":"api/store/azure/#obstore.store.AzureConfig.use_fabric_endpoint","title":"use_fabric_endpoint  <code>instance-attribute</code>","text":"<pre><code>use_fabric_endpoint: bool\n</code></pre> <p>Set if Microsoft Fabric url scheme should be used (defaults to <code>False</code>).</p> <p>When disabled the url scheme used is <code>https://{account}.blob.core.windows.net</code>. When enabled the url scheme used is <code>https://{account}.dfs.fabric.microsoft.com</code>.</p> <p>Note</p> <p><code>endpoint</code> will take precedence over this option.</p>"},{"location":"api/store/azure/#obstore.store.AzureAccessKey","title":"obstore.store.AzureAccessKey","text":"<p>               Bases: <code>TypedDict</code></p> <p>A shared Azure Storage Account Key.</p> <p>learn.microsoft.com/en-us/rest/api/storageservices/authorize-with-shared-key</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore.store import AzureAccessKey\n</code></pre>"},{"location":"api/store/azure/#obstore.store.AzureAccessKey.access_key","title":"access_key  <code>instance-attribute</code>","text":"<pre><code>access_key: str\n</code></pre> <p>Access key value.</p>"},{"location":"api/store/azure/#obstore.store.AzureAccessKey.expires_at","title":"expires_at  <code>instance-attribute</code>","text":"<pre><code>expires_at: datetime | None\n</code></pre> <p>Expiry datetime of credential. The datetime should have time zone set.</p> <p>If None, the credential will never expire.</p>"},{"location":"api/store/azure/#obstore.store.AzureSASToken","title":"obstore.store.AzureSASToken","text":"<p>               Bases: <code>TypedDict</code></p> <p>A shared access signature.</p> <p>learn.microsoft.com/en-us/rest/api/storageservices/delegate-access-with-shared-access-signature</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore.store import AzureSASToken\n</code></pre>"},{"location":"api/store/azure/#obstore.store.AzureSASToken.expires_at","title":"expires_at  <code>instance-attribute</code>","text":"<pre><code>expires_at: datetime | None\n</code></pre> <p>Expiry datetime of credential. The datetime should have time zone set.</p> <p>If None, the credential will never expire.</p>"},{"location":"api/store/azure/#obstore.store.AzureSASToken.sas_token","title":"sas_token  <code>instance-attribute</code>","text":"<pre><code>sas_token: str | list[tuple[str, str]]\n</code></pre> <p>SAS token.</p>"},{"location":"api/store/azure/#obstore.store.AzureBearerToken","title":"obstore.store.AzureBearerToken","text":"<p>               Bases: <code>TypedDict</code></p> <p>An authorization token.</p> <p>learn.microsoft.com/en-us/rest/api/storageservices/authorize-with-azure-active-directory</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore.store import AzureBearerToken\n</code></pre>"},{"location":"api/store/azure/#obstore.store.AzureBearerToken.expires_at","title":"expires_at  <code>instance-attribute</code>","text":"<pre><code>expires_at: datetime | None\n</code></pre> <p>Expiry datetime of credential. The datetime should have time zone set.</p> <p>If None, the credential will never expire.</p>"},{"location":"api/store/azure/#obstore.store.AzureBearerToken.token","title":"token  <code>instance-attribute</code>","text":"<pre><code>token: str\n</code></pre> <p>Bearer token.</p>"},{"location":"api/store/azure/#obstore.store.AzureCredential","title":"obstore.store.AzureCredential  <code>module-attribute</code>","text":"<pre><code>AzureCredential: TypeAlias = AzureAccessKey | AzureSASToken | AzureBearerToken\n</code></pre> <p>A type alias for supported azure credentials to be returned from <code>AzureCredentialProvider</code>.</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore.store import AzureCredential\n</code></pre>"},{"location":"api/store/azure/#obstore.store.AzureCredentialProvider","title":"obstore.store.AzureCredentialProvider","text":"<p>               Bases: <code>Protocol</code></p> <p>A type hint for a synchronous or asynchronous callback to provide custom Azure credentials.</p> <p>This should be passed into the <code>credential_provider</code> parameter of <code>AzureStore</code>.</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore.store import AzureCredentialProvider\n</code></pre>"},{"location":"api/store/azure/#obstore.store.AzureCredentialProvider.__call__","title":"__call__","text":"<pre><code>__call__() -&gt; AzureCredential | Coroutine[Any, Any, AzureCredential]\n</code></pre> <p>Return an <code>AzureCredential</code>.</p>"},{"location":"api/store/config/","title":"Configuration","text":""},{"location":"api/store/config/#obstore.store.ClientConfig","title":"obstore.store.ClientConfig","text":"<p>               Bases: <code>TypedDict</code></p> <p>HTTP client configuration.</p> <p>For timeout values (<code>connect_timeout</code>, <code>http2_keep_alive_timeout</code>, <code>pool_idle_timeout</code>, and <code>timeout</code>), values can either be Python <code>timedelta</code> objects, or they can be \"human-readable duration strings\".</p> <p>The human-readable duration string is a concatenation of time spans. Where each time span is an integer number and a suffix. Supported suffixes:</p> <ul> <li><code>nsec</code>, <code>ns</code> -- nanoseconds</li> <li><code>usec</code>, <code>us</code> -- microseconds</li> <li><code>msec</code>, <code>ms</code> -- milliseconds</li> <li><code>seconds</code>, <code>second</code>, <code>sec</code>, <code>s</code></li> <li><code>minutes</code>, <code>minute</code>, <code>min</code>, <code>m</code></li> <li><code>hours</code>, <code>hour</code>, <code>hr</code>, <code>h</code></li> <li><code>days</code>, <code>day</code>, <code>d</code></li> <li><code>weeks</code>, <code>week</code>, <code>w</code></li> <li><code>months</code>, <code>month</code>, <code>M</code> -- defined as 30.44 days</li> <li><code>years</code>, <code>year</code>, <code>y</code> -- defined as 365.25 days</li> </ul> <p>For example:</p> <ul> <li><code>\"2h 37min\"</code></li> <li><code>\"32ms\"</code></li> </ul> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore.store import ClientConfig\n</code></pre>"},{"location":"api/store/config/#obstore.store.ClientConfig.allow_http","title":"allow_http  <code>instance-attribute</code>","text":"<pre><code>allow_http: bool\n</code></pre> <p>Allow non-TLS, i.e. non-HTTPS connections.</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.allow_invalid_certificates","title":"allow_invalid_certificates  <code>instance-attribute</code>","text":"<pre><code>allow_invalid_certificates: bool\n</code></pre> <p>Skip certificate validation on https connections.</p> <p>Warning</p> <p>You should think very carefully before using this method. If invalid certificates are trusted, any certificate for any site will be trusted for use. This includes expired certificates. This introduces significant vulnerabilities, and should only be used as a last resort or for testing</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.connect_timeout","title":"connect_timeout  <code>instance-attribute</code>","text":"<pre><code>connect_timeout: str | timedelta\n</code></pre> <p>Timeout for only the connect phase of a Client</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.default_content_type","title":"default_content_type  <code>instance-attribute</code>","text":"<pre><code>default_content_type: str\n</code></pre> <p>Default <code>CONTENT_TYPE</code> for uploads</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.default_headers","title":"default_headers  <code>instance-attribute</code>","text":"<pre><code>default_headers: dict[str, str] | dict[str, bytes]\n</code></pre> <p>Default headers to be sent with each request</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.http1_only","title":"http1_only  <code>instance-attribute</code>","text":"<pre><code>http1_only: bool\n</code></pre> <p>Only use http1 connections.</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.http2_keep_alive_interval","title":"http2_keep_alive_interval  <code>instance-attribute</code>","text":"<pre><code>http2_keep_alive_interval: str\n</code></pre> <p>Interval for HTTP2 Ping frames should be sent to keep a connection alive.</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.http2_keep_alive_timeout","title":"http2_keep_alive_timeout  <code>instance-attribute</code>","text":"<pre><code>http2_keep_alive_timeout: str | timedelta\n</code></pre> <p>Timeout for receiving an acknowledgement of the keep-alive ping.</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.http2_keep_alive_while_idle","title":"http2_keep_alive_while_idle  <code>instance-attribute</code>","text":"<pre><code>http2_keep_alive_while_idle: str\n</code></pre> <p>Enable HTTP2 keep alive pings for idle connections</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.http2_only","title":"http2_only  <code>instance-attribute</code>","text":"<pre><code>http2_only: bool\n</code></pre> <p>Only use http2 connections</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.pool_idle_timeout","title":"pool_idle_timeout  <code>instance-attribute</code>","text":"<pre><code>pool_idle_timeout: str | timedelta\n</code></pre> <p>The pool max idle timeout.</p> <p>This is the length of time an idle connection will be kept alive.</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.pool_max_idle_per_host","title":"pool_max_idle_per_host  <code>instance-attribute</code>","text":"<pre><code>pool_max_idle_per_host: str\n</code></pre> <p>Maximum number of idle connections per host.</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.proxy_url","title":"proxy_url  <code>instance-attribute</code>","text":"<pre><code>proxy_url: str\n</code></pre> <p>HTTP proxy to use for requests.</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.timeout","title":"timeout  <code>instance-attribute</code>","text":"<pre><code>timeout: str | timedelta\n</code></pre> <p>Request timeout.</p> <p>The timeout is applied from when the request starts connecting until the response body has finished.</p>"},{"location":"api/store/config/#obstore.store.ClientConfig.user_agent","title":"user_agent  <code>instance-attribute</code>","text":"<pre><code>user_agent: str\n</code></pre> <p>User-Agent header to be used by this client.</p>"},{"location":"api/store/config/#obstore.store.BackoffConfig","title":"obstore.store.BackoffConfig","text":"<p>               Bases: <code>TypedDict</code></p> <p>Exponential backoff with jitter.</p> <p>See aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore.store import BackoffConfig\n</code></pre>"},{"location":"api/store/config/#obstore.store.BackoffConfig.base","title":"base  <code>instance-attribute</code>","text":"<pre><code>base: int | float\n</code></pre> <p>The base of the exponential to use.</p> <p>Defaults to <code>2</code>.</p>"},{"location":"api/store/config/#obstore.store.BackoffConfig.init_backoff","title":"init_backoff  <code>instance-attribute</code>","text":"<pre><code>init_backoff: timedelta\n</code></pre> <p>The initial backoff duration.</p> <p>Defaults to 100 milliseconds.</p>"},{"location":"api/store/config/#obstore.store.BackoffConfig.max_backoff","title":"max_backoff  <code>instance-attribute</code>","text":"<pre><code>max_backoff: timedelta\n</code></pre> <p>The maximum backoff duration.</p> <p>Defaults to 15 seconds.</p>"},{"location":"api/store/config/#obstore.store.RetryConfig","title":"obstore.store.RetryConfig","text":"<p>               Bases: <code>TypedDict</code></p> <p>The configuration for how to respond to request errors.</p> <p>The following categories of error will be retried:</p> <ul> <li>5xx server errors</li> <li>Connection errors</li> <li>Dropped connections</li> <li>Timeouts for safe / read-only requests</li> </ul> <p>Requests will be retried up to some limit, using exponential backoff with jitter. See <code>BackoffConfig</code> for more information</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore.store import RetryConfig\n</code></pre>"},{"location":"api/store/config/#obstore.store.RetryConfig.backoff","title":"backoff  <code>instance-attribute</code>","text":"<pre><code>backoff: BackoffConfig\n</code></pre> <p>The backoff configuration.</p> <p>Defaults to the values listed above if not provided.</p>"},{"location":"api/store/config/#obstore.store.RetryConfig.max_retries","title":"max_retries  <code>instance-attribute</code>","text":"<pre><code>max_retries: int\n</code></pre> <p>The maximum number of times to retry a request</p> <p>Set to 0 to disable retries.</p> <p>Defaults to 10.</p>"},{"location":"api/store/config/#obstore.store.RetryConfig.retry_timeout","title":"retry_timeout  <code>instance-attribute</code>","text":"<pre><code>retry_timeout: timedelta\n</code></pre> <p>The maximum length of time from the initial request after which no further retries will be attempted</p> <p>This not only bounds the length of time before a server error will be surfaced to the application, but also bounds the length of time a request's credentials must remain valid.</p> <p>As requests are retried without renewing credentials or regenerating request payloads, this number should be kept below 5 minutes to avoid errors due to expired credentials and/or request payloads.</p> <p>Defaults to 3 minutes.</p>"},{"location":"api/store/gcs/","title":"Google Cloud Storage","text":""},{"location":"api/store/gcs/#obstore.store.GCSStore","title":"obstore.store.GCSStore","text":"<p>Interface to Google Cloud Storage.</p> <p>All constructors will check for environment variables. Refer to <code>GCSConfig</code> for valid environment variables.</p> <p>If no credentials are explicitly provided, they will be sourced from the environment as documented here.</p>"},{"location":"api/store/gcs/#obstore.store.GCSStore.client_options","title":"client_options  <code>property</code>","text":"<pre><code>client_options: ClientConfig | None\n</code></pre> <p>Get the store's client configuration.</p>"},{"location":"api/store/gcs/#obstore.store.GCSStore.config","title":"config  <code>property</code>","text":"<pre><code>config: GCSConfig\n</code></pre> <p>Get the underlying GCS config parameters.</p>"},{"location":"api/store/gcs/#obstore.store.GCSStore.credential_provider","title":"credential_provider  <code>property</code>","text":"<pre><code>credential_provider: GCSCredentialProvider | None\n</code></pre> <p>Get the store's credential provider.</p>"},{"location":"api/store/gcs/#obstore.store.GCSStore.prefix","title":"prefix  <code>property</code>","text":"<pre><code>prefix: str | None\n</code></pre> <p>Get the prefix applied to all operations in this store, if any.</p>"},{"location":"api/store/gcs/#obstore.store.GCSStore.retry_config","title":"retry_config  <code>property</code>","text":"<pre><code>retry_config: RetryConfig | None\n</code></pre> <p>Get the store's retry configuration.</p>"},{"location":"api/store/gcs/#obstore.store.GCSStore.__init__","title":"__init__","text":"<pre><code>__init__(\n    bucket: str | None = None,\n    *,\n    prefix: str | None = None,\n    config: GCSConfig | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    credential_provider: GCSCredentialProvider | None = None,\n    **kwargs: Unpack[GCSConfig],\n) -&gt; None\n</code></pre> <p>Construct a new GCSStore.</p> <p>Parameters:</p> <ul> <li> <code>bucket</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>The GCS bucket to use.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>prefix</code>               (<code>str | None</code>)           \u2013            <p>A prefix within the bucket to use for all operations.</p> </li> <li> <code>config</code>               (<code>GCSConfig | None</code>)           \u2013            <p>GCS Configuration. Values in this config will override values inferred from the environment. Defaults to None.</p> </li> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> <li> <code>credential_provider</code>               (<code>GCSCredentialProvider | None</code>)           \u2013            <p>A callback to provide custom Google credentials.</p> </li> <li> <code>kwargs</code>               (<code>Unpack[GCSConfig]</code>)           \u2013            <p>GCS configuration values. Supports the same values as <code>config</code>, but as named keyword args.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>GCSStore</p> </li> </ul>"},{"location":"api/store/gcs/#obstore.store.GCSStore.copy","title":"copy","text":"<pre><code>copy(from_: str, to: str, *, overwrite: bool = True) -&gt; None\n</code></pre> <p>Copy an object from one path to another in the same object store.</p> <p>Refer to the documentation for copy.</p>"},{"location":"api/store/gcs/#obstore.store.GCSStore.copy_async","title":"copy_async  <code>async</code>","text":"<pre><code>copy_async(from_: str, to: str, *, overwrite: bool = True) -&gt; None\n</code></pre> <p>Call <code>copy</code> asynchronously.</p> <p>Refer to the documentation for copy.</p>"},{"location":"api/store/gcs/#obstore.store.GCSStore.delete","title":"delete","text":"<pre><code>delete(paths: str | Sequence[str]) -&gt; None\n</code></pre> <p>Delete the object at the specified location(s).</p> <p>Refer to the documentation for delete.</p>"},{"location":"api/store/gcs/#obstore.store.GCSStore.delete_async","title":"delete_async  <code>async</code>","text":"<pre><code>delete_async(paths: str | Sequence[str]) -&gt; None\n</code></pre> <p>Call <code>delete</code> asynchronously.</p> <p>Refer to the documentation for delete.</p>"},{"location":"api/store/gcs/#obstore.store.GCSStore.from_url","title":"from_url  <code>classmethod</code>","text":"<pre><code>from_url(\n    url: str,\n    *,\n    prefix: str | None = None,\n    config: GCSConfig | None = None,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n    credential_provider: GCSCredentialProvider | None = None,\n    **kwargs: Unpack[GCSConfig],\n) -&gt; Self\n</code></pre> <p>Construct a new GCSStore with values populated from a well-known storage URL.</p> <p>Any path on the URL will be assigned as the <code>prefix</code> for the store. So if you pass <code>gs://&lt;bucket&gt;/path/to/directory</code>, the store will be created with a prefix of <code>path/to/directory</code>, and all further operations will use paths relative to that prefix.</p> <p>The supported url schemes are:</p> <ul> <li><code>gs://&lt;bucket&gt;/&lt;path&gt;</code></li> </ul> <p>Parameters:</p> <ul> <li> <code>url</code>               (<code>str</code>)           \u2013            <p>well-known storage URL.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>prefix</code>               (<code>str | None</code>)           \u2013            <p>A prefix within the bucket to use for all operations.</p> </li> <li> <code>config</code>               (<code>GCSConfig | None</code>)           \u2013            <p>GCS Configuration. Values in this config will override values inferred from the url. Defaults to None.</p> </li> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> <li> <code>credential_provider</code>               (<code>GCSCredentialProvider | None</code>)           \u2013            <p>A callback to provide custom Google credentials.</p> </li> <li> <code>kwargs</code>               (<code>Unpack[GCSConfig]</code>)           \u2013            <p>GCS configuration values. Supports the same values as <code>config</code>, but as named keyword args.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Self</code>           \u2013            <p>GCSStore</p> </li> </ul>"},{"location":"api/store/gcs/#obstore.store.GCSStore.get","title":"get","text":"<pre><code>get(path: str, *, options: GetOptions | None = None) -&gt; GetResult\n</code></pre> <p>Return the bytes that are stored at the specified location.</p> <p>Refer to the documentation for get.</p>"},{"location":"api/store/gcs/#obstore.store.GCSStore.get_async","title":"get_async  <code>async</code>","text":"<pre><code>get_async(path: str, *, options: GetOptions | None = None) -&gt; GetResult\n</code></pre> <p>Call <code>get</code> asynchronously.</p> <p>Refer to the documentation for get.</p>"},{"location":"api/store/gcs/#obstore.store.GCSStore.get_range","title":"get_range","text":"<pre><code>get_range(\n    path: str, *, start: int, end: int | None = None, length: int | None = None\n) -&gt; Bytes\n</code></pre> <p>Return the bytes stored at the specified location in the given byte range.</p> <p>Refer to the documentation for get_range.</p>"},{"location":"api/store/gcs/#obstore.store.GCSStore.get_range_async","title":"get_range_async  <code>async</code>","text":"<pre><code>get_range_async(\n    path: str, *, start: int, end: int | None = None, length: int | None = None\n) -&gt; Bytes\n</code></pre> <p>Call <code>get_range</code> asynchronously.</p> <p>Refer to the documentation for get_range.</p>"},{"location":"api/store/gcs/#obstore.store.GCSStore.get_ranges","title":"get_ranges","text":"<pre><code>get_ranges(\n    path: str,\n    *,\n    starts: Sequence[int],\n    ends: Sequence[int] | None = None,\n    lengths: Sequence[int] | None = None,\n) -&gt; list[Bytes]\n</code></pre> <p>Return the bytes stored at the specified location in the given byte ranges.</p> <p>Refer to the documentation for get_ranges.</p>"},{"location":"api/store/gcs/#obstore.store.GCSStore.get_ranges_async","title":"get_ranges_async  <code>async</code>","text":"<pre><code>get_ranges_async(\n    path: str,\n    *,\n    starts: Sequence[int],\n    ends: Sequence[int] | None = None,\n    lengths: Sequence[int] | None = None,\n) -&gt; list[Bytes]\n</code></pre> <p>Call <code>get_ranges</code> asynchronously.</p> <p>Refer to the documentation for get_ranges.</p>"},{"location":"api/store/gcs/#obstore.store.GCSStore.head","title":"head","text":"<pre><code>head(path: str) -&gt; ObjectMeta\n</code></pre> <p>Return the metadata for the specified location.</p> <p>Refer to the documentation for head.</p>"},{"location":"api/store/gcs/#obstore.store.GCSStore.head_async","title":"head_async  <code>async</code>","text":"<pre><code>head_async(path: str) -&gt; ObjectMeta\n</code></pre> <p>Call <code>head</code> asynchronously.</p> <p>Refer to the documentation for head_async.</p>"},{"location":"api/store/gcs/#obstore.store.GCSStore.list","title":"list","text":"<pre><code>list(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[True],\n) -&gt; ListStream[RecordBatch]\n</code></pre><pre><code>list(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[False] = False,\n) -&gt; ListStream[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: bool = False,\n) -&gt; ListStream[RecordBatch] | ListStream[Sequence[ObjectMeta]]\n</code></pre> <p>List all the objects with the given prefix.</p> <p>Refer to the documentation for list.</p>"},{"location":"api/store/gcs/#obstore.store.GCSStore.list_async","title":"list_async","text":"<pre><code>list_async(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[True],\n) -&gt; ListStream[RecordBatch]\n</code></pre><pre><code>list_async(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[False] = False,\n) -&gt; ListStream[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list_async(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: bool = False,\n) -&gt; ListStream[RecordBatch] | ListStream[Sequence[ObjectMeta]]\n</code></pre> <p>List all the objects with the given prefix.</p> <p>Refer to the documentation for list.</p> <p>Note</p> <p>This is an alias for <code>list</code>, provided to match the <code>ListAsync</code> protocol in obspec. There is no difference in functionality between this and the <code>list</code> method.</p>"},{"location":"api/store/gcs/#obstore.store.GCSStore.list_with_delimiter","title":"list_with_delimiter","text":"<pre><code>list_with_delimiter(\n    prefix: str | None = None, *, return_arrow: Literal[True]\n) -&gt; ListResult[Table]\n</code></pre><pre><code>list_with_delimiter(\n    prefix: str | None = None, *, return_arrow: Literal[False] = False\n) -&gt; ListResult[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list_with_delimiter(\n    prefix: str | None = None, *, return_arrow: bool = False\n) -&gt; ListResult[Table] | ListResult[Sequence[ObjectMeta]]\n</code></pre> <p>List objects with the given prefix and an implementation specific delimiter.</p> <p>Refer to the documentation for list_with_delimiter.</p>"},{"location":"api/store/gcs/#obstore.store.GCSStore.list_with_delimiter_async","title":"list_with_delimiter_async  <code>async</code>","text":"<pre><code>list_with_delimiter_async(\n    prefix: str | None = None, *, return_arrow: Literal[True]\n) -&gt; ListResult[Table]\n</code></pre><pre><code>list_with_delimiter_async(\n    prefix: str | None = None, *, return_arrow: Literal[False] = False\n) -&gt; ListResult[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list_with_delimiter_async(\n    prefix: str | None = None, *, return_arrow: bool = False\n) -&gt; ListResult[Table] | ListResult[Sequence[ObjectMeta]]\n</code></pre> <p>Call <code>list_with_delimiter</code> asynchronously.</p> <p>Refer to the documentation for list_with_delimiter.</p>"},{"location":"api/store/gcs/#obstore.store.GCSStore.put","title":"put","text":"<pre><code>put(\n    path: str,\n    file: IO[bytes]\n    | Path\n    | bytes\n    | Buffer\n    | Iterator[Buffer]\n    | Iterable[Buffer],\n    *,\n    attributes: Attributes | None = None,\n    tags: dict[str, str] | None = None,\n    mode: PutMode | None = None,\n    use_multipart: bool | None = None,\n    chunk_size: int = 5 * 1024 * 1024,\n    max_concurrency: int = 12,\n) -&gt; PutResult\n</code></pre> <p>Save the provided bytes to the specified location.</p> <p>Refer to the documentation for put.</p>"},{"location":"api/store/gcs/#obstore.store.GCSStore.put_async","title":"put_async  <code>async</code>","text":"<pre><code>put_async(\n    path: str,\n    file: IO[bytes]\n    | Path\n    | bytes\n    | Buffer\n    | AsyncIterator[Buffer]\n    | AsyncIterable[Buffer]\n    | Iterator[Buffer]\n    | Iterable[Buffer],\n    *,\n    attributes: Attributes | None = None,\n    tags: dict[str, str] | None = None,\n    mode: PutMode | None = None,\n    use_multipart: bool | None = None,\n    chunk_size: int = 5 * 1024 * 1024,\n    max_concurrency: int = 12,\n) -&gt; PutResult\n</code></pre> <p>Call <code>put</code> asynchronously.</p> <p>Refer to the documentation for <code>put</code>. In addition to what the synchronous <code>put</code> allows for the <code>file</code> parameter, this also supports an async iterator or iterable of objects implementing the Python buffer protocol.</p> <p>This means, for example, you can pass the result of <code>get_async</code> directly to <code>put_async</code>, and the request will be streamed through Python during the put operation:</p> <pre><code>import obstore as obs\n\n# This only constructs the stream, it doesn't materialize the data in memory\nresp = await obs.get_async(store1, path1)\n# A streaming upload is created to copy the file to path2\nawait obs.put_async(store2, path2)\n</code></pre>"},{"location":"api/store/gcs/#obstore.store.GCSStore.rename","title":"rename","text":"<pre><code>rename(from_: str, to: str, *, overwrite: bool = True) -&gt; None\n</code></pre> <p>Move an object from one path to another in the same object store.</p> <p>Refer to the documentation for rename.</p>"},{"location":"api/store/gcs/#obstore.store.GCSStore.rename_async","title":"rename_async  <code>async</code>","text":"<pre><code>rename_async(from_: str, to: str, *, overwrite: bool = True) -&gt; None\n</code></pre> <p>Call <code>rename</code> asynchronously.</p> <p>Refer to the documentation for rename.</p>"},{"location":"api/store/gcs/#obstore.store.GCSConfig","title":"obstore.store.GCSConfig","text":"<p>               Bases: <code>TypedDict</code></p> <p>Configuration parameters for GCSStore.</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore.store import GCSConfig\n</code></pre>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.application_credentials","title":"application_credentials  <code>instance-attribute</code>","text":"<pre><code>application_credentials: str\n</code></pre> <p>Application credentials path.</p> <p>See cloud.google.com/docs/authentication/provide-credentials-adc.</p> <p>Environment variable: <code>GOOGLE_APPLICATION_CREDENTIALS</code>.</p>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.bucket","title":"bucket  <code>instance-attribute</code>","text":"<pre><code>bucket: str\n</code></pre> <p>Bucket name. (required)</p> <p>Environment variables:</p> <ul> <li><code>GOOGLE_BUCKET</code></li> <li><code>GOOGLE_BUCKET_NAME</code></li> </ul>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.service_account","title":"service_account  <code>instance-attribute</code>","text":"<pre><code>service_account: str\n</code></pre> <p>Path to the service account file.</p> <p>This or <code>service_account_key</code> must be set.</p> <p>Example value <code>\"/tmp/gcs.json\"</code>. Example contents of <code>gcs.json</code>:</p> <pre><code>{\n   \"gcs_base_url\": \"https://localhost:4443\",\n   \"disable_oauth\": true,\n   \"client_email\": \"\",\n   \"private_key\": \"\"\n}\n</code></pre> <p>Environment variables:</p> <ul> <li><code>GOOGLE_SERVICE_ACCOUNT</code></li> <li><code>GOOGLE_SERVICE_ACCOUNT_PATH</code></li> </ul>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.service_account_key","title":"service_account_key  <code>instance-attribute</code>","text":"<pre><code>service_account_key: str\n</code></pre> <p>The serialized service account key.</p> <p>The service account must be in the JSON format. This or <code>with_service_account_path</code> must be set.</p> <p>Environment variable: <code>GOOGLE_SERVICE_ACCOUNT_KEY</code>.</p>"},{"location":"api/store/gcs/#obstore.store.GCSConfig.skip_signature","title":"skip_signature  <code>instance-attribute</code>","text":"<pre><code>skip_signature: bool\n</code></pre> <p>If <code>True</code>, GCSStore will not fetch credentials and will not sign requests.</p> <p>This can be useful when interacting with public GCS buckets that deny authorized requests.</p> <p>Environment variable: <code>GOOGLE_SKIP_SIGNATURE</code>.</p>"},{"location":"api/store/gcs/#obstore.store.GCSCredential","title":"obstore.store.GCSCredential","text":"<p>               Bases: <code>TypedDict</code></p> <p>A Google Cloud Storage Credential.</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore.store import GCSCredential\n</code></pre>"},{"location":"api/store/gcs/#obstore.store.GCSCredential.expires_at","title":"expires_at  <code>instance-attribute</code>","text":"<pre><code>expires_at: datetime | None\n</code></pre> <p>Expiry datetime of credential. The datetime should have time zone set.</p> <p>If None, the credential will never expire.</p>"},{"location":"api/store/gcs/#obstore.store.GCSCredential.token","title":"token  <code>instance-attribute</code>","text":"<pre><code>token: str\n</code></pre> <p>An HTTP bearer token.</p>"},{"location":"api/store/gcs/#obstore.store.GCSCredentialProvider","title":"obstore.store.GCSCredentialProvider","text":"<p>               Bases: <code>Protocol</code></p> <p>A type hint for a synchronous or asynchronous callback to provide custom Google Cloud Storage credentials.</p> <p>This should be passed into the <code>credential_provider</code> parameter of <code>GCSStore</code>.</p> <p>Not importable at runtime</p> <p>To use this type hint in your code, import it within a <code>TYPE_CHECKING</code> block:</p> <pre><code>from __future__ import annotations\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from obstore.store import GCSCredentialProvider\n</code></pre>"},{"location":"api/store/gcs/#obstore.store.GCSCredentialProvider.__call__","title":"__call__","text":"<pre><code>__call__() -&gt; GCSCredential | Coroutine[Any, Any, GCSCredential]\n</code></pre> <p>Return a <code>GCSCredential</code>.</p>"},{"location":"api/store/http/","title":"HTTP","text":""},{"location":"api/store/http/#obstore.store.HTTPStore","title":"obstore.store.HTTPStore","text":"<p>Configure a connection to a generic HTTP server.</p> <p>Example</p> <p>Accessing the number of stars for a repo:</p> <pre><code>import json\n\nimport obstore as obs\nfrom obstore.store import HTTPStore\n\nstore = HTTPStore.from_url(\"https://api.github.com\")\nresp = obs.get(store, \"repos/developmentseed/obstore\")\n\n# If you have orjson installed, you can load bytes without copying them via\n# `memoryview`:\nimport orjson\ndata = orjson.loads(memoryview(resp.bytes()))\n\n# Otherwise, you'll need to copy with `bytes`, e.g. `json(bytes(resp.bytes()))`\n\nprint(data[\"stargazers_count\"])\n</code></pre>"},{"location":"api/store/http/#obstore.store.HTTPStore.client_options","title":"client_options  <code>property</code>","text":"<pre><code>client_options: ClientConfig | None\n</code></pre> <p>Get the store's client configuration.</p>"},{"location":"api/store/http/#obstore.store.HTTPStore.retry_config","title":"retry_config  <code>property</code>","text":"<pre><code>retry_config: RetryConfig | None\n</code></pre> <p>Get the store's retry configuration.</p>"},{"location":"api/store/http/#obstore.store.HTTPStore.url","title":"url  <code>property</code>","text":"<pre><code>url: str\n</code></pre> <p>Get the base url of this store.</p>"},{"location":"api/store/http/#obstore.store.HTTPStore.__init__","title":"__init__","text":"<pre><code>__init__(\n    url: str,\n    *,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n) -&gt; None\n</code></pre> <p>Construct a new HTTPStore from a URL.</p> <p>Any path on the URL will be assigned as the <code>prefix</code> for the store. So if you pass <code>https://example.com/path/to/directory</code>, the store will be created with a prefix of <code>path/to/directory</code>, and all further operations will use paths relative to that prefix.</p> <p>Parameters:</p> <ul> <li> <code>url</code>               (<code>str</code>)           \u2013            <p>The base URL to use for the store.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>client_options</code>               (<code>ClientConfig | None</code>)           \u2013            <p>HTTP Client options. Defaults to None.</p> </li> <li> <code>retry_config</code>               (<code>RetryConfig | None</code>)           \u2013            <p>Retry configuration. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>HTTPStore</p> </li> </ul>"},{"location":"api/store/http/#obstore.store.HTTPStore.copy","title":"copy","text":"<pre><code>copy(from_: str, to: str, *, overwrite: bool = True) -&gt; None\n</code></pre> <p>Copy an object from one path to another in the same object store.</p> <p>Refer to the documentation for copy.</p>"},{"location":"api/store/http/#obstore.store.HTTPStore.copy_async","title":"copy_async  <code>async</code>","text":"<pre><code>copy_async(from_: str, to: str, *, overwrite: bool = True) -&gt; None\n</code></pre> <p>Call <code>copy</code> asynchronously.</p> <p>Refer to the documentation for copy.</p>"},{"location":"api/store/http/#obstore.store.HTTPStore.delete","title":"delete","text":"<pre><code>delete(paths: str | Sequence[str]) -&gt; None\n</code></pre> <p>Delete the object at the specified location(s).</p> <p>Refer to the documentation for delete.</p>"},{"location":"api/store/http/#obstore.store.HTTPStore.delete_async","title":"delete_async  <code>async</code>","text":"<pre><code>delete_async(paths: str | Sequence[str]) -&gt; None\n</code></pre> <p>Call <code>delete</code> asynchronously.</p> <p>Refer to the documentation for delete.</p>"},{"location":"api/store/http/#obstore.store.HTTPStore.from_url","title":"from_url  <code>classmethod</code>","text":"<pre><code>from_url(\n    url: str,\n    *,\n    client_options: ClientConfig | None = None,\n    retry_config: RetryConfig | None = None,\n) -&gt; Self\n</code></pre> <p>Construct a new HTTPStore from a URL.</p> <p>This is an alias of <code>HTTPStore.__init__</code>.</p>"},{"location":"api/store/http/#obstore.store.HTTPStore.get","title":"get","text":"<pre><code>get(path: str, *, options: GetOptions | None = None) -&gt; GetResult\n</code></pre> <p>Return the bytes that are stored at the specified location.</p> <p>Refer to the documentation for get.</p>"},{"location":"api/store/http/#obstore.store.HTTPStore.get_async","title":"get_async  <code>async</code>","text":"<pre><code>get_async(path: str, *, options: GetOptions | None = None) -&gt; GetResult\n</code></pre> <p>Call <code>get</code> asynchronously.</p> <p>Refer to the documentation for get.</p>"},{"location":"api/store/http/#obstore.store.HTTPStore.get_range","title":"get_range","text":"<pre><code>get_range(\n    path: str, *, start: int, end: int | None = None, length: int | None = None\n) -&gt; Bytes\n</code></pre> <p>Return the bytes stored at the specified location in the given byte range.</p> <p>Refer to the documentation for get_range.</p>"},{"location":"api/store/http/#obstore.store.HTTPStore.get_range_async","title":"get_range_async  <code>async</code>","text":"<pre><code>get_range_async(\n    path: str, *, start: int, end: int | None = None, length: int | None = None\n) -&gt; Bytes\n</code></pre> <p>Call <code>get_range</code> asynchronously.</p> <p>Refer to the documentation for get_range.</p>"},{"location":"api/store/http/#obstore.store.HTTPStore.get_ranges","title":"get_ranges","text":"<pre><code>get_ranges(\n    path: str,\n    *,\n    starts: Sequence[int],\n    ends: Sequence[int] | None = None,\n    lengths: Sequence[int] | None = None,\n) -&gt; list[Bytes]\n</code></pre> <p>Return the bytes stored at the specified location in the given byte ranges.</p> <p>Refer to the documentation for get_ranges.</p>"},{"location":"api/store/http/#obstore.store.HTTPStore.get_ranges_async","title":"get_ranges_async  <code>async</code>","text":"<pre><code>get_ranges_async(\n    path: str,\n    *,\n    starts: Sequence[int],\n    ends: Sequence[int] | None = None,\n    lengths: Sequence[int] | None = None,\n) -&gt; list[Bytes]\n</code></pre> <p>Call <code>get_ranges</code> asynchronously.</p> <p>Refer to the documentation for get_ranges.</p>"},{"location":"api/store/http/#obstore.store.HTTPStore.head","title":"head","text":"<pre><code>head(path: str) -&gt; ObjectMeta\n</code></pre> <p>Return the metadata for the specified location.</p> <p>Refer to the documentation for head.</p>"},{"location":"api/store/http/#obstore.store.HTTPStore.head_async","title":"head_async  <code>async</code>","text":"<pre><code>head_async(path: str) -&gt; ObjectMeta\n</code></pre> <p>Call <code>head</code> asynchronously.</p> <p>Refer to the documentation for head_async.</p>"},{"location":"api/store/http/#obstore.store.HTTPStore.list","title":"list","text":"<pre><code>list(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[True],\n) -&gt; ListStream[RecordBatch]\n</code></pre><pre><code>list(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[False] = False,\n) -&gt; ListStream[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: bool = False,\n) -&gt; ListStream[RecordBatch] | ListStream[Sequence[ObjectMeta]]\n</code></pre> <p>List all the objects with the given prefix.</p> <p>Refer to the documentation for list.</p>"},{"location":"api/store/http/#obstore.store.HTTPStore.list_async","title":"list_async","text":"<pre><code>list_async(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[True],\n) -&gt; ListStream[RecordBatch]\n</code></pre><pre><code>list_async(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[False] = False,\n) -&gt; ListStream[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list_async(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: bool = False,\n) -&gt; ListStream[RecordBatch] | ListStream[Sequence[ObjectMeta]]\n</code></pre> <p>List all the objects with the given prefix.</p> <p>Refer to the documentation for list.</p> <p>Note</p> <p>This is an alias for <code>list</code>, provided to match the <code>ListAsync</code> protocol in obspec. There is no difference in functionality between this and the <code>list</code> method.</p>"},{"location":"api/store/http/#obstore.store.HTTPStore.list_with_delimiter","title":"list_with_delimiter","text":"<pre><code>list_with_delimiter(\n    prefix: str | None = None, *, return_arrow: Literal[True]\n) -&gt; ListResult[Table]\n</code></pre><pre><code>list_with_delimiter(\n    prefix: str | None = None, *, return_arrow: Literal[False] = False\n) -&gt; ListResult[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list_with_delimiter(\n    prefix: str | None = None, *, return_arrow: bool = False\n) -&gt; ListResult[Table] | ListResult[Sequence[ObjectMeta]]\n</code></pre> <p>List objects with the given prefix and an implementation specific delimiter.</p> <p>Refer to the documentation for list_with_delimiter.</p>"},{"location":"api/store/http/#obstore.store.HTTPStore.list_with_delimiter_async","title":"list_with_delimiter_async  <code>async</code>","text":"<pre><code>list_with_delimiter_async(\n    prefix: str | None = None, *, return_arrow: Literal[True]\n) -&gt; ListResult[Table]\n</code></pre><pre><code>list_with_delimiter_async(\n    prefix: str | None = None, *, return_arrow: Literal[False] = False\n) -&gt; ListResult[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list_with_delimiter_async(\n    prefix: str | None = None, *, return_arrow: bool = False\n) -&gt; ListResult[Table] | ListResult[Sequence[ObjectMeta]]\n</code></pre> <p>Call <code>list_with_delimiter</code> asynchronously.</p> <p>Refer to the documentation for list_with_delimiter.</p>"},{"location":"api/store/http/#obstore.store.HTTPStore.put","title":"put","text":"<pre><code>put(\n    path: str,\n    file: IO[bytes]\n    | Path\n    | bytes\n    | Buffer\n    | Iterator[Buffer]\n    | Iterable[Buffer],\n    *,\n    attributes: Attributes | None = None,\n    tags: dict[str, str] | None = None,\n    mode: PutMode | None = None,\n    use_multipart: bool | None = None,\n    chunk_size: int = 5 * 1024 * 1024,\n    max_concurrency: int = 12,\n) -&gt; PutResult\n</code></pre> <p>Save the provided bytes to the specified location.</p> <p>Refer to the documentation for put.</p>"},{"location":"api/store/http/#obstore.store.HTTPStore.put_async","title":"put_async  <code>async</code>","text":"<pre><code>put_async(\n    path: str,\n    file: IO[bytes]\n    | Path\n    | bytes\n    | Buffer\n    | AsyncIterator[Buffer]\n    | AsyncIterable[Buffer]\n    | Iterator[Buffer]\n    | Iterable[Buffer],\n    *,\n    attributes: Attributes | None = None,\n    tags: dict[str, str] | None = None,\n    mode: PutMode | None = None,\n    use_multipart: bool | None = None,\n    chunk_size: int = 5 * 1024 * 1024,\n    max_concurrency: int = 12,\n) -&gt; PutResult\n</code></pre> <p>Call <code>put</code> asynchronously.</p> <p>Refer to the documentation for <code>put</code>. In addition to what the synchronous <code>put</code> allows for the <code>file</code> parameter, this also supports an async iterator or iterable of objects implementing the Python buffer protocol.</p> <p>This means, for example, you can pass the result of <code>get_async</code> directly to <code>put_async</code>, and the request will be streamed through Python during the put operation:</p> <pre><code>import obstore as obs\n\n# This only constructs the stream, it doesn't materialize the data in memory\nresp = await obs.get_async(store1, path1)\n# A streaming upload is created to copy the file to path2\nawait obs.put_async(store2, path2)\n</code></pre>"},{"location":"api/store/http/#obstore.store.HTTPStore.rename","title":"rename","text":"<pre><code>rename(from_: str, to: str, *, overwrite: bool = True) -&gt; None\n</code></pre> <p>Move an object from one path to another in the same object store.</p> <p>Refer to the documentation for rename.</p>"},{"location":"api/store/http/#obstore.store.HTTPStore.rename_async","title":"rename_async  <code>async</code>","text":"<pre><code>rename_async(from_: str, to: str, *, overwrite: bool = True) -&gt; None\n</code></pre> <p>Call <code>rename</code> asynchronously.</p> <p>Refer to the documentation for rename.</p>"},{"location":"api/store/local/","title":"Local","text":""},{"location":"api/store/local/#obstore.store.LocalStore","title":"obstore.store.LocalStore","text":"<p>An ObjectStore interface to local filesystem storage.</p> <p>Can optionally be created with a directory prefix.</p> <pre><code>from pathlib import Path\n\nstore = LocalStore()\nstore = LocalStore(prefix=\"/path/to/directory\")\nstore = LocalStore(prefix=Path(\".\"))\n</code></pre>"},{"location":"api/store/local/#obstore.store.LocalStore.prefix","title":"prefix  <code>property</code>","text":"<pre><code>prefix: Path | None\n</code></pre> <p>Get the prefix applied to all operations in this store, if any.</p>"},{"location":"api/store/local/#obstore.store.LocalStore.__init__","title":"__init__","text":"<pre><code>__init__(\n    prefix: str | Path | None = None,\n    *,\n    automatic_cleanup: bool = False,\n    mkdir: bool = False,\n) -&gt; None\n</code></pre> <p>Create a new LocalStore.</p> <p>Parameters:</p> <ul> <li> <code>prefix</code>               (<code>str | Path | None</code>, default:                   <code>None</code> )           \u2013            <p>Use the specified prefix applied to all paths. Defaults to <code>None</code>.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>automatic_cleanup</code>               (<code>bool</code>)           \u2013            <p>if <code>True</code>, enables automatic cleanup of empty directories when deleting files. Defaults to False.</p> </li> <li> <code>mkdir</code>               (<code>bool</code>)           \u2013            <p>if <code>True</code> and <code>prefix</code> is not <code>None</code>, the directory at <code>prefix</code> will attempt to be created. Note that this root directory will not be cleaned up, even if <code>automatic_cleanup</code> is <code>True</code>.</p> </li> </ul>"},{"location":"api/store/local/#obstore.store.LocalStore.copy","title":"copy","text":"<pre><code>copy(from_: str, to: str, *, overwrite: bool = True) -&gt; None\n</code></pre> <p>Copy an object from one path to another in the same object store.</p> <p>Refer to the documentation for copy.</p>"},{"location":"api/store/local/#obstore.store.LocalStore.copy_async","title":"copy_async  <code>async</code>","text":"<pre><code>copy_async(from_: str, to: str, *, overwrite: bool = True) -&gt; None\n</code></pre> <p>Call <code>copy</code> asynchronously.</p> <p>Refer to the documentation for copy.</p>"},{"location":"api/store/local/#obstore.store.LocalStore.delete","title":"delete","text":"<pre><code>delete(paths: str | Sequence[str]) -&gt; None\n</code></pre> <p>Delete the object at the specified location(s).</p> <p>Refer to the documentation for delete.</p>"},{"location":"api/store/local/#obstore.store.LocalStore.delete_async","title":"delete_async  <code>async</code>","text":"<pre><code>delete_async(paths: str | Sequence[str]) -&gt; None\n</code></pre> <p>Call <code>delete</code> asynchronously.</p> <p>Refer to the documentation for delete.</p>"},{"location":"api/store/local/#obstore.store.LocalStore.from_url","title":"from_url  <code>classmethod</code>","text":"<pre><code>from_url(\n    url: str, *, automatic_cleanup: bool = False, mkdir: bool = False\n) -&gt; Self\n</code></pre> <p>Construct a new LocalStore from a <code>file://</code> URL.</p> <p>Examples:</p> <p>Construct a new store pointing to the root of your filesystem: <pre><code>url = \"file:///\"\nstore = LocalStore.from_url(url)\n</code></pre></p> <p>Construct a new store with a directory prefix: <pre><code>url = \"file:///Users/kyle/\"\nstore = LocalStore.from_url(url)\n</code></pre></p>"},{"location":"api/store/local/#obstore.store.LocalStore.get","title":"get","text":"<pre><code>get(path: str, *, options: GetOptions | None = None) -&gt; GetResult\n</code></pre> <p>Return the bytes that are stored at the specified location.</p> <p>Refer to the documentation for get.</p>"},{"location":"api/store/local/#obstore.store.LocalStore.get_async","title":"get_async  <code>async</code>","text":"<pre><code>get_async(path: str, *, options: GetOptions | None = None) -&gt; GetResult\n</code></pre> <p>Call <code>get</code> asynchronously.</p> <p>Refer to the documentation for get.</p>"},{"location":"api/store/local/#obstore.store.LocalStore.get_range","title":"get_range","text":"<pre><code>get_range(\n    path: str, *, start: int, end: int | None = None, length: int | None = None\n) -&gt; Bytes\n</code></pre> <p>Return the bytes stored at the specified location in the given byte range.</p> <p>Refer to the documentation for get_range.</p>"},{"location":"api/store/local/#obstore.store.LocalStore.get_range_async","title":"get_range_async  <code>async</code>","text":"<pre><code>get_range_async(\n    path: str, *, start: int, end: int | None = None, length: int | None = None\n) -&gt; Bytes\n</code></pre> <p>Call <code>get_range</code> asynchronously.</p> <p>Refer to the documentation for get_range.</p>"},{"location":"api/store/local/#obstore.store.LocalStore.get_ranges","title":"get_ranges","text":"<pre><code>get_ranges(\n    path: str,\n    *,\n    starts: Sequence[int],\n    ends: Sequence[int] | None = None,\n    lengths: Sequence[int] | None = None,\n) -&gt; list[Bytes]\n</code></pre> <p>Return the bytes stored at the specified location in the given byte ranges.</p> <p>Refer to the documentation for get_ranges.</p>"},{"location":"api/store/local/#obstore.store.LocalStore.get_ranges_async","title":"get_ranges_async  <code>async</code>","text":"<pre><code>get_ranges_async(\n    path: str,\n    *,\n    starts: Sequence[int],\n    ends: Sequence[int] | None = None,\n    lengths: Sequence[int] | None = None,\n) -&gt; list[Bytes]\n</code></pre> <p>Call <code>get_ranges</code> asynchronously.</p> <p>Refer to the documentation for get_ranges.</p>"},{"location":"api/store/local/#obstore.store.LocalStore.head","title":"head","text":"<pre><code>head(path: str) -&gt; ObjectMeta\n</code></pre> <p>Return the metadata for the specified location.</p> <p>Refer to the documentation for head.</p>"},{"location":"api/store/local/#obstore.store.LocalStore.head_async","title":"head_async  <code>async</code>","text":"<pre><code>head_async(path: str) -&gt; ObjectMeta\n</code></pre> <p>Call <code>head</code> asynchronously.</p> <p>Refer to the documentation for head_async.</p>"},{"location":"api/store/local/#obstore.store.LocalStore.list","title":"list","text":"<pre><code>list(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[True],\n) -&gt; ListStream[RecordBatch]\n</code></pre><pre><code>list(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[False] = False,\n) -&gt; ListStream[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: bool = False,\n) -&gt; ListStream[RecordBatch] | ListStream[Sequence[ObjectMeta]]\n</code></pre> <p>List all the objects with the given prefix.</p> <p>Refer to the documentation for list.</p>"},{"location":"api/store/local/#obstore.store.LocalStore.list_async","title":"list_async","text":"<pre><code>list_async(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[True],\n) -&gt; ListStream[RecordBatch]\n</code></pre><pre><code>list_async(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[False] = False,\n) -&gt; ListStream[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list_async(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: bool = False,\n) -&gt; ListStream[RecordBatch] | ListStream[Sequence[ObjectMeta]]\n</code></pre> <p>List all the objects with the given prefix.</p> <p>Refer to the documentation for list.</p> <p>Note</p> <p>This is an alias for <code>list</code>, provided to match the <code>ListAsync</code> protocol in obspec. There is no difference in functionality between this and the <code>list</code> method.</p>"},{"location":"api/store/local/#obstore.store.LocalStore.list_with_delimiter","title":"list_with_delimiter","text":"<pre><code>list_with_delimiter(\n    prefix: str | None = None, *, return_arrow: Literal[True]\n) -&gt; ListResult[Table]\n</code></pre><pre><code>list_with_delimiter(\n    prefix: str | None = None, *, return_arrow: Literal[False] = False\n) -&gt; ListResult[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list_with_delimiter(\n    prefix: str | None = None, *, return_arrow: bool = False\n) -&gt; ListResult[Table] | ListResult[Sequence[ObjectMeta]]\n</code></pre> <p>List objects with the given prefix and an implementation specific delimiter.</p> <p>Refer to the documentation for list_with_delimiter.</p>"},{"location":"api/store/local/#obstore.store.LocalStore.list_with_delimiter_async","title":"list_with_delimiter_async  <code>async</code>","text":"<pre><code>list_with_delimiter_async(\n    prefix: str | None = None, *, return_arrow: Literal[True]\n) -&gt; ListResult[Table]\n</code></pre><pre><code>list_with_delimiter_async(\n    prefix: str | None = None, *, return_arrow: Literal[False] = False\n) -&gt; ListResult[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list_with_delimiter_async(\n    prefix: str | None = None, *, return_arrow: bool = False\n) -&gt; ListResult[Table] | ListResult[Sequence[ObjectMeta]]\n</code></pre> <p>Call <code>list_with_delimiter</code> asynchronously.</p> <p>Refer to the documentation for list_with_delimiter.</p>"},{"location":"api/store/local/#obstore.store.LocalStore.put","title":"put","text":"<pre><code>put(\n    path: str,\n    file: IO[bytes]\n    | Path\n    | bytes\n    | Buffer\n    | Iterator[Buffer]\n    | Iterable[Buffer],\n    *,\n    attributes: Attributes | None = None,\n    tags: dict[str, str] | None = None,\n    mode: PutMode | None = None,\n    use_multipart: bool | None = None,\n    chunk_size: int = 5 * 1024 * 1024,\n    max_concurrency: int = 12,\n) -&gt; PutResult\n</code></pre> <p>Save the provided bytes to the specified location.</p> <p>Refer to the documentation for put.</p>"},{"location":"api/store/local/#obstore.store.LocalStore.put_async","title":"put_async  <code>async</code>","text":"<pre><code>put_async(\n    path: str,\n    file: IO[bytes]\n    | Path\n    | bytes\n    | Buffer\n    | AsyncIterator[Buffer]\n    | AsyncIterable[Buffer]\n    | Iterator[Buffer]\n    | Iterable[Buffer],\n    *,\n    attributes: Attributes | None = None,\n    tags: dict[str, str] | None = None,\n    mode: PutMode | None = None,\n    use_multipart: bool | None = None,\n    chunk_size: int = 5 * 1024 * 1024,\n    max_concurrency: int = 12,\n) -&gt; PutResult\n</code></pre> <p>Call <code>put</code> asynchronously.</p> <p>Refer to the documentation for <code>put</code>. In addition to what the synchronous <code>put</code> allows for the <code>file</code> parameter, this also supports an async iterator or iterable of objects implementing the Python buffer protocol.</p> <p>This means, for example, you can pass the result of <code>get_async</code> directly to <code>put_async</code>, and the request will be streamed through Python during the put operation:</p> <pre><code>import obstore as obs\n\n# This only constructs the stream, it doesn't materialize the data in memory\nresp = await obs.get_async(store1, path1)\n# A streaming upload is created to copy the file to path2\nawait obs.put_async(store2, path2)\n</code></pre>"},{"location":"api/store/local/#obstore.store.LocalStore.rename","title":"rename","text":"<pre><code>rename(from_: str, to: str, *, overwrite: bool = True) -&gt; None\n</code></pre> <p>Move an object from one path to another in the same object store.</p> <p>Refer to the documentation for rename.</p>"},{"location":"api/store/local/#obstore.store.LocalStore.rename_async","title":"rename_async  <code>async</code>","text":"<pre><code>rename_async(from_: str, to: str, *, overwrite: bool = True) -&gt; None\n</code></pre> <p>Call <code>rename</code> asynchronously.</p> <p>Refer to the documentation for rename.</p>"},{"location":"api/store/memory/","title":"Memory","text":""},{"location":"api/store/memory/#obstore.store.MemoryStore","title":"obstore.store.MemoryStore","text":"<p>A fully in-memory implementation of ObjectStore.</p> <p>Create a new in-memory store: <pre><code>store = MemoryStore()\n</code></pre></p>"},{"location":"api/store/memory/#obstore.store.MemoryStore.copy","title":"copy","text":"<pre><code>copy(from_: str, to: str, *, overwrite: bool = True) -&gt; None\n</code></pre> <p>Copy an object from one path to another in the same object store.</p> <p>Refer to the documentation for copy.</p>"},{"location":"api/store/memory/#obstore.store.MemoryStore.copy_async","title":"copy_async  <code>async</code>","text":"<pre><code>copy_async(from_: str, to: str, *, overwrite: bool = True) -&gt; None\n</code></pre> <p>Call <code>copy</code> asynchronously.</p> <p>Refer to the documentation for copy.</p>"},{"location":"api/store/memory/#obstore.store.MemoryStore.delete","title":"delete","text":"<pre><code>delete(paths: str | Sequence[str]) -&gt; None\n</code></pre> <p>Delete the object at the specified location(s).</p> <p>Refer to the documentation for delete.</p>"},{"location":"api/store/memory/#obstore.store.MemoryStore.delete_async","title":"delete_async  <code>async</code>","text":"<pre><code>delete_async(paths: str | Sequence[str]) -&gt; None\n</code></pre> <p>Call <code>delete</code> asynchronously.</p> <p>Refer to the documentation for delete.</p>"},{"location":"api/store/memory/#obstore.store.MemoryStore.get","title":"get","text":"<pre><code>get(path: str, *, options: GetOptions | None = None) -&gt; GetResult\n</code></pre> <p>Return the bytes that are stored at the specified location.</p> <p>Refer to the documentation for get.</p>"},{"location":"api/store/memory/#obstore.store.MemoryStore.get_async","title":"get_async  <code>async</code>","text":"<pre><code>get_async(path: str, *, options: GetOptions | None = None) -&gt; GetResult\n</code></pre> <p>Call <code>get</code> asynchronously.</p> <p>Refer to the documentation for get.</p>"},{"location":"api/store/memory/#obstore.store.MemoryStore.get_range","title":"get_range","text":"<pre><code>get_range(\n    path: str, *, start: int, end: int | None = None, length: int | None = None\n) -&gt; Bytes\n</code></pre> <p>Return the bytes stored at the specified location in the given byte range.</p> <p>Refer to the documentation for get_range.</p>"},{"location":"api/store/memory/#obstore.store.MemoryStore.get_range_async","title":"get_range_async  <code>async</code>","text":"<pre><code>get_range_async(\n    path: str, *, start: int, end: int | None = None, length: int | None = None\n) -&gt; Bytes\n</code></pre> <p>Call <code>get_range</code> asynchronously.</p> <p>Refer to the documentation for get_range.</p>"},{"location":"api/store/memory/#obstore.store.MemoryStore.get_ranges","title":"get_ranges","text":"<pre><code>get_ranges(\n    path: str,\n    *,\n    starts: Sequence[int],\n    ends: Sequence[int] | None = None,\n    lengths: Sequence[int] | None = None,\n) -&gt; list[Bytes]\n</code></pre> <p>Return the bytes stored at the specified location in the given byte ranges.</p> <p>Refer to the documentation for get_ranges.</p>"},{"location":"api/store/memory/#obstore.store.MemoryStore.get_ranges_async","title":"get_ranges_async  <code>async</code>","text":"<pre><code>get_ranges_async(\n    path: str,\n    *,\n    starts: Sequence[int],\n    ends: Sequence[int] | None = None,\n    lengths: Sequence[int] | None = None,\n) -&gt; list[Bytes]\n</code></pre> <p>Call <code>get_ranges</code> asynchronously.</p> <p>Refer to the documentation for get_ranges.</p>"},{"location":"api/store/memory/#obstore.store.MemoryStore.head","title":"head","text":"<pre><code>head(path: str) -&gt; ObjectMeta\n</code></pre> <p>Return the metadata for the specified location.</p> <p>Refer to the documentation for head.</p>"},{"location":"api/store/memory/#obstore.store.MemoryStore.head_async","title":"head_async  <code>async</code>","text":"<pre><code>head_async(path: str) -&gt; ObjectMeta\n</code></pre> <p>Call <code>head</code> asynchronously.</p> <p>Refer to the documentation for head_async.</p>"},{"location":"api/store/memory/#obstore.store.MemoryStore.list","title":"list","text":"<pre><code>list(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[True],\n) -&gt; ListStream[RecordBatch]\n</code></pre><pre><code>list(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[False] = False,\n) -&gt; ListStream[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: bool = False,\n) -&gt; ListStream[RecordBatch] | ListStream[Sequence[ObjectMeta]]\n</code></pre> <p>List all the objects with the given prefix.</p> <p>Refer to the documentation for list.</p>"},{"location":"api/store/memory/#obstore.store.MemoryStore.list_async","title":"list_async","text":"<pre><code>list_async(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[True],\n) -&gt; ListStream[RecordBatch]\n</code></pre><pre><code>list_async(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: Literal[False] = False,\n) -&gt; ListStream[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list_async(\n    prefix: str | None = None,\n    *,\n    offset: str | None = None,\n    chunk_size: int = 50,\n    return_arrow: bool = False,\n) -&gt; ListStream[RecordBatch] | ListStream[Sequence[ObjectMeta]]\n</code></pre> <p>List all the objects with the given prefix.</p> <p>Refer to the documentation for list.</p> <p>Note</p> <p>This is an alias for <code>list</code>, provided to match the <code>ListAsync</code> protocol in obspec. There is no difference in functionality between this and the <code>list</code> method.</p>"},{"location":"api/store/memory/#obstore.store.MemoryStore.list_with_delimiter","title":"list_with_delimiter","text":"<pre><code>list_with_delimiter(\n    prefix: str | None = None, *, return_arrow: Literal[True]\n) -&gt; ListResult[Table]\n</code></pre><pre><code>list_with_delimiter(\n    prefix: str | None = None, *, return_arrow: Literal[False] = False\n) -&gt; ListResult[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list_with_delimiter(\n    prefix: str | None = None, *, return_arrow: bool = False\n) -&gt; ListResult[Table] | ListResult[Sequence[ObjectMeta]]\n</code></pre> <p>List objects with the given prefix and an implementation specific delimiter.</p> <p>Refer to the documentation for list_with_delimiter.</p>"},{"location":"api/store/memory/#obstore.store.MemoryStore.list_with_delimiter_async","title":"list_with_delimiter_async  <code>async</code>","text":"<pre><code>list_with_delimiter_async(\n    prefix: str | None = None, *, return_arrow: Literal[True]\n) -&gt; ListResult[Table]\n</code></pre><pre><code>list_with_delimiter_async(\n    prefix: str | None = None, *, return_arrow: Literal[False] = False\n) -&gt; ListResult[Sequence[ObjectMeta]]\n</code></pre> <pre><code>list_with_delimiter_async(\n    prefix: str | None = None, *, return_arrow: bool = False\n) -&gt; ListResult[Table] | ListResult[Sequence[ObjectMeta]]\n</code></pre> <p>Call <code>list_with_delimiter</code> asynchronously.</p> <p>Refer to the documentation for list_with_delimiter.</p>"},{"location":"api/store/memory/#obstore.store.MemoryStore.put","title":"put","text":"<pre><code>put(\n    path: str,\n    file: IO[bytes]\n    | Path\n    | bytes\n    | Buffer\n    | Iterator[Buffer]\n    | Iterable[Buffer],\n    *,\n    attributes: Attributes | None = None,\n    tags: dict[str, str] | None = None,\n    mode: PutMode | None = None,\n    use_multipart: bool | None = None,\n    chunk_size: int = 5 * 1024 * 1024,\n    max_concurrency: int = 12,\n) -&gt; PutResult\n</code></pre> <p>Save the provided bytes to the specified location.</p> <p>Refer to the documentation for put.</p>"},{"location":"api/store/memory/#obstore.store.MemoryStore.put_async","title":"put_async  <code>async</code>","text":"<pre><code>put_async(\n    path: str,\n    file: IO[bytes]\n    | Path\n    | bytes\n    | Buffer\n    | AsyncIterator[Buffer]\n    | AsyncIterable[Buffer]\n    | Iterator[Buffer]\n    | Iterable[Buffer],\n    *,\n    attributes: Attributes | None = None,\n    tags: dict[str, str] | None = None,\n    mode: PutMode | None = None,\n    use_multipart: bool | None = None,\n    chunk_size: int = 5 * 1024 * 1024,\n    max_concurrency: int = 12,\n) -&gt; PutResult\n</code></pre> <p>Call <code>put</code> asynchronously.</p> <p>Refer to the documentation for <code>put</code>. In addition to what the synchronous <code>put</code> allows for the <code>file</code> parameter, this also supports an async iterator or iterable of objects implementing the Python buffer protocol.</p> <p>This means, for example, you can pass the result of <code>get_async</code> directly to <code>put_async</code>, and the request will be streamed through Python during the put operation:</p> <pre><code>import obstore as obs\n\n# This only constructs the stream, it doesn't materialize the data in memory\nresp = await obs.get_async(store1, path1)\n# A streaming upload is created to copy the file to path2\nawait obs.put_async(store2, path2)\n</code></pre>"},{"location":"api/store/memory/#obstore.store.MemoryStore.rename","title":"rename","text":"<pre><code>rename(from_: str, to: str, *, overwrite: bool = True) -&gt; None\n</code></pre> <p>Move an object from one path to another in the same object store.</p> <p>Refer to the documentation for rename.</p>"},{"location":"api/store/memory/#obstore.store.MemoryStore.rename_async","title":"rename_async  <code>async</code>","text":"<pre><code>rename_async(from_: str, to: str, *, overwrite: bool = True) -&gt; None\n</code></pre> <p>Call <code>rename</code> asynchronously.</p> <p>Refer to the documentation for rename.</p>"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/2025/02/10/releasing-obstore-04/","title":"Releasing obstore 0.4!","text":"<p>Obstore is the simplest, highest-throughput Python interface to Amazon S3, Google Cloud Storage, and Azure Storage, powered by Rust.</p> <p>This post gives an overview of what's new in obstore version 0.4.</p> <p>Refer to the changelog for all updates.</p>"},{"location":"blog/2025/02/10/releasing-obstore-04/#easier-store-creation-with-from_url","title":"Easier store creation with <code>from_url</code>","text":"<p>There's a new top-level <code>obstore.store.from_url</code> function, which makes it dead-simple to create a store from a URL.</p> <p>Here's an example of using it to inspect data from the Sentinel-2 open data bucket. <code>from_url</code> automatically infers that this is an S3 path and constructs an <code>S3Store</code>, which we can pass to <code>obstore.list_with_delimiter</code> and <code>obstore.get</code>.</p> <pre><code>import obstore as obs\nfrom obstore.store import from_url\n\n# The base path within the bucket to \"mount\" to\nurl = \"s3://sentinel-cogs/sentinel-s2-l2a-cogs/12/S/UF/2022/6/S2A_12SUF_20220601_0_L2A\"\n\n# Pass in store-specific parameters as keyword arguments\n# Here, we pass `skip_signature=True` because it's a public bucket\nstore = from_url(url, region=\"us-west-2\", skip_signature=True)\n\n# Print filenames in this directory\nprint([meta[\"path\"] for meta in obs.list_with_delimiter(store)[\"objects\"]])\n# ['AOT.tif', 'B01.tif', 'B02.tif', 'B03.tif', 'B04.tif', 'B05.tif', 'B06.tif', 'B07.tif', 'B08.tif', 'B09.tif', 'B11.tif', 'B12.tif', 'B8A.tif', 'L2A_PVI.tif', 'S2A_12SUF_20220601_0_L2A.json', 'SCL.tif', 'TCI.tif', 'WVP.tif', 'granule_metadata.xml', 'thumbnail.jpg', 'tileinfo_metadata.json']\n\n# Download thumbnail\nwith open(\"thumbnail.jpg\", \"wb\") as f:\n    f.write(obs.get(store, \"thumbnail.jpg\").bytes())\n</code></pre> <p>And voil\u00e0, we have a thumbnail of the Grand Canyon from space:</p> <p></p> <p><code>from_url</code> also supports typing overloads. So your type checker will raise an error if you try to mix AWS-specific and Azure-specific configuration.</p> <p>Nevertheless, for best typing support, we still suggest using one of the store-specific <code>from_url</code> constructors (such as <code>S3Store.from_url</code>) if you know the protocol. Then your type checker can infer the type of the returned store.</p>"},{"location":"blog/2025/02/10/releasing-obstore-04/#pickle-support","title":"Pickle support","text":"<p>One of obstore's initial integration targets is zarr-python, which needs to load large chunked N-dimensional arrays from object storage. In our early benchmarking, we've found that the obstore-based backend can cut data loading times in half as compared to the standard fsspec-based backend.</p> <p>However, Zarr is commonly used in distributed execution environments like Dask, which needs to be able to move store instances between workers. We've implemented pickle support for store classes to unblock this use case. Read our pickle documentation for more info.</p>"},{"location":"blog/2025/02/10/releasing-obstore-04/#enhanced-loading-of-aws-credentials-provisional","title":"Enhanced loading of AWS credentials (provisional)","text":"<p>By default, each store class expects to find credential information either in environment variables or in passed-in arguments. In the case of AWS, that means the default constructors will not look in file-based credentials sources.</p> <p>The provisional <code>S3Store._from_native</code> constructor uses the official AWS Rust configuration crate to find credentials on the file system. This integration is expected to also automatically refresh temporary credentials before expiration.</p> <p>This API is provisional and may change in the future. If you have any feedback, please open an issue.</p> <p>Obstore version 0.5 is expected to improve on extensible credentials by enabling users to pass in arbitrary credentials in a sync or async function callback.</p>"},{"location":"blog/2025/02/10/releasing-obstore-04/#return-arrow-data-from-list_with_delimiter","title":"Return Arrow data from <code>list_with_delimiter</code>","text":"<p>By default, the <code>obstore.list</code> and <code>obstore.list_with_delimiter</code> APIs return standard Python <code>dict</code>s. However, if you're listing a large bucket, the overhead of materializing all those Python objects can become significant.</p> <p><code>obstore.list</code> and <code>obstore.list_with_delimiter</code> now both support a <code>return_arrow</code> keyword parameter. If set to <code>True</code>, an Arrow <code>RecordBatch</code> or <code>Table</code> will be returned, which is both faster and more memory efficient.</p>"},{"location":"blog/2025/02/10/releasing-obstore-04/#access-configuration-values-back-from-a-store","title":"Access configuration values back from a store","text":"<p>There are new attributes, such as <code>config</code>, <code>client_options</code>, and <code>retry_config</code> for accessing configuration parameters back from a store instance.</p> <p>This example uses an <code>S3Store</code> but the same behavior applies to <code>GCSStore</code> and <code>AzureStore</code> as well.</p> <pre><code>from obstore.store import S3Store\n\nstore = S3Store.from_url(\n    \"s3://ookla-open-data/parquet/performance/type=fixed/year=2024/quarter=1\",\n    region=\"us-west-2\",\n    skip_signature=True,\n)\nnew_store = S3Store(\n    config=store.config,\n    prefix=store.prefix,\n    client_options=store.client_options,\n    retry_config=store.retry_config,\n)\nassert store.config == new_store.config\nassert store.prefix == new_store.prefix\nassert store.client_options == new_store.client_options\nassert store.retry_config == new_store.retry_config\n</code></pre>"},{"location":"blog/2025/02/10/releasing-obstore-04/#open-remote-objects-as-file-like-readers-or-writers","title":"Open remote objects as file-like readers or writers","text":"<p>This version adds support for opening remote objects as a file-like reader or writer.</p> <pre><code>import os\n\nimport obstore as obs\nfrom obstore.store import MemoryStore\n\n# Create an in-memory store\nstore = MemoryStore()\n\n# Iteratively write to the file\nwith obs.open_writer(store, \"new_file.csv\") as writer:\n    writer.write(b\"col1,col2,col3\\n\")\n    writer.write(b\"a,1,True\\n\")\n    writer.write(b\"b,2,False\\n\")\n    writer.write(b\"c,3,True\\n\")\n\n\n# Open a reader from the file\nreader = obs.open_reader(store, \"new_file.csv\")\nfile_length = reader.seek(0, os.SEEK_END)\nprint(file_length) # 43\nreader.seek(0)\nbuf = reader.read()\nprint(buf)\n# Bytes(b\"col1,col2,col3\\na,1,True\\nb,2,False\\nc,3,True\\n\")\n</code></pre> <p>See <code>obstore.open_reader</code> and <code>obstore.open_writer</code> for more details. An async file-like reader and writer is also provided, see <code>obstore.open_reader_async</code> and <code>obstore.open_writer_async</code>.</p>"},{"location":"blog/2025/02/10/releasing-obstore-04/#benchmarking","title":"Benchmarking","text":"<p>Benchmarking is still ongoing, but early results have been very promising and we've added documentation about our progress so far.</p>"},{"location":"blog/2025/02/10/releasing-obstore-04/#new-examples","title":"New examples","text":"<p>We've worked to update the documentation with more examples! We now have examples for how to use obstore with FastAPI, MinIO, and tqdm.</p> <p>We've also worked to consolidate introductory documentation into the \"user guide\".</p>"},{"location":"blog/2025/02/10/releasing-obstore-04/#all-updates","title":"All updates","text":"<p>Refer to the changelog for all updates.</p>"},{"location":"blog/2025/03/17/releasing-obstore-05/","title":"Releasing obstore 0.5!","text":"<p>Obstore is the simplest, highest-throughput Python interface to Amazon S3, Google Cloud Storage, and Azure Storage, powered by Rust.</p> <p>This post gives an overview of what's new in obstore version 0.5.</p> <p>Refer to the changelog for all updates.</p>"},{"location":"blog/2025/03/17/releasing-obstore-05/#class-method-wrappers","title":"Class method wrappers","text":"<p>Until now, obstore provided only a functional API with top-level functions exported from the <code>obstore</code> module. Now, obstore additionally provides these functions as methods on each store class.</p> <p>Previously:</p> <pre><code>import obstore as obs\nfrom obstore.store import AzureStore\n\nstore = AzureStore()\nobs.put(store, ...)\n</code></pre> <p>Now:</p> <pre><code>from obstore.store import AzureStore\n\nstore = AzureStore()\nstore.put(...) # (1)!\n</code></pre> <ol> <li>Note that this calls the class method <code>store.put</code> instead of the module-level function <code>obstore.put</code>.</li> </ol> <p>This also can ease understanding of the API, since you can explore available methods from the store object directly.</p> <p></p>"},{"location":"blog/2025/03/17/releasing-obstore-05/#credential-providers","title":"Credential providers","text":"<p>Authentication tends to be among the trickiest but most important elements of connecting to object storage. There are many ways to handle credentials, and trying to support every one natively in Obstore demands a high maintenance burden.</p> <p>Instead, this release supports custom credential providers: Python callbacks that allow for full control over credential generation.</p> <p>We'll dive into a few salient points, but make sure to read the full authentication documentation in the user guide.</p>"},{"location":"blog/2025/03/17/releasing-obstore-05/#official-sdk-credential-providers","title":"\"Official\" SDK credential providers","text":"<p>You can use the <code>Boto3CredentialProvider</code> to use <code>boto3.Session</code> to handle credentials.</p> <pre><code>from boto3 import Session\nfrom obstore.auth.boto3 import Boto3CredentialProvider\nfrom obstore.store import S3Store\n\nsession = Session(...)\ncredential_provider = Boto3CredentialProvider(session)\nstore = S3Store(\"bucket_name\", credential_provider=credential_provider)\n</code></pre>"},{"location":"blog/2025/03/17/releasing-obstore-05/#custom-credential-providers","title":"Custom credential providers","text":"<p>There's a long tail of possible authentication mechanisms. Obstore allows you to provide your own custom authentication callback.</p> <p>You can provide either a synchronous or asynchronous custom authentication function.</p> <p>The simplest custom credential provider can be just a function callback:</p> <pre><code>from datetime import datetime, timedelta, UTC\n\ndef get_credentials() -&gt; S3Credential:\n    return {\n        \"access_key_id\": \"...\",\n        \"secret_access_key\": \"...\",\n        # Not always required\n        \"token\": \"...\",\n        \"expires_at\": datetime.now(UTC) + timedelta(minutes=30),\n    }\n</code></pre> <p>Then just pass that function into <code>credential_provider</code>:</p> <pre><code>S3Store(..., credential_provider=get_credentials)\n</code></pre> <p>More advanced credential providers, which may need to store state, can be class based. See the authentication user guide for more information.</p>"},{"location":"blog/2025/03/17/releasing-obstore-05/#automatic-token-refresh","title":"Automatic token refresh","text":"<p>If the credential returned by the credential provider includes an <code>expires_at</code> key, obstore will automatically call the credential provider to refresh your token before the expiration time.</p> <p>Your code doesn't need to think about token expiration times!</p> <p>This allows for seamlessly using something like the AWS Security Token Service (STS), which provides temporary token credentials each hour. See <code>StsCredentialProvider</code> for an example of a credential provider that uses <code>STS.Client.assume_role</code> to automatically refresh tokens.</p>"},{"location":"blog/2025/03/17/releasing-obstore-05/#improved-fsspec-integration","title":"Improved Fsspec integration","text":"<p>This release also significantly improves integration with the fsspec ecosystem.</p> <p>You can now register obstore as the default handler for supported protocols, like <code>s3</code>, <code>gs</code>, and <code>az</code>. Then calling <code>fsspec.filesystem</code> or <code>fsspec.open</code> will automatically defer to <code>obstore.fsspec.FsspecStore</code> and <code>obstore.fsspec.BufferedFile</code>, respectively.</p> <p>The fsspec integration is no longer tied to a specific bucket. Instead, <code>FsspecStore</code> will automatically handle multiple buckets within a single protocol.</p> <p>For example, obstore's fsspec integration is now tested as working with pyarrow.</p> <p>For more information, read the fsspec page in the user guide.</p>"},{"location":"blog/2025/03/17/releasing-obstore-05/#improved-aws-type-hinting","title":"Improved AWS type hinting","text":"<p>Type hinting has been improved for AWS enums, for example AWS region. Now, when you're constructing an S3Store, if your editor supports it, you'll receive suggestions based on the type hints.</p> <p>Here are two examples from vscode:</p> <p> </p>"},{"location":"blog/2025/03/17/releasing-obstore-05/#benchmarking","title":"Benchmarking","text":"<p>We've continued work on benchmarking obstore.</p> <p>New benchmarks run on an EC2 M5 instance indicate obstore provides 2.8x higher throughput than aioboto3 when fetching the first 16KB of a file many times from an async context.</p>"},{"location":"blog/2025/03/17/releasing-obstore-05/#improved-documentation","title":"Improved documentation","text":"<ul> <li>fsspec documentation</li> <li>pyarrow integration</li> <li>authentication documentation</li> </ul>"},{"location":"blog/2025/03/17/releasing-obstore-05/#all-updates","title":"All updates","text":"<p>Refer to the changelog for all updates.</p>"},{"location":"blog/2025/03/24/releasing-obstore-06/","title":"Releasing obstore 0.6!","text":"<p>Obstore is the simplest, highest-throughput Python interface to Amazon S3, Google Cloud Storage, and Azure Storage, powered by Rust.</p> <p>This post gives an overview of what's new in obstore version 0.6.</p> <p>Refer to the changelog for all updates.</p>"},{"location":"blog/2025/03/24/releasing-obstore-06/#easier-access-to-microsoft-planetary-computer","title":"Easier access to Microsoft Planetary Computer","text":"<p>The Microsoft Planetary Computer hosts a multi-petabyte catalog of global environmental data.</p> <p>The contained data is publicly accessible, but requires the user to fetch short-lived access tokens. But accessing and refreshing these tokens every hour can be confusing and annoying.</p> <p>Following up on the addition in v0.5 of credential providers, this release adds <code>PlanetaryComputerCredentialProvider</code>, which handles all token access and refresh automatically.</p> <p>As a quick example, we'll read data from the NAIP dataset:</p> <pre><code>from obstore.store import AzureStore\nfrom obstore.auth.planetary_computer import PlanetaryComputerCredentialProvider\n\nurl = \"https://naipeuwest.blob.core.windows.net/naip/v002/mt/2023/mt_060cm_2023/\"\n\n# Construct an AzureStore with this credential provider.\n#\n# The account, container, and container prefix are passed down to AzureStore\n# automatically.\nstore = AzureStore(credential_provider=PlanetaryComputerCredentialProvider(url))\n</code></pre> <p>Then, for example, list some items in the container (the prefix <code>v002/mt/2023/mt_060cm_2023</code> was automatically set as the prefix on the <code>AzureStore</code>):</p> <pre><code>items = next(store.list())\nprint(items[:2])\n</code></pre> <pre><code>[{'path': '44104/m_4410401_ne_13_060_20230811_20240103.200.jpg',\n  'last_modified': datetime.datetime(2025, 1, 13, 18, 18, 1, tzinfo=datetime.timezone.utc),\n  'size': 14459,\n  'e_tag': '0x8DD33FE9DB7A24D',\n  'version': None},\n {'path': '44104/m_4410401_ne_13_060_20230811_20240103.tif',\n  'last_modified': datetime.datetime(2025, 1, 13, 16, 39, 6, tzinfo=datetime.timezone.utc),\n  'size': 400422790,\n  'e_tag': '0x8DD33F0CC1D1752',\n  'version': None}]\n</code></pre> <p>And we can fetch an image thumbnail:</p> <pre><code>path = \"44106/m_4410602_nw_13_060_20230712_20240103.200.jpg\"\nimage_content = store.get(path).bytes()\n\n# Write out the image content to a file in the current directory\nwith open(\"thumbnail.jpg\", \"wb\") as f:\n    f.write(image_content)\n</code></pre> <p>And voil\u00e0:</p> <p></p>"},{"location":"blog/2025/03/24/releasing-obstore-06/#using-with-the-planetary-computer-stac-api","title":"Using with the Planetary Computer STAC API","text":"<p>STAC is a metadata specification for geospatial data. The Planetary Computer provides a STAC API to help search and find data of interest.</p> <p>The <code>PlanetaryComputerCredentialProvider</code> includes a <code>from_asset</code>.from_asset] constructor to easily convey configuration.</p> <pre><code>import pystac_client\n\nfrom obstore.auth.planetary_computer import PlanetaryComputerCredentialProvider\nfrom obstore.store import AzureStore\n\nstac_url = \"https://planetarycomputer.microsoft.com/api/stac/v1/\"\n# Open the STAC Catalog\ncatalog = pystac_client.Client.open(stac_url)\n\n# Access a specific Collection and Asset\ncollection = catalog.get_collection(\"daymet-daily-hi\")\nasset = collection.assets[\"zarr-abfs\"]\n\n# Then we can pass this directly to `from_asset`\ncredential_provider = PlanetaryComputerCredentialProvider.from_asset(asset)\n\n# Print objects at the root of this directory\nstore = AzureStore(credential_provider=credential_provider)\nprint(store.list_with_delimiter()[\"objects\"])\n</code></pre> <pre><code>[{'path': '.zattrs',\n  'last_modified': datetime.datetime(2021, 6, 9, 15, 48, 6, tzinfo=datetime.timezone.utc),\n  'size': 402,\n  'e_tag': '0x8D92B5DF9186DED',\n  'version': None},\n {'path': '.zgroup',\n  'last_modified': datetime.datetime(2021, 6, 9, 15, 45, 56, tzinfo=datetime.timezone.utc),\n  'size': 24,\n  'e_tag': '0x8D92B5DABDE919A',\n  'version': None},\n {'path': '.zmetadata',\n  'last_modified': datetime.datetime(2021, 6, 9, 15, 46, 56, tzinfo=datetime.timezone.utc),\n  'size': 13479,\n  'e_tag': '0x8D92B5DCFE1B7CC',\n  'version': None}]\n</code></pre>"},{"location":"blog/2025/03/24/releasing-obstore-06/#all-updates","title":"All updates","text":"<p>Refer to the changelog for all updates.</p>"},{"location":"blog/2025/06/25/releasing-obstore-07/","title":"Releasing obstore 0.7!","text":"<p>Obstore is the simplest, highest-throughput Python interface to Amazon S3, Google Cloud Storage, and Azure Storage, powered by Rust.</p> <p>This post gives an overview of what's new in obstore version 0.7.</p> <p>Refer to the changelog for all updates.</p>"},{"location":"blog/2025/06/25/releasing-obstore-07/#anonymous-connections-to-google-cloud-storage","title":"Anonymous connections to Google Cloud Storage","text":"<p>Obstore now supports anonymous connections to GCS. Pass <code>skip_signature=True</code> to configure an anonymous connection.</p> <pre><code>from obstore.store import GCSStore\n\nstore = GCSStore(\n    \"weatherbench2\",\n    prefix=\"datasets/era5/1959-2023_01_10-full_37-1h-0p25deg-chunk-1.zarr\",\n    # Anonymous connection\n    skip_signature=True,\n)\nstore.list_with_delimiter()[\"objects\"]\n</code></pre> <p>Now prints:</p> <pre><code>[{'path': '.zattrs',\n  'last_modified': datetime.datetime(2023, 11, 22, 9, 4, 54, 481000, tzinfo=datetime.timezone.utc),\n  'size': 2,\n  'e_tag': '\"99914b932bd37a50b983c5e7c90ae93b\"',\n  'version': None},\n {'path': '.zgroup',\n  'last_modified': datetime.datetime(2023, 11, 22, 9, 4, 53, 465000, tzinfo=datetime.timezone.utc),\n  'size': 24,\n  'e_tag': '\"e20297935e73dd0154104d4ea53040ab\"',\n  'version': None},\n {'path': '.zmetadata',\n  'last_modified': datetime.datetime(2023, 11, 22, 9, 4, 54, 947000, tzinfo=datetime.timezone.utc),\n  'size': 46842,\n  'e_tag': '\"9d287796ca614bfec4f1bb20a4ac1ba3\"',\n  'version': None}]\n</code></pre>"},{"location":"blog/2025/06/25/releasing-obstore-07/#obspec-v01-compatibility","title":"Obspec v0.1 compatibility","text":"<p>Obstore provides an implementation for accessing Amazon S3, Google Cloud Storage, and Azure Storage, but some libraries may want to also support other backends, such as HTTP clients or more obscure things like SFTP or HDFS filesystems.</p> <p>Additionally, there's a bunch of useful behavior that could exist on top of Obstore: caching, metrics, globbing, bulk operations. While all of those operations are useful, we want to keep the core Obstore library as small as possible, tightly coupled with the underlying Rust <code>object_store</code> library.</p> <p>Obspec exists to provide the abstractions for generic programming against object store backends. Obspec is essentially a formalization and generalization of the Obstore API, so if you're already using Obstore, very few changes are needed to use Obspec instead.</p> <p>Downstream libraries can program against the Obspec API to be fully generic around what underlying backend is used at runtime.</p> <p>For further information, refer to the Obspec documentation and the Obspec announcement blog post.</p>"},{"location":"blog/2025/06/25/releasing-obstore-07/#customize-headers-sent-in-requests","title":"Customize headers sent in requests","text":"<p><code>ClientConfig</code> now accepts a <code>default_headers</code> key. This allows you to add additional headers that will be sent by the HTTP client on every request.</p>"},{"location":"blog/2025/06/25/releasing-obstore-07/#improvements-to-nasa-earthdata-credential-provider","title":"Improvements to NASA Earthdata credential provider","text":"<p>The NASA Earthdata credential provider now allows user to customize the host that handles credentialization.</p> <p>It also allows for more possibilities of passing credentials. Authentication information can be a NASA Earthdata token, NASA Earthdata username/password (tuple), or <code>None</code>, in which case, environment variables or a <code>~/.netrc</code> file are used, if set.</p> <p>See updated documentation on the NASA Earthdata page.</p>"},{"location":"blog/2025/06/25/releasing-obstore-07/#fixed-creation-of-azurestore-from-https-url","title":"Fixed creation of <code>AzureStore</code> from HTTPS URL","text":"<p>Previously, this would create an incorrect AzureStore configuration:</p> <pre><code>url = \"https://overturemapswestus2.blob.core.windows.net/release\"\nstore = AzureStore.from_url(url, skip_signature=True)\n</code></pre> <p>because it would interpret <code>release</code> as part of the within-bucket prefix, when it should really be interpreted as the container name.</p> <p>This is now fixed and this test passes:</p> <pre><code>url = \"https://overturemapswestus2.blob.core.windows.net/release\"\nstore = AzureStore.from_url(url, skip_signature=True)\n\nassert store.config.get(\"container_name\") == \"release\"\nassert store.config.get(\"account_name\") == \"overturemapswestus2\"\nassert store.prefix is None\n</code></pre>"},{"location":"blog/2025/06/25/releasing-obstore-07/#improved-documentation","title":"Improved documentation","text":"<ul> <li>New <code>Zarr</code> example</li> <li>New <code>stream-zip</code> example</li> </ul>"},{"location":"blog/2025/06/25/releasing-obstore-07/#all-updates","title":"All updates","text":"<p>Refer to the changelog for all updates.</p>"},{"location":"dev/DEVELOP/","title":"Contributor Documentation","text":""},{"location":"dev/DEVELOP/#prerequisites","title":"Prerequisites","text":"<p>Install uv and Rust.</p>"},{"location":"dev/DEVELOP/#layout","title":"Layout","text":"<ul> <li><code>pyo3-object_store/</code>: Logic for constructing <code>object_store</code> instances lives here, so that it can potentially be shared with other Rust-Python libraries in the future.</li> <li><code>obstore/</code>: The primary Python-facing bindings of the <code>obstore</code> library. This re-exports the classes defined in <code>pyo3-object_store</code>. It also adds the top-level functions that form the <code>obstore</code> API.</li> <li><code>pyo3-bytes</code>: A wrapper of <code>bytes::Bytes</code> that is used inside <code>obstore</code> for zero-copy buffer exchange between Rust and Python but also is intended to be reusable for other Rust-Python libraries.</li> </ul>"},{"location":"dev/DEVELOP/#developing-obstore","title":"Developing obstore","text":"<p>From the top-level directory, run</p> <pre><code>uv run maturin dev -m obstore/Cargo.toml\n</code></pre> <p>this will compile <code>obstore</code> and add it to the uv-managed Python environment.</p> <p>If you wish to do any benchmarking, run</p> <pre><code>uv run maturin dev -m obstore/Cargo.toml --release\n</code></pre> <p>to compile <code>obstore</code> with release optimizations turned on.</p>"},{"location":"dev/DEVELOP/#maturin-import-hook","title":"Maturin import hook","text":"<p>Run <pre><code>uv run python -m maturin_import_hook site install\n</code></pre></p> <p>to ensure that obstore is automatically recompiled if changed whenever you import <code>obstore</code> in Python.</p> <p>See import hook docs for more information.</p>"},{"location":"dev/DEVELOP/#tests","title":"Tests","text":"<p>All obstore tests should go into the top-level <code>tests</code> directory.</p>"},{"location":"dev/DEVELOP/#publishing","title":"Publishing","text":"<p>Push a new tag to the main branch of the format <code>py-v*</code>. A new version will be published to PyPI automatically.</p>"},{"location":"dev/DEVELOP/#documentation-website","title":"Documentation website","text":"<p>The documentation website is generated with <code>mkdocs</code> and <code>mkdocs-material</code>. You can serve the docs website locally with</p> <pre><code>uv run mkdocs serve\n</code></pre> <p>Publishing documentation happens automatically via CI when a new tag is published of the format <code>py-v*</code>. It can also be triggered manually through the Github Actions dashboard on this page. Note that publishing docs manually is not advised if there have been new code additions since the last release as the new functionality will be associated in the documentation with the tag of the previous release. In this case, prefer publishing a new patch or minor release, which will publish both a new Python package and the new documentation for it.</p>"},{"location":"dev/functional-api/","title":"Functional API Design Choice","text":"<p>Last edited 2025-02-04.</p> <p>See further discussion in this issue.</p> <p>Obstore intentionally presents its main API as top-level functions. E.g. users must use the top level <code>obstore.put</code> function:</p> <pre><code>import obstore as obs\nfrom obstore.store import AzureStore\n\nstore = AzureStore()\nobs.put(store, ....)\n</code></pre> <p>instead of a method on the store itself:</p> <pre><code>import obstore as obs\nfrom obstore.store import AzureStore\n\nstore = AzureStore()\nstore.put(....)\n</code></pre> <p>This page documents the design decisions for this API.</p>"},{"location":"dev/functional-api/#store-specific-vs-generic-api","title":"Store-specific vs generic API","text":"<p>This presents a nice separation of concerns, in my opinion, between store-specific properties and a generic API that works for every <code>ObjectStore</code>.</p> <p>Python store classes such as <code>S3Store</code> have a few properties to access the store-specific configuration, e.g. <code>S3Store.config</code> accesses the S3 credentials. Anything that's a property/method of the store class is specific to that type of store. Whereas any top-level method should work on any store equally well.</p>"},{"location":"dev/functional-api/#simpler-rust-code","title":"Simpler Rust code","text":"<p>On the Rust side, each Python class is a separate <code>struct</code>. A pyo3 <code>#[pyclass]</code> can't implement a trait, so the only way to implement the same methods on multiple Rust structs without copy-pasting is by having a macro. That isn't out of the question, however it does hamper extensibility, and having one and only one way to call commands is simpler to maintain.</p>"},{"location":"dev/functional-api/#simpler-middlewares","title":"Simpler Middlewares","text":"<p>The <code>PrefixStore</code> concept has since been taken out, in favor of natively handling store prefixes, but this argument still holds for other potential middlewares in the future.</p> <p>In developmentseed/obstore!117 we added a binding for <code>PrefixStore</code>.  Because we use object store classes functionally, we only needed 20 lines of Rust code: github.com/developmentseed/obstore/blob/b40d59b4e060ba4fd3dc69468b3ba7da1149758e/pyo3-object_store/src/prefix.rs#L10-L25</p> <p>If we exposed methods on an <code>S3Store</code>, then those methods would be lost whenever you apply a middleware around it, such as <code>PrefixStore(S3Store(...))</code>. So we'd have to ensure those same methods are also installed onto every middleware or other wrapper.</p>"},{"location":"dev/functional-api/#external-ffi-for-objectstore","title":"External FFI for ObjectStore","text":"<p>There was recently discussion on Discord about the merits of having a stable FFI for <code>ObjectStore</code>. If this comes to fruition in the future, then by having a functional API we could seamlessly use third party ObjectStore implementations or middlewares, with no Python overhead.</p> <p>I use a similar functional API in other Python bindings, especially in cases with zero-copy FFI, such as kylebarron.dev/geo-index/latest/api/rtree/#geoindex_rs.rtree.search (where the spatial index is passed in as the first argument instead) and kylebarron.dev/arro3/latest/api/compute/#arro3.compute.cast where the <code>cast</code> is not a method on the Arrow Array.</p>"},{"location":"dev/functional-api/#smaller-core-for-third-party-rust-bindings","title":"Smaller core for third-party Rust bindings","text":"<p>This repo has twin goals:</p> <ol> <li>Provide bindings to <code>object_store</code> for Python users who want a Python API.</li> <li>Make it easier for other Rust developers who are making Python bindings, who are using <code>object_store</code> on the Rust side already, and who want to expose <code>ObjectStore</code> bindings to Python in their own projects.</li> </ol> <p>The first goal is served by the <code>obstore</code> Python package and the second is served by the <code>pyo3-object_store</code> Rust crate. The latter provides builders for <code>S3Store</code>, <code>AzureStore</code>, <code>GCSStore</code>, which means that those third party Rust-Python bindings can have code as simple as:</p> <pre><code>#[pyfunction]\nfn use_object_store(store: PyObjectStore) {\n    let store: Arc&lt;dyn ObjectStore&gt; = store.into_inner();\n}\n</code></pre> <p>Those third party bindings don't need the Python bindings to perform arbitrary <code>get</code>, <code>list</code>, <code>put</code> from Python. Instead, they use this to access a raw <code>Arc&lt;dyn ObjectStore&gt;</code> from the Rust side.</p> <p>You'll notice that <code>S3Store</code>, <code>GCSStore</code>, and <code>AzureStore</code> aren't in the <code>obstore</code> library; they're in <code>pyo3-object_store</code>. We can't add methods to a pyclass from an external crate, so we couldn't leave those builders in <code>pyo3_object_store</code> while having the Python-facing operations live in <code>obstore</code>. Instead we'd have to put the entire content of the Python bindings in the <code>pyo3-object_store</code> crate. Then this would expose whatever class methods from the <code>obstore</code> Python API onto any external Rust-Python library that uses <code>pyo3-object_store</code>. I don't want to leak this abstraction nor make that public to other Rust consumers.</p>"},{"location":"dev/overridden-defaults/","title":"Overridden Defaults","text":"<p>In general, we wish to follow the upstream <code>object_store</code> as closely as possible, which should reduce the maintenance overhead here.</p> <p>However, there are occasionally places where we want to diverge from the upstream decision making, and we document those here.</p> <p>(Currently none).</p>"},{"location":"dev/pickle/","title":"Pickle Implementation","text":"<p>Last edited 2025-02-04.</p> <p>Pickle support is important but hard to implement. It's important to support because it's commonly used from inside Dask and similar libraries to manage state across distributed workers.</p>"},{"location":"dev/pickle/#background","title":"Background","text":"<p>There are two ways to implement pickle support.</p> <ol> <li>Implementing <code>__getstate__</code> and <code>__setstate__</code>. The return value of <code>__getstate__</code> can be pretty much anything I think, and that gets passed back into <code>__setstate__</code> to be unpacked and set as the internal state.</li> <li>Implementing a constructor (tagged in Rust with <code>#[new]</code>) and <code>__getnewargs_ex__</code>. <code>__getnewargs_ex__</code> must return a tuple of <code>(args: tuple, kwargs: dict)</code>, which can be passed to the <code>#[new]</code> constructor. This can be simpler when you already have a <code>#[new]</code> implemented and when the parameters into that <code>#[new]</code> function are easily serializable. However it might require (I wonder if there's a way to recursively pickle things?)</li> </ol> <p>We can't extract the configuration out from a \"finished\" <code>object_store</code> instance like an <code>AmazonS3</code>. We could extract some configuration out of a builder instance like <code>AmazonS3Builder</code>, but then every time we use that class we'd have to call <code>build()</code> on the Rust side, which would probably significantly hurt performance. Therefore, the only(?) possible way to implement pickle support inside obstore is to persist the store configuration separately inside the <code>#[pyclass]</code>.</p>"},{"location":"dev/pickle/#implementation","title":"Implementation","text":"<ul> <li>Store configuration information a second time in the <code>#[pyclass]</code> of each store. (It's already implicitly stored by the underlying rust <code>ObjectStore</code> instance.)</li> <li>Handle prefixes automatically within each Python store class.</li> <li>Implement <code>__getnewargs_ex__</code>, returning the parameters passed to <code>#[new]</code></li> <li>Implement <code>IntoPyObject</code> for each configuration object: the store-specific config, client options, and retry options</li> </ul>"},{"location":"dev/pickle/#benefits","title":"Benefits","text":"<ul> <li>It should be relatively straightforward to implement for any of the raw stores: <code>S3Store</code>, <code>GCSStore</code>, <code>AzureStore</code>, <code>LocalStore</code>, and <code>MemoryStore</code>.</li> <li>We're already validating the <code>PyAmazonS3Config</code>, <code>PyClientOptions</code>, and <code>PyRetryConfig</code>, so it isn't that much extra work just to store those on the Rust class. So we can serialize them to Python objects in <code>__getnewargs_ex__</code> and then have Python automatically pass them to <code>#[new]</code>.</li> <li>Using <code>__getnewargs_ex__</code> means we don't need to add serde support; we can use <code>IntoPyObject</code> and <code>FromPyObject</code> for all (de)serialization and only have a single code path.</li> <li>We can persist all of the store-specific config, the client options, and the retry config, so the pickled instances should be exactly the same as the original instances.</li> <li>Supports any of the builder classmethods, e.g. <code>from_env</code>, <code>from_url</code>, etc,</li> <li>Most of the time, storing configuration information should be just a few strings. So ideally it'll increase memory usage only slightly, and won't affect runtime performance otherwise (assuming you reuse a store instead of creating a new one each time).</li> <li>Since we don't allow the store classes to be mutated after creation from Python, there's no risk of the two copies of the configuration getting out of sync.</li> </ul>"},{"location":"dev/pickle/#drawbacks","title":"Drawbacks","text":"<ul> <li>Because <code>url</code> has deferred parsing in the <code>object_store</code> builders, we need to special-case <code>url</code> handling. Naturally, passing <code>url</code> to a store with <code>with_url</code> means that <code>object_store</code> doesn't actually parse the URL until the <code>build()</code> method, and at that point we can no longer access config information from the built <code>AmazonS3</code>. Without special-casing this URL handling, pickling would fail for instances created from <code>from_url</code>.</li> </ul> <p>Therefore, we handle this by vendoring the small amount of URL parsing from upstream. So we apply the URL parsing onto our config <code>HashMap</code>s and then apply those to the builder. So our configs and those used by the raw stores stay in sync. See developmentseed/obstore!209. - Unclear how to support middleware, including <code>PrefixStore</code>, because those have to support an arbitrary wrapped object. Is there a way to recursively pickle and unpickle the thing it's wrapping?   - (Implemented) If we can't find a way to support pickling of arbitrary middleware, we could alternatively use a <code>PrefixStore</code> internally and automatically inside an <code>S3Store</code>, <code>GCSStore</code>, <code>AzureStore</code> (NOTE: we should maybe benchmark the overhead a <code>PrefixStore</code> causes, in case it's something we don't want to force on everyone? Well, if the <code>S3Store</code> stored an arbitrary <code>Arc&lt;dyn ObjectStore&gt;</code> then we could prefix when asked for and not prefix when not asked for, but maybe that would conflict with signing, if that requires a raw <code>object_store::AmazonS3</code> instance?). Alternatively, we could create the <code>PrefixStore</code> on demand, since it looks virtually free. - We don't currently implement pickle support for <code>MemoryStore</code>, as we don't have a way to serialize the memory state across workers.</p>"},{"location":"examples/fastapi/","title":"FastAPI","text":"<p>FastAPI is a modern, high-performance, web framework for building APIs with Python based on standard Python type hints.</p> <p>It's easy to integrate obstore with FastAPI routes, where you want to download a file from an object store and return it to the user.</p> <p>FastAPI has a <code>StreamingResponse</code>, which neatly integrates with <code>BytesStream</code> to stream the response to the user.</p>"},{"location":"examples/fastapi/#example","title":"Example","text":"<p>Note</p> <p>This example is also available on Github if you'd like to test it out locally.</p> <p>First, import <code>fastapi</code> and <code>obstore</code> and create the FastAPI application.</p> <pre><code>from fastapi import FastAPI\nfrom fastapi.responses import StreamingResponse\n\nfrom obstore.store import HTTPStore, S3Store\n\napp = FastAPI()\n</code></pre> <p>Next, we can add our route. Here, we create a simple route that fetches a small Parquet file from an HTTP url and returns it to the user.</p> <p>Passing <code>resp</code> directly to <code>StreamingResponse</code> calls <code>GetResult.stream()</code> under the hood and thus uses the default chunking behavior of <code>GetResult.stream()</code>.</p> <pre><code>@app.get(\"/example.parquet\")\nasync def download_example() -&gt; StreamingResponse:\n    store = HTTPStore.from_url(\"https://raw.githubusercontent.com\")\n    path = \"opengeospatial/geoparquet/refs/heads/main/examples/example.parquet\"\n\n    # Make the request. This only begins the download; it does not wait for the\n    # download to finish.\n    resp = await store.get_async(path)\n    return StreamingResponse(resp)\n</code></pre> <p>You may also want to customize the chunking behavior of the async stream. To do this, call <code>GetResult.stream()</code> before passing to <code>StreamingResponse</code>.</p> <pre><code>@app.get(\"/large.parquet\")\nasync def large_example() -&gt; StreamingResponse:\n    # Example large Parquet file hosted in AWS open data\n    store = S3Store(\"ookla-open-data\", region=\"us-west-2\", skip_signature=True)\n    path = \"parquet/performance/type=fixed/year=2024/quarter=1/2024-01-01_performance_fixed_tiles.parquet\"\n\n    # Note: for large file downloads you may need to increase the timeout in\n    # the client configuration\n    resp = await store.get_async(path)\n\n    # Example: Ensure the stream returns at least 5MB of data in each chunk.\n    return StreamingResponse(resp.stream(min_chunk_size=5 * 1024 * 1024))\n</code></pre> <p>Note that here FastAPI wraps <code>starlette.responses.StreamingResponse</code>. So any web server that uses Starlette for responses can use this same code.</p>"},{"location":"examples/minio/","title":"Minio","text":"<p>MinIO is a high-performance, S3 compatible object store, open sourced under GNU AGPLv3 license. It's often used for testing or self-hosting S3-compatible storage.</p>"},{"location":"examples/minio/#example","title":"Example","text":"<p>Note</p> <p>This example is also available on Github if you'd like to test it out locally.</p> <p>We can run minio locally using docker:</p> <pre><code>docker run -p 9000:9000 -p 9001:9001 \\\n    quay.io/minio/minio server /data --console-address \":9001\"\n</code></pre> <p><code>obstore</code> isn't able to create a bucket, so we need to do that manually. We can do that through the minio web UI. After running the above docker command, go to localhost:9001. Then log in with the credentials <code>minioadmin</code>, <code>minioadmin</code> for username and password. Then click \"Create a Bucket\" and create a bucket with the name <code>\"test-bucket\"</code>.</p> <p>Now we can create an <code>S3Store</code> to interact with minio:</p> <pre><code>from obstore.store import S3Store\n\nstore = S3Store(\n    \"test-bucket\",\n    endpoint=\"http://localhost:9000\",\n    access_key_id=\"minioadmin\",\n    secret_access_key=\"minioadmin\",\n    virtual_hosted_style_request=False,\n    client_options={\"allow_http\": True},\n)\n\n# Add files\nstore.put(\"a.txt\", b\"foo\")\nstore.put(\"b.txt\", b\"bar\")\nstore.put(\"c/d.txt\", b\"baz\")\n\n# List files\nfiles = store.list().collect()\nprint(files)\n\n# Download a file\nresp = store.get(\"a.txt\")\nprint(resp.bytes())\n\n# Delete a file\nstore.delete(\"a.txt\")\n</code></pre> <p>There's a full example in the obstore repository.</p>"},{"location":"examples/pyarrow/","title":"PyArrow","text":"<p>PyArrow is the canonical Python implementation for the Apache Arrow project.</p> <p>PyArrow also supports reading and writing various file formats, including Parquet, CSV, JSON, and Arrow IPC.</p> <p>PyArrow integration is supported via its fsspec integration, since Obstore exposes an fsspec-compatible API.</p> <p><pre><code>import pyarrow.parquet as pq\n\nfrom obstore.fsspec import FsspecStore\n\nfs = FsspecStore(\"s3\", skip_signature=True, region=\"us-west-2\")\n\nurl = \"s3://overturemaps-us-west-2/release/2025-02-19.0/theme=addresses/type=address/part-00010-e084a2d7-fea9-41e5-a56f-e638a3307547-c000.zstd.parquet\"\nparquet_file = pq.ParquetFile(url, filesystem=fs)\nprint(parquet_file.schema_arrow)\n</code></pre> prints: <pre><code>id: string\ngeometry: binary\nbbox: struct&lt;xmin: float, xmax: float, ymin: float, ymax: float&gt; not null\n  child 0, xmin: float\n  child 1, xmax: float\n  child 2, ymin: float\n  child 3, ymax: float\ncountry: string\npostcode: string\nstreet: string\nnumber: string\nunit: string\naddress_levels: list&lt;element: struct&lt;value: string&gt;&gt;\n  child 0, element: struct&lt;value: string&gt;\n      child 0, value: string\npostal_city: string\nversion: int32 not null\nsources: list&lt;element: struct&lt;property: string, dataset: string, record_id: string, update_time: string, confidence: double&gt;&gt;\n  child 0, element: struct&lt;property: string, dataset: string, record_id: string, update_time: string, confidence: double&gt;\n      child 0, property: string\n      child 1, dataset: string\n      child 2, record_id: string\n      child 3, update_time: string\n      child 4, confidence: double\n-- schema metadata --\ngeo: '{\"version\":\"1.1.0\",\"primary_column\":\"geometry\",\"columns\":{\"geometry' + 230\norg.apache.spark.legacyINT96: ''\norg.apache.spark.version: '3.4.1'\norg.apache.spark.sql.parquet.row.metadata: '{\"type\":\"struct\",\"fields\":[{\"' + 1586\norg.apache.spark.legacyDateTime: ''\n</code></pre></p>"},{"location":"examples/r2/","title":"Cloudflare R2","text":"<p>Cloudflare R2 is Cloudflare's object storage solution, designed to be compatible with the S3 API. Some developers may choose to use Cloudflare R2 because it has no egress fees.</p> <p>It's easy to read and write data to and from Cloudflare R2 with obstore's <code>S3Store</code> with three steps:</p> <ol> <li> <p>Create an API token with read or read/write access to one or more buckets.</p> <p>Copy the <code>Access Key ID</code> and <code>Secret Access Key</code> to use in your code.</p> <p></p> </li> <li> <p>On the general settings of a bucket, take note of the <code>S3 API</code> URL. In my case it's <code>https://f0b62eebfbdde1133378bfe3958325f6.r2.cloudflarestorage.com/kylebarron-public</code>.</p> <p></p> </li> <li> <p>Pass this information to <code>S3Store.from_url</code>:</p> <pre><code>from obstore.store import S3Store\n\naccess_key_id = \"...\"\nsecret_access_key = \"...\"\nstore = S3Store.from_url(\n    \"https://f0b62eebfbdde1133378bfe3958325f6.r2.cloudflarestorage.com/ kylebarron-public\",\n    access_key_id=access_key_id,\n    secret_access_key=secret_access_key,\n)\nstore.list_with_delimiter()\n</code></pre> <p>Or you can construct a store manually with the <code>endpoint</code> and <code>bucket</code> parameters:</p> <pre><code>from obstore.store import S3Store\n\naccess_key_id = \"...\"\nsecret_access_key = \"...\"\nbucket = \"kylebarron-public\"\nendpoint = \"https://f0b62eebfbdde1133378bfe3958325f6.r2.cloudflarestorage. com\"\nstore = S3Store(\n    bucket,\n    access_key_id=access_key_id,\n    secret_access_key=secret_access_key,\n    endpoint=endpoint,\n)\nstore.list_with_delimiter()\n</code></pre> </li> </ol>"},{"location":"examples/stream-zip/","title":"Streaming ZIP file creation","text":"<p>This example demonstrates how to create a zip archive from files in one store and upload it to another store using the <code>stream_zip</code> library.</p> <p>This never stores any entire source file or the target zip file in memory, so you can zip large files with low memory overhead.</p>"},{"location":"examples/stream-zip/#example","title":"Example","text":"<p>Note</p> <p>This example is also available on Github if you'd like to test it out locally.</p> <pre><code>from __future__ import annotations\n\nimport asyncio\nfrom pathlib import Path\nfrom stat import S_IFREG\nfrom typing import TYPE_CHECKING\n\nimport stream_zip\nfrom stream_zip import ZIP_32, AsyncMemberFile\n\nfrom obstore.store import LocalStore, MemoryStore\n\nif TYPE_CHECKING:\n    from collections.abc import AsyncIterable, Iterable\n\n    from obstore.store import ObjectStore\n\n\nasync def member_file(store: ObjectStore, path: str) -&gt; AsyncMemberFile:\n    \"\"\"Create a member file for the zip archive.\"\"\"\n    resp = await store.get_async(path)\n    last_modified = resp.meta[\"last_modified\"]\n    mode = S_IFREG | 0o644\n    # Unclear why but we need to wrap the response in an async generator\n    return (path, last_modified, mode, ZIP_32, (byte async for byte in resp.stream()))\n\n\nasync def member_files(\n    store: ObjectStore,\n    paths: Iterable[str],\n) -&gt; AsyncIterable[AsyncMemberFile]:\n    \"\"\"Create an async iterable of files for the zip archive.\"\"\"\n    for path in paths:\n        yield await member_file(store, path)\n\n\nasync def zip_copy() -&gt; None:\n    \"\"\"Copy files from one store into a zip archive that we upload to another store.\"\"\"\n    # Input store with source data\n    input_store = MemoryStore()\n    input_store.put(\"foo\", b\"hello\")\n    input_store.put(\"bar\", b\"world\")\n\n    # Output store where the zip file will be saved\n    output_store = LocalStore(Path())\n\n    # We can pass the streaming zip directly to `put`\n    await output_store.put_async(\n        \"my.zip\",\n        stream_zip.async_stream_zip(\n            member_files(input_store, [\"foo\", \"bar\"]),\n            chunk_size=10 * 1024 * 1024,\n        ),\n    )\n</code></pre> <p>This creates a zip file in the current directory:</p> <pre><code>&gt; unzip -l my.zip\nArchive:  my.zip\n  Length      Date    Time    Name\n---------  ---------- -----   ----\n        5  05-22-2025 13:37   foo\n        5  05-22-2025 13:37   bar\n---------                     -------\n       10                     2 files\n</code></pre> <p>And we can read a file:</p> <pre><code>&gt; unzip -p my.zip foo\nhello\n</code></pre>"},{"location":"examples/tqdm/","title":"tqdm (Progress Bar)","text":"<p>tqdm provides an interactive progress bar for Python.</p> <p></p> <p>It's easy to wrap obstore downloads with a tqdm progress bar:</p> <pre><code>from obstore.store import HTTPStore\nfrom tqdm import tqdm\n\nstore = HTTPStore.from_url(\"https://ookla-open-data.s3.us-west-2.amazonaws.com\")\npath = \"parquet/performance/type=fixed/year=2019/quarter=1/2019-01-01_performance_fixed_tiles.parquet\"\nresponse = obs.get(store, path)\nfile_size = response.meta[\"size\"]\nwith tqdm(total=file_size) as pbar:\n    for bytes_chunk in response:\n        # Do something with buffer\n        pbar.update(len(bytes_chunk))\n</code></pre> <p>Or, if you're using the async API:</p> <pre><code>from obstore.store import HTTPStore\nfrom tqdm import tqdm\n\nstore = HTTPStore.from_url(\"https://ookla-open-data.s3.us-west-2.amazonaws.com\")\npath = \"parquet/performance/type=fixed/year=2019/quarter=1/2019-01-01_performance_fixed_tiles.parquet\"\nresponse = await obs.get_async(store, path)\nfile_size = response.meta[\"size\"]\nwith tqdm(total=file_size) as pbar:\n    async for bytes_chunk in response:\n        # Do something with buffer\n        pbar.update(len(bytes_chunk))\n</code></pre> <p>There's a full example in the obstore repository.</p>"},{"location":"examples/zarr/","title":"Zarr","text":"<p>Zarr-Python is a Python library for reading and writing the Zarr file format for N-dimensional arrays. Zarr-Python is often used in conjunction with Xarray.</p> <p>Zarr datasets are often very large and thus stored in object storage for cost effectiveness. As of Zarr-Python version 3.0.7 and later, you can use Obstore as a backend for Zarr-Python. For large queries this can be significantly faster than the default fsspec-based backend.</p>"},{"location":"examples/zarr/#example","title":"Example","text":"<p>Note</p> <p>This example is also available on Github if you'd like to test it out locally.</p> <pre><code>import matplotlib.pyplot as plt\nimport pystac_client\nimport xarray as xr\nfrom zarr.storage import ObjectStore\n\nfrom obstore.auth.planetary_computer import PlanetaryComputerCredentialProvider\nfrom obstore.store import AzureStore\n\n# These first lines are specific to Zarr stored in the Microsoft Planetary\n# Computer. We use pystac-client to find the metadata for this specific Zarr\n# store.\ncatalog = pystac_client.Client.open(\n    \"https://planetarycomputer.microsoft.com/api/stac/v1/\",\n)\ncollection = catalog.get_collection(\"daymet-daily-hi\")\nasset = collection.assets[\"zarr-abfs\"]\n\n# We construct an AzureStore because this Zarr dataset is stored in Azure\n# storage\nazure_store = AzureStore(\n    credential_provider=PlanetaryComputerCredentialProvider.from_asset(asset),\n)\n\n# Next we use the Zarr ObjectStorage adapter and pass it to xarray.\nzarr_store = ObjectStore(azure_store, read_only=True)\nds = xr.open_dataset(zarr_store, consolidated=True, engine=\"zarr\")\n\n# And plot with matplotlib\nfig, ax = plt.subplots(figsize=(12, 12))\nds.sel(time=\"2009\")[\"tmax\"].mean(dim=\"time\").plot.imshow(ax=ax, cmap=\"inferno\")\nfig.savefig(\"zarr-example.png\")\n</code></pre> <p>This plots:</p> <p></p>"},{"location":"integrations/","title":"External Integrations","text":"<p>Various integrations with external libraries exist:</p> <ul> <li><code>dagster</code>: Refer to <code>dagster-obstore</code>.</li> <li><code>fsspec</code>: Use the <code>obstore.fsspec</code> module.</li> <li><code>zarr-python</code>: Use <code>zarr.storage.ObjectStore</code>, included as of Zarr version <code>3.0.7</code> and later. See also the Obstore-Zarr example.</li> </ul> <p>And obstore is used internally in more projects:</p> <ul> <li>litData</li> <li>VirtualiZarr</li> </ul> <p>Know of an integration that doesn't exist here? Edit this document.</p>"},{"location":"integrations/fsspec/","title":"fsspec Integration","text":"<p>Obstore provides native integration with the fsspec ecosystem.</p> <p>The fsspec integration is best effort and may not provide the same performance as the rest of obstore. Where possible, implementations should use the underlying <code>obstore</code> APIs directly. If you find any bugs with this integration, please file an issue.</p>"},{"location":"integrations/fsspec/#usage","title":"Usage","text":""},{"location":"integrations/fsspec/#direct-class-usage","title":"Direct class usage","text":"<p>Construct an fsspec-compatible filesystem with <code>FsspecStore</code>. This implements <code>AbstractFileSystem</code>, so you can use it wherever an API expects an fsspec-compatible filesystem.</p> <pre><code>from obstore.fsspec import FsspecStore\n\nfs = FsspecStore(\"s3\", region=\"us-west-2\", skip_signature=True)\nprefix = (\n    \"s3://sentinel-cogs/sentinel-s2-l2a-cogs/12/S/UF/2022/6/S2B_12SUF_20220609_0_L2A/\"\n)\nitems = fs.ls(prefix)\n# [{'name': 'sentinel-cogs/sentinel-s2-l2a-cogs/12/S/UF/2022/6/S2B_12SUF_20220609_0_L2A/AOT.tif',\n#   'size': 80689,\n#   'type': 'file',\n#   'e_tag': '\"c93b0f6b0e2cf8e375968f41161f9df7\"'},\n#   ...\n</code></pre> <p>If you need a readable or writable file-like object, you can call the <code>open</code> method provided on <code>FsspecStore</code>, or you may construct a <code>BufferedFile</code> directly.</p> <pre><code>from obstore.fsspec import FsspecStore\n\nfs = FsspecStore(\"s3\", region=\"us-west-2\", skip_signature=True)\n\nwith fs.open(\n    \"s3://sentinel-cogs/sentinel-s2-l2a-cogs/12/S/UF/2022/6/S2B_12SUF_20220609_0_L2A/thumbnail.jpg\",\n) as file:\n    content = file.read()\n</code></pre> <p>Using the <code>FsspecStore</code> class directly may be preferred because the type hinting should work automatically, which may help IDEs like VSCode suggest valid keyword parameters.</p>"},{"location":"integrations/fsspec/#register-as-a-global-handler","title":"Register as a global handler","text":"<p>Use <code>register</code> to register obstore as the default handler for various protocols. Then use <code>fsspec.filesystem</code> to create an fsspec filesystem object for a specific protocol. Or use <code>fsspec.open</code> to open a file given a URL.</p> <pre><code>import fsspec\nfrom obstore.fsspec import register\n\n# Register obstore as the default handler for all protocols supported by\n# obstore.\n# You may wish to register only specific protocols, instead.\nregister()\n\n# Create a new fsspec filesystem for the given protocol\nfs = fsspec.filesystem(\"https\")\ncontent = fs.cat_file(\"https://example.com/\")\n\n# Or, open the file directly\nurl = \"https://github.com/opengeospatial/geoparquet/raw/refs/heads/main/examples/example.parquet\"\nwith fsspec.open(url) as file:\n    content = file.read()\n</code></pre>"},{"location":"integrations/fsspec/#store-configuration","title":"Store configuration","text":"<p>Some stores may require configuration. You may pass configuration parameters to the <code>FsspecStore</code> constructor directly. Or, if you're using <code>fsspec.filesystem</code>, you may pass configuration parameters to that call, which will pass parameters down to the <code>FsspecStore</code> constructor internally.</p> <pre><code>from obstore.fsspec import FsspecStore\n\nfs = FsspecStore(\"s3\", region=\"us-west-2\", skip_signature=True)\n</code></pre> <p>Or, with <code>fsspec.filesystem</code>:</p> <pre><code>import fsspec\n\nfrom obstore.fsspec import register\n\nregister(\"s3\")\n\nfs = fsspec.filesystem(\"s3\", region=\"us-west-2\", skip_signature=True)\n</code></pre>"},{"location":"integrations/fsspec/#type-hinting","title":"Type hinting","text":"<p>The fsspec API is not conducive to type checking. The easiest way to get type hinting for parameters is to use <code>FsspecStore</code> to construct fsspec-compatible stores instead of <code>fsspec.filesystem</code>.</p> <p><code>fsspec.open</code> and <code>fsspec.filesystem</code> take arbitrary keyword arguments that they pass down to the underlying store, and these pass-through arguments are not typed.</p> <p>However, it is possible to get type checking of store configuration by defining config parameters as a dictionary:</p> <pre><code>from __future__ import annotations\n\nfrom typing import TYPE_CHECKING\n\nimport fsspec\n\nfrom obstore.fsspec import register\n\nif TYPE_CHECKING:\n    from obstore.store import S3Config\n\nregister(\"s3\")\n\nconfig: S3Config = {\"region\": \"us-west-2\", \"skip_signature\": True}\nfs = fsspec.filesystem(\"s3\", config=config)\n</code></pre> <p>Then your type checker will validate that the <code>config</code> dictionary is compatible with <code>S3Config</code>. VSCode also provides auto suggestions for parameters:</p> <p></p> <p>Note</p> <p><code>S3Config</code> is a \"type-only\" construct, and so it needs to be imported from within an <code>if TYPE_CHECKING</code> block. Additionally, <code>from __future__ import annotations</code> must be at the top of the file.</p>"},{"location":"troubleshooting/aws/","title":"Troubleshooting Amazon S3","text":""},{"location":"troubleshooting/aws/#region-required","title":"Region required","text":"<p>All requests to S3 must include the region. An error will occur on requests when you don't pass the correct region.</p> <p>For example, trying to list the <code>sentinel-cogs</code> open bucket without passing a region will fail:</p> <pre><code>from obstore.store import S3Store\n\nstore = S3Store(\"sentinel-cogs\", skip_signature=True)\nnext(store.list())\n</code></pre> <p>raises</p> <pre><code>GenericError: Generic S3 error: Error performing list request:\nReceived redirect without LOCATION, this normally indicates an incorrectly\nconfigured region\n</code></pre> <p>We can fix this by passing the correct region:</p> <pre><code>from obstore.store import S3Store\n\nstore = S3Store(\"sentinel-cogs\", skip_signature=True, region=\"us-west-2\")\nnext(store.list())\n</code></pre> <p>this prints:</p> <pre><code>[{'path': 'sentinel-s2-l2a-cogs/1/C/CV/2018/10/S2B_1CCV_20181004_0_L2A/AOT.tif',\n  'last_modified': datetime.datetime(2020, 9, 30, 20, 25, 56, tzinfo=datetime.timezone.utc),\n  'size': 50510,\n  'e_tag': '\"2e24c2ee324ea478f2f272dbd3f5ce69\"',\n  'version': None},\n...\n</code></pre>"},{"location":"troubleshooting/aws/#inferring-the-bucket-region","title":"Inferring the bucket region","text":"<p>Note that it's possible to infer the S3 bucket region from an arbitrary <code>HEAD</code> request.</p> <p>Here, we show an example of using <code>requests</code> to find the bucket region, but you can use any HTTP client:</p> <pre><code>import requests\n\ndef find_bucket_region(bucket_name: str) -&gt; str:\n    resp = requests.head(f\"https://{bucket_name}.s3.amazonaws.com\")\n    return resp.headers[\"x-amz-bucket-region\"]\n</code></pre> <p>Applying this to our previous example, we can use this to find the region of the <code>sentinel-cogs</code> bucket:</p> <pre><code>find_bucket_region(\"sentinel-cogs\")\n# 'us-west-2'\n</code></pre> <p>Or we can pass this directly into the region:</p> <pre><code>bucket_name = \"sentinel-cogs\"\nstore = S3Store(\n    bucket_name, skip_signature=True, region=find_bucket_region(bucket_name)\n)\n</code></pre> <p>Finding the bucket region in this way works both for public and non-public buckets.</p> <p>This <code>HEAD</code> request can also tell you if the bucket is public or not by checking the HTTP response code (accessible in <code>requests</code> via <code>resp.status_code</code>):</p> <ul> <li><code>200</code>: public bucket.</li> <li><code>403</code>: private bucket.</li> </ul>"},{"location":"blog/archive/2025/","title":"2025","text":""},{"location":"blog/category/release/","title":"Release","text":""}]}